{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather Data Definition  \n",
    "STATION = Weather station ID  \n",
    "NAME = Weather station location  \n",
    "Date = Date  \n",
    "AWND = Average daily wind speed (meters per second or miles per hour as per user preference)  \n",
    "PGTM = Peak gust time (hours and minutes, i.e., HHMM)  \n",
    "PRCP = Precipitation (mm or inches as per user preference, inches to hundredths on Daily Form pdf file)  \n",
    "TMAX = Maximum temperature, F  \n",
    "TMIN = Minimum temperature, F  \n",
    "WDF2 = Direction of fastest 2-minute wind (degrees)  \n",
    "WDF5 = Direction of fastest 5-second wind (degrees)  \n",
    "WSF2 = Fastest 2-minute wind speed (miles per hour or meters per second as per user preference)  \n",
    "WSF5 = Fastest 5-second wind speed (miles per hour or meters per second as per user preference)  \n",
    "WT01 = Fog, ice fog, or freezing fog (may include heavy fog)  \n",
    "WT02 = Heavy fog or heaving freezing fog (not always distinguished from fog)  \n",
    "WT08 = Smoke or haze  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"C:/Users/ping/MyDrive/py_files/python/py379/\")\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "pd.set_option('max_colwidth', 12, 'display.max_columns', 18, 'display.width', 1200, 'display.max_rows', 100)\n",
    "INPUT_DIR = 'C:/Users/ping/OneDrive/Documents/jenn_bb_sales'\n",
    "path_pickle_dump = f'{INPUT_DIR}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_load(path_pickle_dump, 'df_item_sale_n_weather_raw')\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''drop wholesale customers '''\n",
    "df = df[df['Customer Name'] != 'Canyon Coffee']\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In columns with string dtype:'''\n",
    "'''  strip leading and trailing spacee'''\n",
    "'''  converts first character of each word to uppercase'''\n",
    "# https://stackoverflow.com/questions/65756553/check-if-entire-pandas-object-column-is-a-string\n",
    "for column in df.columns:\n",
    "  # infer column cell type: 'string' or 'floating'\n",
    "  col_type = pd.api.types.infer_dtype(df[column])\n",
    "  if col_type == 'string':\n",
    "    # https://www.datasciencemadesimple.com/strip-space-column-pandas-dataframe-leading-trailing-2/\n",
    "    df[column] = df[column].str.strip()\n",
    "    df[column] = df[column].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Combine same items'''\n",
    "df.Item = df.Item.replace(to_replace=['Double Chocolate Espresso Cookie', '2X Choc'], value='Double Chocolate Cookie')\n",
    "df.Item = df.Item.replace(to_replace=['Choc Croissant', 'Choc Crx'], value='Chocolate Croissant')\n",
    "df.Item = df.Item.replace(to_replace=['Crx'], value='Croissant')\n",
    "df.Item = df.Item.replace(to_replace=['Ccc'], value='Chocolate Chip Cookie')\n",
    "df.Item = df.Item.replace(to_replace=['Cinn Knot'], value='Cinnamon Knot')\n",
    "df.Item = df.Item.replace(to_replace=['Bluerberry Muffin', 'Bb Muf'], value='Blueberry Muffin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''group and count items in the Item column'''\n",
    "s = df.Item\n",
    "grouped = s.groupby(s)\n",
    "_dict = {}\n",
    "for key in grouped.groups.keys():\n",
    "  _count = grouped.get_group(key).count()\n",
    "  _dict[key] = _count\n",
    "\n",
    "_dict = dict(sorted(_dict.items(), reverse = True, key=lambda item: item[1]))\n",
    "for k, v in _dict.items():\n",
    "    print(f'{k:<45}{v:10,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''drop columns that are not needed'''\n",
    "cols_df = df.columns.tolist()\n",
    "cols_grSale_keep = \\\n",
    "  ['Date', 'Time', 'Category', 'Item', 'Qty', 'Gross Sales', 'Discounts', 'Net Sales', 'Tax', 'Transaction ID', 'Event Type', 'Dining Option', 'Customer Name']\n",
    "cols_weather_keep = ['NAME', 'AWND', 'PRCP', 'TAVG', 'TMAX', 'TMIN', 'WT01', 'WT02', 'WT08', 'DOW']\n",
    "cols_keep = cols_grSale_keep + cols_weather_keep\n",
    "diff = set(cols_df) - set(cols_keep)\n",
    "cols_drop = [item for item in cols_df if item in diff]  # retaining column order of set difference\n",
    "df.drop(cols_drop, axis=1, inplace=True)\n",
    "print(f'df.columns: {df.columns}')\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''calculate avg. temp.'''\n",
    "df.TAVG = (df.TMAX + df.TMIN) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''replace Day-Of-Week from str to integer''' \n",
    "df['DOW'] = df['DOW'].replace(to_replace=['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'], value=[0, 1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''strip leading $, convert from object to float'''\n",
    "_cols = ['Gross Sales', 'Discounts', 'Net Sales', 'Tax']\n",
    "for _col in _cols:\n",
    "  df[_col] = df[_col].str.split('$').str[-1]  # strip leading $\n",
    "  df[_col] = pd.to_numeric(df[_col])  # convert from object to float\n",
    "pickle_dump(df, path_pickle_dump, 'df_item_sale_n_weather_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_load(path_pickle_dump, 'df_item_sale_n_weather_cleaned')\n",
    "print(f'df.shape: {df.shape}')\n",
    "print(f'df.info(): {df.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''group and count items in each column'''\n",
    "# https://datagy.io/pandas-groupby/\n",
    "for column in df.columns[2::]: # skip columns: Date, Time\n",
    "  s = df[column]\n",
    "  grouped = s.groupby(s)\n",
    "  print(f'Column: {column}')\n",
    "  print('='*20)\n",
    "  _dict = {}\n",
    "  for key in grouped.groups.keys():\n",
    "    _count = grouped.get_group(key).count()\n",
    "    _dict[key] = _count\n",
    "  \n",
    "  # sort items and counts in the column in reverse order \n",
    "  _dict = dict(sorted(_dict.items(), reverse = True, key=lambda item: item[1]))\n",
    "  for k, v in _dict.items():\n",
    "      print(f'{k:<45}{v:10,.0f}')\n",
    "  print('='*20, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows have one or more valid inputs in columns: WT01, WT02, WT08'\n",
    "_df = df[['WT01', 'WT02', 'WT08']]\n",
    "_idx = _df.index[_df.notnull().any(axis=1)]\n",
    "_df_notnull = _df.iloc[_idx]\n",
    "print(f'{_df_notnull.shape[0]} rows have one or more valid inputs in columns: WT01, WT02, WT08')\n",
    "print(f'_df_notnull.shape: {_df_notnull.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
