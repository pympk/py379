{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"C:/Users/ping/MyDrive/py_files/python/py379/\")\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "INPUT_DIR = 'C:/Users/ping/OneDrive/Documents/jenn_bb_sales'\n",
    "path_pickle_dump = f'{INPUT_DIR}/'\n",
    "\n",
    "pd.set_option('max_colwidth', 12, 'display.max_columns', 18, 'display.width', 1200, 'display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (18366, 27)\n"
     ]
    }
   ],
   "source": [
    "# read Square csv and pickle df\n",
    "df1 = pd.read_csv(f'{INPUT_DIR}/items-2021-02-01-2021-10-02.csv')\n",
    "df2 = pd.read_csv(f'{INPUT_DIR}/items-2021-09-06-2022-09-07.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "df = df.drop_duplicates()  # drop overlap between the 2 csv files\n",
    "# df.sort_values(by=['Date', 'Time'])\n",
    "# df.reset_index(drop=True)  # create new index\n",
    "df = df.sort_values(by=['Date', 'Time'])\n",
    "df = df.reset_index(drop=True)  # create new index\n",
    "pickle_dump(df, path_pickle_dump, 'df_sq_download')\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los Angeles temperature and precipitation data\n",
    "# https://www.ncei.noaa.gov/cdo-web/datatools/findstation\n",
    "\n",
    "df_weather = pd.read_csv(f'{INPUT_DIR}/la_weather_2021-01-01_2022-09-28.csv')\n",
    "# df_weather = pd.read_csv(f'{INPUT_DIR}/la_temp.csv')\n",
    "\n",
    "df_weather = df_weather.set_index(\"DATE\")\n",
    "# df_weather = df_weather.set_index(\"Date\")\n",
    "\n",
    "df_weather.index = pd.to_datetime(df_weather.index)  # change index to datetime before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df = pickle_load(path_pickle_dump, 'df_sq_download')\n",
    "df_shape_before_clean = df.shape\n",
    "# select only these columns\n",
    "df = df[['Date', 'Time', 'Category', 'Item', 'Qty',\n",
    "       'Price Point Name', 'Gross Sales',\n",
    "       'Discounts', 'Net Sales', 'Tax', \n",
    "       'Device Name', 'Notes', 'Event Type', \n",
    "       'Dining Option', 'Customer Name']]\n",
    "# strip leading $, convert from object to float\n",
    "cols_to_clean = ['Gross Sales', 'Discounts', 'Net Sales', 'Tax']\n",
    "for col in cols_to_clean:\n",
    "  df[col] = df[col].str.split('$').str[-1]  # strip leading $\n",
    "  df[col] = pd.to_numeric(df[col])  # convert from object to float\n",
    "df = df.set_index('Date')  # set index to Date column\n",
    "df.index = pd.to_datetime(df.index)  # convert Date string to datetime \n",
    "df.Time = pd.to_datetime(df.Time, format= '%H:%M:%S').dt.time  # convert Time string to hour:minute:second\n",
    "# remove whole sale customer \"Canyon Coffee\" \"Canyon Coffee\"\n",
    "print(f'df.shape before removing whole sale customer \"Canyon Coffee\": {df.shape}')\n",
    "df = df[df['Customer Name'] != \"Canyon Coffee\"]\n",
    "print(f'df.shape after removing whole sale customer \"Canyon Coffee\":  {df.shape}')\n",
    "df_shape_after_clean = df.shape\n",
    "pickle_dump(df, path_pickle_dump, 'df_clean')\n",
    "print(f'df.shape before clean:  {df_shape_before_clean}')\n",
    "print(f'df.shape after clean:   {df_shape_after_clean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_load(path_pickle_dump, 'df_clean')\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time of fist row, hour: {df.head(1).Time[0].hour}, minute: {df.head(1).Time[0].minute}, second: {df.head(1).Time[0].second}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum daily sales into a series\n",
    "gross = df.groupby('Date')['Gross Sales'].sum()\n",
    "# convert series into dataframe\n",
    "df_gross = pd.DataFrame(gross)\n",
    "df_gross.index = pd.to_datetime(df_gross.index)  # change index to datetime before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los Angeles temperature and precipitation data\n",
    "# https://www.ncei.noaa.gov/cdo-web/datatools/findstation\n",
    "df_weather = pd.read_csv(f'{INPUT_DIR}/la_temp.csv')\n",
    "df_weather = df_weather.set_index(\"Date\")\n",
    "df_weather.index = pd.to_datetime(df_weather.index)  # change index to datetime before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate columns of df_gross and df_weather using inner join\n",
    "df_grSales_weather = pd.concat([df_gross, df_weather], axis=1, join='inner')\n",
    "df_grSales_weather['DoW'] = \\\n",
    "  df_grSales_weather['DoW'].replace(to_replace=['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'], value=[0, 1, 2, 3, 4, 5, 6])\n",
    "pickle_dump(df_grSales_weather, path_pickle_dump, 'df_grSales_weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grSales_weather = pickle_load(path_pickle_dump, 'df_grSales_weather')\n",
    "df_grSales_weather"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
