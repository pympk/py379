{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"C:/Users/ping/MyDrive/py_files/python/py379/\")\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('max_colwidth', 12, 'display.max_columns', 18, 'display.width', 1200, 'display.max_rows',100)\n",
    "INPUT_DIR = 'C:/Users/ping/OneDrive/Documents/jenn_bb_sales'\n",
    "path_pickle_dump = f'{INPUT_DIR}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (18366, 27)\n"
     ]
    }
   ],
   "source": [
    "# read Square csv and pickle df\n",
    "df1 = pd.read_csv(f'{INPUT_DIR}/items-2021-02-01-2021-10-02.csv')\n",
    "df2 = pd.read_csv(f'{INPUT_DIR}/items-2021-09-06-2022-09-07.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "df = df.drop_duplicates()  # drop overlap between the 2 csv files\n",
    "df = df.sort_values(by=['Date', 'Time'])\n",
    "df = df.reset_index(drop=True)  # create new index\n",
    "pickle_dump(df, path_pickle_dump, 'df_sq_download')\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape before removing whole sale customer \"Canyon Coffee\": (18366, 14)\n",
      "df.shape after removing whole sale customer \"Canyon Coffee\":  (18364, 14)\n",
      "df.shape before clean:  (18366, 27)\n",
      "df.shape after clean:   (18364, 14)\n"
     ]
    }
   ],
   "source": [
    "# clean data\n",
    "df = pickle_load(path_pickle_dump, 'df_sq_download')\n",
    "df_shape_before_clean = df.shape\n",
    "# select only these columns\n",
    "df = df[['Date', 'Time', 'Category', 'Item', 'Qty',\n",
    "       'Price Point Name', 'Gross Sales',\n",
    "       'Discounts', 'Net Sales', 'Tax', \n",
    "       'Device Name', 'Notes', 'Event Type', \n",
    "       'Dining Option', 'Customer Name']]\n",
    "# strip leading $, convert from object to float\n",
    "cols_to_clean = ['Gross Sales', 'Discounts', 'Net Sales', 'Tax']\n",
    "for col in cols_to_clean:\n",
    "  df[col] = df[col].str.split('$').str[-1]  # strip leading $\n",
    "  df[col] = pd.to_numeric(df[col])  # convert from object to float\n",
    "df = df.set_index('Date')  # set index to Date column\n",
    "df.index = pd.to_datetime(df.index)  # convert Date string to datetime \n",
    "df.Time = pd.to_datetime(df.Time, format= '%H:%M:%S').dt.time  # convert Time string to hour:minute:second\n",
    "# remove whole sale customer \"Canyon Coffee\" \"Canyon Coffee\"\n",
    "print(f'df.shape before removing whole sale customer \"Canyon Coffee\": {df.shape}')\n",
    "df = df[df['Customer Name'] != \"Canyon Coffee\"]\n",
    "print(f'df.shape after removing whole sale customer \"Canyon Coffee\":  {df.shape}')\n",
    "df_shape_after_clean = df.shape\n",
    "pickle_dump(df, path_pickle_dump, 'df_clean')\n",
    "print(f'df.shape before clean:  {df_shape_before_clean}')\n",
    "print(f'df.shape after clean:   {df_shape_after_clean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (18364, 14)\n"
     ]
    }
   ],
   "source": [
    "df = pickle_load(path_pickle_dump, 'df_clean')\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fist row, hour: 17, minute: 31, second: 7\n"
     ]
    }
   ],
   "source": [
    "print(f'Time of fist row, hour: {df.head(1).Time[0].hour}, minute: {df.head(1).Time[0].minute}, second: {df.head(1).Time[0].second}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum daily sales into a series\n",
    "gross = df.groupby('Date')['Gross Sales'].sum()\n",
    "# convert series into dataframe\n",
    "df_gross = pd.DataFrame(gross)\n",
    "df_gross.index = pd.to_datetime(df_gross.index)  # change index to datetime before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gross Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-08</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09</th>\n",
       "      <td>859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-10</th>\n",
       "      <td>1205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-16</th>\n",
       "      <td>847.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-17</th>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>935.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-03</th>\n",
       "      <td>589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-04</th>\n",
       "      <td>668.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gross Sales\n",
       "Date                   \n",
       "2021-07-08         30.0\n",
       "2021-07-09        859.0\n",
       "2021-07-10       1205.0\n",
       "2021-07-16        847.0\n",
       "2021-07-17       1026.0\n",
       "...                 ...\n",
       "2022-08-21        935.5\n",
       "2022-09-01         64.0\n",
       "2022-09-02        400.0\n",
       "2022-09-03        589.0\n",
       "2022-09-04        668.0\n",
       "\n",
       "[186 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los Angeles temperature and precipitation data\n",
    "# https://www.ncei.noaa.gov/cdo-web/datatools/findstation\n",
    "\n",
    "df_weather = pd.read_csv(f'{INPUT_DIR}/la_weather_2021-01-01_2022-09-28.csv')\n",
    "df_weather = df_weather.set_index(\"DATE\")\n",
    "df_weather.index = pd.to_datetime(df_weather.index)  # change index to datetime before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate columns of df_gross and df_weather using inner join\n",
    "df_grSales_weather = pd.concat([df_gross, df_weather], axis=1, join='inner')\n",
    "df_grSales_weather['DOW'] = \\\n",
    "  df_grSales_weather['DOW'].replace(to_replace=['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'], value=[0, 1, 2, 3, 4, 5, 6])\n",
    "pickle_dump(df_grSales_weather, path_pickle_dump, 'df_grSales_weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gross Sales</th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PGTM</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>WDF2</th>\n",
       "      <th>WDF5</th>\n",
       "      <th>WSF2</th>\n",
       "      <th>WSF5</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT08</th>\n",
       "      <th>DOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-08</th>\n",
       "      <td>30.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09</th>\n",
       "      <td>859.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-10</th>\n",
       "      <td>1205.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-16</th>\n",
       "      <td>847.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>67</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-17</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>2.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>935.5</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>64.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>280.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>400.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-03</th>\n",
       "      <td>589.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>75</td>\n",
       "      <td>280.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-04</th>\n",
       "      <td>668.0</td>\n",
       "      <td>USW00093134</td>\n",
       "      <td>LOS ANGE...</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>77</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gross Sales      STATION         NAME  AWND  PGTM  PRCP  TAVG  TMAX  TMIN   WDF2   WDF5  WSF2  WSF5  WT01  WT02  WT08  DOW\n",
       "2021-07-08         30.0  USW00093134  LOS ANGE...  1.34   NaN   0.0   NaN    84    68  270.0  270.0   8.1  12.1   NaN   NaN   NaN    4\n",
       "2021-07-09        859.0  USW00093134  LOS ANGE...  1.12   NaN   0.0   NaN    86    68  270.0  270.0   8.9  14.1   NaN   NaN   NaN    5\n",
       "2021-07-10       1205.0  USW00093134  LOS ANGE...  1.57   NaN   0.0   NaN    85    69  270.0  270.0   8.1  14.1   NaN   NaN   NaN    6\n",
       "2021-07-16        847.0  USW00093134  LOS ANGE...  1.79   NaN   0.0   NaN    82    67  270.0  260.0   8.1  15.0   NaN   NaN   1.0    5\n",
       "2021-07-17       1026.0  USW00093134  LOS ANGE...  2.01   NaN   0.0   NaN    85    66  260.0  260.0   8.9  15.0   NaN   NaN   NaN    6\n",
       "...                 ...          ...          ...   ...   ...   ...   ...   ...   ...    ...    ...   ...   ...   ...   ...   ...  ...\n",
       "2022-08-21        935.5  USW00093134  LOS ANGE...  1.12   NaN   0.0   NaN    80    65  270.0  260.0   8.1  14.1   NaN   NaN   1.0    0\n",
       "2022-09-01         64.0  USW00093134  LOS ANGE...  1.34   NaN   0.0   NaN    96    74  280.0  270.0   6.9  11.0   NaN   NaN   1.0    4\n",
       "2022-09-02        400.0  USW00093134  LOS ANGE...  1.34   NaN   0.0   NaN    96    72  270.0  260.0   8.1  13.0   NaN   NaN   NaN    5\n",
       "2022-09-03        589.0  USW00093134  LOS ANGE...  1.12   NaN   0.0   NaN    98    75  280.0  280.0   8.9  14.1   NaN   NaN   NaN    6\n",
       "2022-09-04        668.0  USW00093134  LOS ANGE...  1.12   NaN   0.0   NaN   103    77  260.0  260.0   8.1  13.0   NaN   NaN   NaN    0\n",
       "\n",
       "[186 rows x 17 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grSales_weather = pickle_load(path_pickle_dump, 'df_grSales_weather')\n",
    "df_grSales_weather"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
