{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"C:/Users/ping/MyDrive/py_files/python/py379/\")\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "path_pickle_dump = 'C:/Users/ping/OneDrive/Documents/jenn_bb_sales/'\n",
    "pd.set_option('max_colwidth', 12, 'display.max_columns', 18, 'display.width', 1200, 'display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read Square csv and pickle df\n",
    "# df1 = pd.read_csv('C:/Users/ping/OneDrive/Documents/jenn_bb_sales/items-2021-02-01-2021-10-02.csv')\n",
    "# df2 = pd.read_csv('C:/Users/ping/OneDrive/Documents/jenn_bb_sales/items-2021-09-06-2022-09-07.csv')\n",
    "# df = pd.concat([df1, df2])\n",
    "# df = df.drop_duplicates()  # drop overlap between the 2 csv files\n",
    "# # df.sort_values(by=['Date', 'Time'])\n",
    "# # df.reset_index(drop=True)  # create new index\n",
    "# df = df.sort_values(by=['Date', 'Time'])\n",
    "# df = df.reset_index(drop=True)  # create new index\n",
    "# pickle_dump(df, path_pickle_dump, 'df_sq_download')\n",
    "# print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean data\n",
    "# df = pickle_load(path_pickle_dump, 'df_sq_download')\n",
    "# df_shape_before_clean = df.shape\n",
    "# # select only these columns\n",
    "# df = df[['Date', 'Time', 'Category', 'Item', 'Qty',\n",
    "#        'Price Point Name', 'Gross Sales',\n",
    "#        'Discounts', 'Net Sales', 'Tax', \n",
    "#        'Device Name', 'Notes', 'Event Type', \n",
    "#        'Dining Option', 'Customer Name']]\n",
    "# # strip leading $, convert from object to float\n",
    "# cols_to_clean = ['Gross Sales', 'Discounts', 'Net Sales', 'Tax']\n",
    "# for col in cols_to_clean:\n",
    "#   df[col] = df[col].str.split('$').str[-1]  # strip leading $\n",
    "#   df[col] = pd.to_numeric(df[col])  # convert from object to float\n",
    "# df = df.set_index('Date')  # set index to Date column\n",
    "# df.index = pd.to_datetime(df.index)  # convert Date string to datetime \n",
    "# df.Time = pd.to_datetime(df.Time, format= '%H:%M:%S').dt.time  # convert Time string to hour:minute:second\n",
    "# # remove whole sale customer \"Canyon Coffee\" \"Canyon Coffee\"\n",
    "# print(f'df.shape before removing whole sale customer \"Canyon Coffee\": {df.shape}')\n",
    "# df = df[df['Customer Name'] != \"Canyon Coffee\"]\n",
    "# print(f'df.shape after removing whole sale customer \"Canyon Coffee\":  {df.shape}')\n",
    "# df_shape_after_clean = df.shape\n",
    "# pickle_dump(df, path_pickle_dump, 'df_clean')\n",
    "# print(f'df.shape before clean:  {df_shape_before_clean}')\n",
    "# print(f'df.shape after clean:   {df_shape_after_clean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pickle_load(path_pickle_dump, 'df_clean')\n",
    "# print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Time of fist row, hour: {df.head(1).Time[0].hour}, minute: {df.head(1).Time[0].minute}, second: {df.head(1).Time[0].second}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sum daily sales into a series\n",
    "# gross = df.groupby('Date')['Gross Sales'].sum()\n",
    "# # convert series into dataframe\n",
    "# df_gross = pd.DataFrame(gross)\n",
    "# df_gross.index = pd.to_datetime(df_gross.index)  # change index to datetime before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Los Angeles temperature and precipitation data\n",
    "# # https://www.ncei.noaa.gov/cdo-web/datatools/findstation\n",
    "# df_weather = pd.read_csv('C:/Users/ping/OneDrive/Documents/jenn_bb_sales/la_temp.csv')\n",
    "# df_weather = df_weather.set_index(\"Date\")\n",
    "# df_weather.index = pd.to_datetime(df_weather.index)  # change index to datetime before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # concatenate columns of df_gross and df_weather using inner join\n",
    "# df_grSales_weather = pd.concat([df_gross, df_weather], axis=1, join='inner')\n",
    "# df_grSales_weather['DoW'] = \\\n",
    "#   df_grSales_weather['DoW'].replace(to_replace=['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'], value=[0, 1, 2, 3, 4, 5, 6])\n",
    "# pickle_dump(df_grSales_weather, path_pickle_dump, 'df_grSales_weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gross Sales</th>\n",
       "      <th>Prcp</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>DoW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-08</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09</th>\n",
       "      <td>859.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-10</th>\n",
       "      <td>1205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-16</th>\n",
       "      <td>847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-17</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-20</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>935.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-03</th>\n",
       "      <td>589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gross Sales  Prcp  Tmax  DoW\n",
       "Date                                    \n",
       "2021-07-08         30.0   0.0    84    4\n",
       "2021-07-09        859.0   0.0    86    5\n",
       "2021-07-10       1205.0   0.0    85    6\n",
       "2021-07-16        847.0   0.0    82    5\n",
       "2021-07-17       1026.0   0.0    85    6\n",
       "...                 ...   ...   ...  ...\n",
       "2022-08-20        768.0   0.0    82    6\n",
       "2022-08-21        935.5   0.0    80    0\n",
       "2022-09-01         64.0   0.0    96    4\n",
       "2022-09-02        400.0   0.0    96    5\n",
       "2022-09-03        589.0   0.0    98    6\n",
       "\n",
       "[185 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grSales_weather = pickle_load(path_pickle_dump, 'df_grSales_weather')\n",
    "df_grSales_weather"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
