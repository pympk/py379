{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adjOHLCV has data only for NYSE trading days, no weekend data\n",
    "# df_adjOHLCV includes data for weekends when BTC trades\n",
    "# read symbols in file to list syms_in_file\n",
    "# download OHLCV data for symbols in syms_in_file\n",
    "# drop symbols with all NaN in OHLCV columns from df\n",
    "# rename column names from ['Open', ..., 'Volume'] to ['open', ..., 'volume']\n",
    "# drop weekend data by reindex to date index of index_symbol\n",
    "# pickled df_adjOHLCV\n",
    "# pickled df_adjOHLCV\n",
    "# pickled symbols_df_adjOHLCV\n",
    "# create df_symbols_close, sort df by symbols\n",
    "# pickled df_symbols_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67690778/how-to-detect-failed-downloads-using-yfinance\n",
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to adjust OHLCV\n",
    "# https://github.com/ranaroussi/yfinance/issues/687\n",
    "def auto_adjust(data):\n",
    "    df = data.copy()\n",
    "    ratio = df[\"Close\"] / df[\"Adj Close\"]\n",
    "    df[\"Adj Open\"] = df[\"Open\"] / ratio\n",
    "    df[\"Adj High\"] = df[\"High\"] / ratio\n",
    "    df[\"Adj Low\"] = df[\"Low\"] / ratio\n",
    "\n",
    "    df.drop(\n",
    "        [\"Open\", \"High\", \"Low\", \"Close\"],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "    df.rename(columns={\n",
    "        \"Adj Open\": \"Open\", \"Adj High\": \"High\",\n",
    "        \"Adj Low\": \"Low\", \"Adj Close\": \"Close\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # df = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "    return df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "\n",
    "def close_vs_Yahoo (symbols, df):\n",
    "  for symbol in symbols:\n",
    "    s = df.iloc[-250]\n",
    "    \n",
    "    sDate = s.name.strftime('%Y-%m-%d')\n",
    "    sClose = s[symbol].Close\n",
    "\n",
    "    df_sym = yf.Ticker(symbol).history(period='2y')\n",
    "    # 10:45PM got Adj Close\n",
    "    yhClose = df_sym.loc[sDate]['Close']\n",
    "\n",
    "    abs_pct_diff = abs(1 - sClose/yhClose)*100\n",
    "    print(f'symbol:  {symbol:>4}   Date: {sDate:13}df_Close: {sClose:>10.5f} \\\n",
    "    Yahoo_Close: {yhClose:>10.5f}   %_dif_Close: {abs_pct_diff:>7.5f}')\n",
    "    if abs_pct_diff > .0001:\n",
    "      msg_err = f'{symbol}  %_dif_Close > .0001'\n",
    "      # raise SystemExit(msg_err)\n",
    "      print(msg_err)  # even if discrepancy, the relative relationship of OHLCV in df_close matches Yahoo_Close\n",
    "    if symbol == symbols[-1]:\n",
    "      msg_done = f\"No errors found.  Symbols' 'Adjusted Close' matched Yahoo symbols' Close \"\n",
    "      print(msg_done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Full path to pickled df_adjOHLCV:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_adjOHLCV\n",
      "download_last_date: 2022-11-14\n",
      "df_adjOHLCV_last_date: 2022-11-11\n"
     ]
    }
   ],
   "source": [
    "# Stop if last date in df_adjOHLCV is the same as Yahoo download\n",
    "index_symbol = \"XOM\"  \n",
    "df_XOM = yf.download(index_symbol)\n",
    "download_last_date = df_XOM.index[-1].strftime('%Y-%m-%d')\n",
    "print(f\"Full path to pickled df_adjOHLCV:  {path_data_dump}{filename_pickled_df_adjOHLCV}\")\n",
    "print(f'download_last_date: {download_last_date}')\n",
    "df = pickle_load(path_data_dump, filename_pickled_df_adjOHLCV, verbose=verbose)\n",
    "df_adjOHLCV_last_date = df.index[-1].strftime('%Y-%m-%d')\n",
    "print(f'df_adjOHLCV_last_date: {df_adjOHLCV_last_date}')\n",
    "if download_last_date == df_adjOHLCV_last_date:\n",
    "  msg_stop = f\"df_adjOHLCV is up-to-date,\\nlast date from df_adjOHLCV is {df_adjOHLCV_last_date},\\nlast date from Yahoo's {index_symbol} download is {download_last_date}\"\n",
    "  raise SystemExit(msg_stop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "symbol:     A   Date: 2021-11-17   df_Close:  160.51204     Yahoo_Close:  160.51202   %_dif_Close: 0.00001\n",
      "symbol:   LMT   Date: 2021-11-17   df_Close:  332.56610     Yahoo_Close:  332.56607   %_dif_Close: 0.00001\n",
      "symbol:   YUM   Date: 2021-11-17   df_Close:  125.22156     Yahoo_Close:  125.22155   %_dif_Close: 0.00001\n",
      "No errors found.  Symbols' 'Adjusted Close' matched Yahoo symbols' Close \n"
     ]
    }
   ],
   "source": [
    "# verify df test_symbols' close against Yahoo\n",
    "# even if discrepancy, the relative relationship of OHLCV in df_close matches Yahoo_Close\n",
    "test_symbols = ['A', 'LMT', 'YUM']\n",
    "_df_list=[]\n",
    "_df = yf_download_AdjOHLCV_noAutoAdj(test_symbols, verbose=False)\n",
    "_df_list.append(_df)\n",
    "_df = pd.concat(_df_list, axis=1)\n",
    "# get unique symbols from column name\n",
    "_l_symbols = list(set(_df.columns.get_level_values(0)))\n",
    "_l_symbols.sort()\n",
    "\n",
    "_df_adj_list=[]\n",
    "# adjust OHLC using 'Adj Close'\n",
    "for symbol in _l_symbols:\n",
    "  _df1 = auto_adjust(_df[symbol])\n",
    "  _df_adj_list.append(_df1)\n",
    "\n",
    "_df_adj = pd.concat(_df_adj_list, axis=1)\n",
    "_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "# create multilevel column names\n",
    "_col_names = pd.MultiIndex.from_product([_l_symbols, _cols])\n",
    "_df_adj.columns = _col_names\n",
    "\n",
    "close_vs_Yahoo(test_symbols, _df_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read symbols in file to a list and convert to chunks\n",
    "#  each chunk must have more than 1 symbol, otherwise, symbol won't appear as column name\n",
    "symbols_in_file = read_symbols_file(filename_symbols)\n",
    "symbols_chunks = chunked_list(symbols_in_file, 400)  # e.g. [['A', 'BB', ...], ['CC', 'DD', ...], ..., ['Z', 'ZWS', ...]]\n",
    "for chunk in symbols_chunks:\n",
    "  if len(chunk) == 1:\n",
    "    raise SystemExit(f'ERROR, Must be more than 1 symbol in each chunk\\nsymbols in chunk: {chunk}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[]]\n",
      "downloaded symbols from chuck 0, sleep start\n",
      "downloaded symbols from chuck 0, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[], []]\n",
      "downloaded symbols from chuck 1, sleep start\n",
      "downloaded symbols from chuck 1, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[], [], []]\n",
      "downloaded symbols from chuck 2, sleep start\n",
      "downloaded symbols from chuck 2, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[], [], [], []]\n",
      "downloaded symbols from chuck 3, sleep start\n",
      "downloaded symbols from chuck 3, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[], [], [], [], []]\n",
      "downloaded symbols from chuck 4, sleep start\n",
      "downloaded symbols from chuck 4, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[], [], [], [], [], []]\n",
      "downloaded symbols from chuck 5, sleep start\n",
      "downloaded symbols from chuck 5, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[], [], [], [], [], [], []]\n",
      "downloaded symbols from chuck 6, sleep start\n",
      "downloaded symbols from chuck 6, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SFB: No data found for this date range, symbol may be delisted\n",
      "symbols_download_err: [[], [], [], [], [], [], [], ['SFB']]\n",
      "downloaded symbols from chuck 7, sleep start\n",
      "downloaded symbols from chuck 7, sleep ends\n",
      "[*********************100%***********************]  400 of 400 completed\n",
      "symbols_download_err: [[], [], [], [], [], [], [], ['SFB'], []]\n",
      "downloaded symbols from chuck 8, sleep start\n",
      "downloaded symbols from chuck 8, sleep ends\n",
      "[*********************100%***********************]  53 of 53 completed\n",
      "symbols_download_err: [[], [], [], [], [], [], [], ['SFB'], [], []]\n",
      "downloaded symbols from all chucks\n",
      "symbols_download_err: [[], [], [], [], [], [], [], ['SFB'], [], []]\n"
     ]
    }
   ],
   "source": [
    "df_list=[]\n",
    "symbols_download_err = []\n",
    "# took 24 minutes to download 1917 symbols without error caused by Yahoo\n",
    "# for i, symbols in enumerate(symbols_chunks):\n",
    "for i, symbols in enumerate(symbols_chunks):\n",
    "  df = yf_download_AdjOHLCV_noAutoAdj(symbols, verbose=False)  \n",
    "  symbols_download_err.append(list(shared._ERRORS.keys()))\n",
    "  print(f'symbols_download_err: {symbols_download_err}')\n",
    "  df_list.append(df)\n",
    "  # pause between download\n",
    "  if i < len(symbols_chunks) - 1 :  # skip pause after last download\n",
    "    print(f'downloaded symbols from chuck {i}, sleep start')\n",
    "    # sleep 78(18m 25s)\n",
    "    time.sleep(78)\n",
    "    print(f'downloaded symbols from chuck {i}, sleep ends')\n",
    "  else:\n",
    "    print(f'downloaded symbols from all chucks')\n",
    "\n",
    "print(f'symbols_download_err: {symbols_download_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SFB']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten symbols_download_err which is a list-of-lists\n",
    "l_symbols_err = [val for sublist in symbols_download_err for val in sublist]\n",
    "pickle_dump(l_symbols_err, path_data_dump, 'l_symbols_err')\n",
    "l_symbols_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path to pickled df_OHLCVA_downloaded:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_OHLCVA_downloaded \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(df_list, axis=1)\n",
    "df.drop(l_symbols_err, axis=1, level=0, inplace=True)  # drop symbols with errors  \n",
    "l_symbols = list(set(df.columns.get_level_values(0)))  # get unique symbols\n",
    "l_symbols.sort()\n",
    "df = df[l_symbols]  # sort columns by list\n",
    "print(f\"Full path to pickled df_OHLCVA_downloaded:  {path_data_dump}{filename_pickled_df_OHLCVA_downloaded}\")\n",
    "pickle_dump(df, path_data_dump, filename_pickled_df_OHLCVA_downloaded)  # save OHLCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path to pickled df_adjOHLCV:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_adjOHLCV\n"
     ]
    }
   ],
   "source": [
    "# adjust OHLC\n",
    "df_adj_list=[]\n",
    "for symbol in l_symbols:\n",
    "  _df = auto_adjust(df[symbol])\n",
    "  df_adj_list.append(_df)\n",
    "\n",
    "df_adj = pd.concat(df_adj_list, axis=1)\n",
    "cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "col_names = pd.MultiIndex.from_product([l_symbols, cols])  # create multilevel column names\n",
    "df_adj.columns = col_names  # reindex columns\n",
    "\n",
    "print(f\"Full path to pickled df_adjOHLCV:  {path_data_dump}{filename_pickled_df_adjOHLCV}\")\n",
    "pickle_dump(df_adj, path_data_dump, filename_pickled_df_adjOHLCV)  # save adjusted OHLCV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjOHLCV = pickle_load(path_data_dump, filename_pickled_df_adjOHLCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol's OHLCV are all NaN: []\n",
      "symbols with all NaN dropped from df_adjOHLCV: []\n"
     ]
    }
   ],
   "source": [
    "# drop symbols with all NaN in OHLCV columns from df\n",
    "df_adjOHLCV, symbols_OHLCV, symbols_dropped = drop_symbols_all_NaN(df_adjOHLCV, verbose)\n",
    "print(f'symbols with all NaN dropped from df_adjOHLCV: {symbols_dropped}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns OHLCV *ONLY AFTER* dropping symbols with all NaN from df,\n",
    "#   symbols with all NaN has an added AdjClose column and will cause errors  \n",
    "#  rename column names from ['Open', ..., 'Volume'] to ['open', ..., 'volume']\n",
    "#  .remove_unused_levels() prevents ValueError\n",
    "#   e.g ValueError: On level 1, code max (5) >= length of level (5). NOTE: this index is in an inconsistent state\n",
    "# The error may be caused by removing symbols from the dataframe with all NaN in OHLCV columns\n",
    "df_adjOHLCV.columns = df_adjOHLCV.columns.remove_unused_levels()\n",
    "# # set_levels reorders df columns in alphabetical order, so the list of column names also needs to be in alphabetical order\n",
    "# df_adjOHLCV.columns = df_adjOHLCV.columns.set_levels(['close', 'high', 'low', 'open', 'volume'], level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop weekend data by re-indexing to date-index of index_symbol\n",
    "myNaN = float('nan')\n",
    "# use Exxon's date as proxy for NYSE trading dates\n",
    "df_adjOHLCV = df_adjOHLCV.reindex(df_XOM.index, fill_value=myNaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path to pickled df_adjOHLCV:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_adjOHLCV\n",
      "Full path to pickled symbols_df_adjOHLCV:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/symbols_df_adjOHLCV\n"
     ]
    }
   ],
   "source": [
    "# pickle df_adjOHLCV and symbols\n",
    "# print(f\"Full path to pickled df_adjOHLCV_downloaded:  {path_data_dump}{filename_pickled_df_adjOHLCV_downloaded}\")\n",
    "# pickle_dump(df_adjOHLCV_downloaded, path_data_dump, filename_pickled_df_adjOHLCV_downloaded, verbose=verbose)\n",
    "print(f\"Full path to pickled df_adjOHLCV:  {path_data_dump}{filename_pickled_df_adjOHLCV}\")\n",
    "pickle_dump(df_adjOHLCV, path_data_dump, filename_pickled_df_adjOHLCV, verbose=verbose)\n",
    "print(f\"Full path to pickled symbols_df_adjOHLCV:  {path_data_dump}{filename_pickled_symbols_df_adjOHLCV}\")\n",
    "pickle_dump(symbols_OHLCV, path_data_dump, filename_pickled_symbols_df_adjOHLCV, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_OHLCV = list(set([i[0] for i in list(df_adjOHLCV)]))\n",
    "df_symbols_close = df_adjOHLCV.xs('Close', level=1, axis=1)\n",
    "pickle_dump(df_symbols_close, path_data_dump, filename_pickled_df_symbols_close, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path to pickled df_OHLCVA_downloaded:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_OHLCVA_downloaded \n",
      "Full path to pickled df_adjOHLCV:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_adjOHLCV\n",
      "Full path to pickled df_symbols_close:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_symbols_close\n",
      "Full path to pickled symbols_df_adjOHLCV:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/symbols_df_adjOHLCV\n"
     ]
    }
   ],
   "source": [
    "# retrieve pickled files\n",
    "\n",
    "print(f\"Full path to pickled df_OHLCVA_downloaded:  {path_data_dump}{filename_pickled_df_OHLCVA_downloaded}\")\n",
    "df_OHLCVA_downloaded = pickle_load(path_data_dump, filename_pickled_df_OHLCVA_downloaded, verbose=verbose)\n",
    "\n",
    "print(f\"Full path to pickled df_adjOHLCV:  {path_data_dump}{filename_pickled_df_adjOHLCV}\")\n",
    "df_adjOHLCV = pickle_load(path_data_dump, filename_pickled_df_adjOHLCV, verbose=verbose)\n",
    "\n",
    "print(f\"Full path to pickled df_symbols_close:  {path_data_dump}{filename_pickled_df_symbols_close}\")\n",
    "df_close = pickle_load(path_data_dump, filename_pickled_df_symbols_close, verbose=verbose)\n",
    "\n",
    "print(f\"Full path to pickled symbols_df_adjOHLCV:  {path_data_dump}{filename_pickled_symbols_df_adjOHLCV}\")\n",
    "symbols_df = pickle_load(path_data_dump, filename_pickled_symbols_df_adjOHLCV, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15324 entries, 1962-01-02 to 2022-11-14\n",
      "Columns: 21912 entries, ('A', 'Open') to ('ZWS', 'Volume')\n",
      "dtypes: float64(21888), int64(24)\n",
      "memory usage: 2.5 GB\n",
      "df_OHLCVA_downloaded.info():\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15324 entries, 1962-01-02 to 2022-11-14\n",
      "Columns: 18260 entries, ('A', 'Open') to ('ZWS', 'Volume')\n",
      "dtypes: float64(18236), int64(24)\n",
      "memory usage: 2.1 GB\n",
      "df_adjOHLCV.info():\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15324 entries, 1962-01-02 to 2022-11-14\n",
      "Columns: 3652 entries, A to ZWS\n",
      "dtypes: float64(3652)\n",
      "memory usage: 427.1 MB\n",
      "df_close.info():\n",
      "None\n",
      "\n",
      "len(symbols_df):\n",
      "3652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'df_OHLCVA_downloaded.info():\\n{df_OHLCVA_downloaded.info()}\\n')\n",
    "print(f'df_adjOHLCV.info():\\n{df_adjOHLCV.info()}\\n')\n",
    "print(f'df_close.info():\\n{df_close.info()}\\n')\n",
    "print(f'len(symbols_df):\\n{len(symbols_df)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error found, Column counts in df_close, df_OHLCVA, df_adjOHLCV matched symbol count\n"
     ]
    }
   ],
   "source": [
    "count_symbols = len(symbols_df)\n",
    "count_df_close_cols = len(df_close.columns)\n",
    "count_cols_df_OHLCVA_downloaded = len(df_OHLCVA_downloaded.columns)\n",
    "count_cols_df_adjOHLCV = len(df_adjOHLCV.columns)\n",
    "if count_symbols != count_df_close_cols:\n",
    "  raise SystemExit(f'symbol count: {count_symbols} does not equal df_close column count: {count_df_close_cols}')\n",
    "if count_symbols * 6 != count_cols_df_OHLCVA_downloaded:\n",
    "  raise SystemExit(f'6 x symbol count: {6 * count_symbols} does not equal df_OHLCVA_downloaded column count: {count_cols_df_OHLCVA_downloaded}')\n",
    "if count_symbols * 5 != count_cols_df_adjOHLCV:\n",
    "  raise SystemExit(f'5 x symbol count: {5 * count_symbols} does not equal df_adjOHLCV column count: {count_cols_df_adjOHLCV}')\n",
    "print(f'No error found, Column counts in df_close, df_OHLCVA, df_adjOHLCV matched symbol count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_symbols: 3652\n",
      "count_df_close_cols: 3652\n",
      "count_cols_df_OHLCVA_downloaded: 21912\n",
      "count_cols_df_adjOHLCV: 18260\n"
     ]
    }
   ],
   "source": [
    "print(f'count_symbols: {count_symbols}')\n",
    "print(f'count_df_close_cols: {count_df_close_cols}')\n",
    "print(f'count_cols_df_OHLCVA_downloaded: {count_cols_df_OHLCVA_downloaded}')\n",
    "print(f'count_cols_df_adjOHLCV: {count_cols_df_adjOHLCV}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol:     A   Date: 2021-11-17   df_Close:  160.51202     Yahoo_Close:  161.32751   %_dif_Close: 0.50549\n",
      "A  %_dif_Close > .0001\n",
      "symbol:   LMT   Date: 2021-11-17   df_Close:  336.86447     Yahoo_Close:  332.56604   %_dif_Close: 1.29250\n",
      "LMT  %_dif_Close > .0001\n",
      "symbol:   YUM   Date: 2021-11-17   df_Close:  126.45914     Yahoo_Close:  125.22155   %_dif_Close: 0.98832\n",
      "YUM  %_dif_Close > .0001\n",
      "No errors found.  Symbols' 'Adjusted Close' matched Yahoo symbols' Close \n"
     ]
    }
   ],
   "source": [
    "close_vs_Yahoo(test_symbols, df_adjOHLCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-15</th>\n",
       "      <td>161.250000</td>\n",
       "      <td>162.330002</td>\n",
       "      <td>157.500000</td>\n",
       "      <td>157.779999</td>\n",
       "      <td>156.775970</td>\n",
       "      <td>1121300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-16</th>\n",
       "      <td>157.050003</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>156.960007</td>\n",
       "      <td>161.389999</td>\n",
       "      <td>160.362976</td>\n",
       "      <td>1276300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-17</th>\n",
       "      <td>161.919998</td>\n",
       "      <td>161.919998</td>\n",
       "      <td>159.899994</td>\n",
       "      <td>161.539993</td>\n",
       "      <td>160.512024</td>\n",
       "      <td>872400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18</th>\n",
       "      <td>162.529999</td>\n",
       "      <td>162.820007</td>\n",
       "      <td>160.399994</td>\n",
       "      <td>162.160004</td>\n",
       "      <td>161.128082</td>\n",
       "      <td>1475800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2021-11-15  161.250000  162.330002  157.500000  157.779999  156.775970   \n",
       "2021-11-16  157.050003  163.000000  156.960007  161.389999  160.362976   \n",
       "2021-11-17  161.919998  161.919998  159.899994  161.539993  160.512024   \n",
       "2021-11-18  162.529999  162.820007  160.399994  162.160004  161.128082   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2021-11-15  1121300.0  \n",
       "2021-11-16  1276300.0  \n",
       "2021-11-17   872400.0  \n",
       "2021-11-18  1475800.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sym = 'A'\n",
    "s_start, s_end = -252, -248\n",
    "df_adjOHLCV[_sym].iloc[s_start:s_end]\n",
    "df_OHLCVA_downloaded[_sym].iloc[s_start:s_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">A</th>\n",
       "      <th colspan=\"5\" halign=\"left\">AA</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ZUMZ</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ZWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-08</th>\n",
       "      <td>138.500000</td>\n",
       "      <td>140.690002</td>\n",
       "      <td>136.600006</td>\n",
       "      <td>138.750000</td>\n",
       "      <td>1028100.0</td>\n",
       "      <td>42.180000</td>\n",
       "      <td>43.384998</td>\n",
       "      <td>41.459999</td>\n",
       "      <td>43.230000</td>\n",
       "      <td>4740200</td>\n",
       "      <td>...</td>\n",
       "      <td>22.870001</td>\n",
       "      <td>23.360001</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>22.469999</td>\n",
       "      <td>311800.0</td>\n",
       "      <td>23.17</td>\n",
       "      <td>23.209999</td>\n",
       "      <td>22.340000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>2154600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-09</th>\n",
       "      <td>138.309998</td>\n",
       "      <td>139.419998</td>\n",
       "      <td>136.660004</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>971200.0</td>\n",
       "      <td>42.529999</td>\n",
       "      <td>42.744999</td>\n",
       "      <td>40.340000</td>\n",
       "      <td>40.680000</td>\n",
       "      <td>4181200</td>\n",
       "      <td>...</td>\n",
       "      <td>22.360001</td>\n",
       "      <td>22.430000</td>\n",
       "      <td>20.639999</td>\n",
       "      <td>20.780001</td>\n",
       "      <td>239800.0</td>\n",
       "      <td>22.26</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>1013200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10</th>\n",
       "      <td>142.869995</td>\n",
       "      <td>146.720001</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>146.300003</td>\n",
       "      <td>1591900.0</td>\n",
       "      <td>42.810001</td>\n",
       "      <td>45.490002</td>\n",
       "      <td>42.810001</td>\n",
       "      <td>43.830002</td>\n",
       "      <td>8201900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.830000</td>\n",
       "      <td>23.690001</td>\n",
       "      <td>21.780001</td>\n",
       "      <td>23.510000</td>\n",
       "      <td>327600.0</td>\n",
       "      <td>22.92</td>\n",
       "      <td>23.910000</td>\n",
       "      <td>22.690001</td>\n",
       "      <td>23.440001</td>\n",
       "      <td>2877700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-11</th>\n",
       "      <td>147.119995</td>\n",
       "      <td>149.740005</td>\n",
       "      <td>146.350006</td>\n",
       "      <td>148.309998</td>\n",
       "      <td>1227500.0</td>\n",
       "      <td>45.259998</td>\n",
       "      <td>50.759998</td>\n",
       "      <td>45.040001</td>\n",
       "      <td>47.660000</td>\n",
       "      <td>18064800</td>\n",
       "      <td>...</td>\n",
       "      <td>23.770000</td>\n",
       "      <td>24.620001</td>\n",
       "      <td>23.670000</td>\n",
       "      <td>24.280001</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>23.59</td>\n",
       "      <td>24.480000</td>\n",
       "      <td>23.549999</td>\n",
       "      <td>24.200001</td>\n",
       "      <td>1534600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14</th>\n",
       "      <td>149.009995</td>\n",
       "      <td>149.710007</td>\n",
       "      <td>146.300003</td>\n",
       "      <td>146.380005</td>\n",
       "      <td>1173955.0</td>\n",
       "      <td>46.549999</td>\n",
       "      <td>49.049999</td>\n",
       "      <td>46.400002</td>\n",
       "      <td>48.220001</td>\n",
       "      <td>6518813</td>\n",
       "      <td>...</td>\n",
       "      <td>23.930000</td>\n",
       "      <td>24.180000</td>\n",
       "      <td>23.670000</td>\n",
       "      <td>23.709999</td>\n",
       "      <td>235246.0</td>\n",
       "      <td>24.07</td>\n",
       "      <td>24.230000</td>\n",
       "      <td>23.764999</td>\n",
       "      <td>23.809999</td>\n",
       "      <td>1018519.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A                                                 \\\n",
       "                  Open        High         Low       Close     Volume   \n",
       "Date                                                                    \n",
       "2022-11-08  138.500000  140.690002  136.600006  138.750000  1028100.0   \n",
       "2022-11-09  138.309998  139.419998  136.660004  137.000000   971200.0   \n",
       "2022-11-10  142.869995  146.720001  142.529999  146.300003  1591900.0   \n",
       "2022-11-11  147.119995  149.740005  146.350006  148.309998  1227500.0   \n",
       "2022-11-14  149.009995  149.710007  146.300003  146.380005  1173955.0   \n",
       "\n",
       "                   AA                                             ...  \\\n",
       "                 Open       High        Low      Close    Volume  ...   \n",
       "Date                                                              ...   \n",
       "2022-11-08  42.180000  43.384998  41.459999  43.230000   4740200  ...   \n",
       "2022-11-09  42.529999  42.744999  40.340000  40.680000   4181200  ...   \n",
       "2022-11-10  42.810001  45.490002  42.810001  43.830002   8201900  ...   \n",
       "2022-11-11  45.259998  50.759998  45.040001  47.660000  18064800  ...   \n",
       "2022-11-14  46.549999  49.049999  46.400002  48.220001   6518813  ...   \n",
       "\n",
       "                 ZUMZ                                               ZWS  \\\n",
       "                 Open       High        Low      Close    Volume   Open   \n",
       "Date                                                                      \n",
       "2022-11-08  22.870001  23.360001  22.219999  22.469999  311800.0  23.17   \n",
       "2022-11-09  22.360001  22.430000  20.639999  20.780001  239800.0  22.26   \n",
       "2022-11-10  21.830000  23.690001  21.780001  23.510000  327600.0  22.92   \n",
       "2022-11-11  23.770000  24.620001  23.670000  24.280001  205000.0  23.59   \n",
       "2022-11-14  23.930000  24.180000  23.670000  23.709999  235246.0  24.07   \n",
       "\n",
       "                                                        \n",
       "                 High        Low      Close     Volume  \n",
       "Date                                                    \n",
       "2022-11-08  23.209999  22.340000  22.600000  2154600.0  \n",
       "2022-11-09  22.799999  21.910000  21.980000  1013200.0  \n",
       "2022-11-10  23.910000  22.690001  23.440001  2877700.0  \n",
       "2022-11-11  24.480000  23.549999  24.200001  1534600.0  \n",
       "2022-11-14  24.230000  23.764999  23.809999  1018519.0  \n",
       "\n",
       "[5 rows x 18260 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjOHLCV.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
