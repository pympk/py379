{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_OHLCV has data only for NYSE trading days, no weekend data\n",
    "# df_OHLCV_all_dates includes data for weekends when BTC trades\n",
    "# read symbols in file to list syms_in_file\n",
    "# download OHLCV data for symbols in syms_in_file\n",
    "# drop symbols with all NaN in OHLCV columns from df\n",
    "# rename column names from ['Open', ..., 'Volume'] to ['open', ..., 'volume']\n",
    "# drop weekend data by reindex to date index of index_symbol\n",
    "# pickled df_OHLCV_all_dates\n",
    "# pickled df_OHLCV\n",
    "# pickled symbols_df_OHLCV\n",
    "# create df_symbols_close, sort df by symbols\n",
    "# pickled df_symbols_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import time\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, yf_symbols_close, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV, yf_download_AdjOHLCV_noAutoAdj\n",
    "verbose = False  # True prints more output\n",
    "# verbose = True  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "# filename_symbols = path_data_dump + 'symbols_mktCap_2b.csv'  # symbols text file\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "\n",
    "filename_pickled_df_OHLCV_downloaded = 'df_OHLCV_downloaded'  # pickled filename\n",
    "filename_pickled_df_OHLCV = 'df_OHLCV'  # pickled filename reindexed to NYSE dates\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # pickled filename\n",
    "filename_pickled_symbols_df_OHLCV =  'symbols_df_OHLCV'  # pickled filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stop if Yahoo has not updated OHLCV data\n",
    "# index_symbol = \"XOM\"  \n",
    "# df_XOM = yf.download(index_symbol)\n",
    "# df_last_date = df_XOM.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "# # yesterday = str(date.today() - timedelta(days = 1))\n",
    "# # if yesterday == df_last_date:\n",
    "# print(f'Yahoo data date: {df_last_date}, today: {str(date.today())}, weekday: {now.weekday()}')\n",
    "# now = datetime.now()  # get current date and time\n",
    "# if str(date.today()) == df_last_date and (now.weekday() != 5 or now.weekday() != 6):\n",
    "  \n",
    "#   msg_stop = f'Yahoo has not updated OHLCV data, today: {str(date.today())}, Yahoo download last date: {df_last_date}'\n",
    "#   raise SystemExit(msg_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "\nToo soon to update,\nLast Yahoo XOM download date is Friday 2022-11-04,\nToday is Saturday 2022-11-05,\nDifference between the two dates is: 1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m \nToo soon to update,\nLast Yahoo XOM download date is Friday 2022-11-04,\nToday is Saturday 2022-11-05,\nDifference between the two dates is: 1\n"
     ]
    }
   ],
   "source": [
    "index_symbol = \"XOM\"  \n",
    "df_XOM = yf.download(index_symbol)\n",
    "df_last_date = df_XOM.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "dict_weekday = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "date_last_df_XOM = df_XOM.index[-1].date()\n",
    "wkday_last_df_XOM =dict_weekday[date_last_df_XOM.weekday()]\n",
    "date_now = now.date()\n",
    "wkday_now =dict_weekday[date_now.weekday()]\n",
    "days_diff = (date_now - date_last_df_XOM).days\n",
    "\n",
    "msg_last_df_date = f'Last Yahoo XOM download date is {wkday_last_df_XOM} {date_last_df_XOM}'\n",
    "msg_now_date = f'Today is {wkday_now} {date_now}'\n",
    "msg_err = f'Too soon to update,\\n{msg_last_df_date},\\n{msg_now_date},\\nDifference between the two dates is: {days_diff}'\n",
    "\n",
    "if days_diff == 0:\n",
    "  raise SystemExit(f'\\n{msg_err}')\n",
    "elif days_diff == 1 and wkday_last_df_XOM == 'Friday':\n",
    "  raise SystemExit(f'\\n{msg_err}')\n",
    "elif days_diff == 2 and wkday_last_df_XOM == 'Friday':\n",
    "  raise SystemExit(f'\\n{msg_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stop if df_OHLCV is up to date\n",
    "# print(f\"Full path to pickled df_OHLCV:  {path_data_dump}{filename_pickled_df_OHLCV}\")\n",
    "# df = pickle_load(path_data_dump, filename_pickled_df_OHLCV, verbose=verbose)\n",
    "# df_OHLCV_last_date = df.index[-1].strftime('%Y-%m-%d')\n",
    "# today = str(date.today())\n",
    "# if today == df_OHLCV_last_date:  \n",
    "#   msg_stop = f'df_OHLCV is up to date, today: {today}, df_OHLCV last date: {df_OHLCV_last_date}'\n",
    "#   raise SystemExit(msg_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read symbols in file to a list\n",
    "symbols_in_file = read_symbols_file(filename_symbols)\n",
    "symbols_chunks = chunked_list(symbols_in_file, 400)  # e.g. [['A', 'BB', ...], ['CC', 'DD', ...], ..., ['Z', 'ZWS', ...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "# took 24 minutes to download 1917 symbols without error caused by Yahoo\n",
    "for i, symbols in enumerate(symbols_chunks):\n",
    "  df = yf_download_AdjOHLCV(symbols, verbose=False)\n",
    "  df_list.append(df)\n",
    "  # pause 5 - 15 sec between download\n",
    "  if i < len(symbols_chunks) - 1 :  # skip pause after last download\n",
    "    print(f'downloaded symbols from chuck {i}, sleep start')\n",
    "    # sleep 78(18m 25s), 155, 305 sec to avoid download error from Yahoo\n",
    "    time.sleep(78)\n",
    "    print(f'downloaded symbols from chuck {i}, sleep ends')\n",
    "  else:\n",
    "    print(f'downloaded symbols from all chucks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verify df test_symbols' close against Yahoo\n",
    "# test_symbols = ['A', 'SHEL', 'YUM']\n",
    "# now = datetime.now()  # get current date and time\n",
    "# # if now.hour >= 20:  # only run this test after 8 pm when Yahoo data should be updated\n",
    "# #  run this test after 8 pm or on the weekend when Yahoo data should be updated\n",
    "# if (now.hour >= 20) or now.weekday() == 5 or now.weekday() == 6:\n",
    "#   for symbol in test_symbols:\n",
    "#     s = df.iloc[-222]\n",
    "#     sDate = s.name.strftime('%Y-%m-%d')\n",
    "#     sClose = s[symbol].close\n",
    "#     sClose\n",
    "#     df_sym = yf.Ticker(symbol).history(period='2y')\n",
    "#     yhClose = df_sym.loc[sDate]['Close']\n",
    "#     abs_pct_diff = abs(1 - sClose/yhClose)*100\n",
    "#     print(f'symbol:  {symbol:>4}   Date: {sDate:13}df_Close: {sClose:>10.5f} \\\n",
    "#     Yahoo_Close: {yhClose:>10.5f}   %_dif_Close: {abs_pct_diff:>7.5f}')\n",
    "#     if abs_pct_diff > .0001:\n",
    "#       msg_stop = f'{symbol}  %_dif_Close > .0001'\n",
    "#       raise SystemExit(msg_stop)\n",
    "#     if symbol == test_symbols[-1]:\n",
    "#       msg_done = f\"No errors found.  df test_symbols' Close matched Yahoo symbols' Close \"\n",
    "#       print(msg_done)\n",
    "# else:\n",
    "#   print(f\"Did not verify df test_symbols' close against Yahoo.  It's not 8 PM yet. Yahoo may not have updated their data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Full path to pickled df_OHLCV_downloaded:  {path_data_dump}{filename_pickled_df_OHLCV_downloaded}\")\n",
    "pickle_dump(df, path_data_dump, filename_pickled_df_OHLCV_downloaded, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df by symbol\n",
    "df_OHLCV_all_dates = df.sort_index(axis=1,level=0,sort_remaining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop symbols with all NaN in OHLCV columns from df\n",
    "df_OHLCV_all_dates, symbols_OHLCV, symbols_dropped = drop_symbols_all_NaN(df_OHLCV_all_dates, verbose)\n",
    "# print(f'symbols_OHLCV: {symbols_OHLCV}')\n",
    "print(f'symbols with all NaN dropped from df_OHLCV_all_dates: {symbols_dropped}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns OHLCV *ONLY AFTER* dropping symbols with all NaN from df,\n",
    "#   symbols with all NaN has an added AdjClose column and will cause errors  \n",
    "#  rename column names from ['Open', ..., 'Volume'] to ['open', ..., 'volume']\n",
    "#  .remove_unused_levels() prevents ValueError\n",
    "#   e.g ValueError: On level 1, code max (5) >= length of level (5). NOTE: this index is in an inconsistent state\n",
    "# The error may be caused by removing symbols from the dataframe with all NaN in OHLCV columns\n",
    "df_OHLCV_all_dates.columns = df_OHLCV_all_dates.columns.remove_unused_levels()\n",
    "# set_levels reorders df columns in alphabetical order, so the list of column names also needs to be in alphabetical order\n",
    "df_OHLCV_all_dates.columns = df_OHLCV_all_dates.columns.set_levels(['close', 'high', 'low', 'open', 'volume'], level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop weekend data by re-indexing to date-index of index_symbol\n",
    "myNaN = float('nan')\n",
    "# use Exxon's date as proxy for NYSE trading dates\n",
    "df_OHLCV = df_OHLCV_all_dates.reindex(df_XOM.index, fill_value=myNaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_OHLCV and symbols\n",
    "# print(f\"Full path to pickled df_OHLCV_downloaded:  {path_data_dump}{filename_pickled_df_OHLCV_downloaded}\")\n",
    "# pickle_dump(df_OHLCV_downloaded, path_data_dump, filename_pickled_df_OHLCV_downloaded, verbose=verbose)\n",
    "print(f\"Full path to pickled df_OHLCV:  {path_data_dump}{filename_pickled_df_OHLCV}\")\n",
    "pickle_dump(df_OHLCV, path_data_dump, filename_pickled_df_OHLCV, verbose=verbose)\n",
    "print(f\"Full path to pickled symbols_df_OHLCV:  {path_data_dump}{filename_pickled_symbols_df_OHLCV}\")\n",
    "pickle_dump(symbols_OHLCV, path_data_dump, filename_pickled_symbols_df_OHLCV, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df of symbols' Close, sort df by symbols, pickled df\n",
    "df_symbols_close, dates_dropped, symbols_OHLCV, symbols_dropped = yf_symbols_close(\n",
    "    path_dir,\n",
    "    path_data_dump,\n",
    "    filename_pickled_df_OHLCV,\n",
    "    verbose=verbose,\n",
    ")\n",
    "# multi-index sort df by symbol\n",
    "df_symbols_close = df_symbols_close.sort_index(axis=1,level=0,sort_remaining=False)\n",
    "print(f\"Full path to pickled df_symbols_close:  {path_data_dump}{filename_pickled_df_symbols_close}\")\n",
    "pickle_dump(df_symbols_close, path_data_dump, filename_pickled_df_symbols_close, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve pickled files\n",
    "# print(f\"Full path to pickled df_OHLCV_all_dates:  {path_data_dump}{filename_pickled_df_OHLCV_all_dates}\")\n",
    "# # df_all_dates = pickle_load(path_data_dump, filename_pickled_df_OHLCV_all_dates, verbose=verbose)\n",
    "\n",
    "print(f\"Full path to pickled df_OHLCV_downloaded:  {path_data_dump}{filename_pickled_df_OHLCV_downloaded}\")\n",
    "df_OHLCV_downloaded = pickle_load(path_data_dump, filename_pickled_df_OHLCV_downloaded, verbose=verbose)\n",
    "print(f\"Full path to pickled df_OHLCV:  {path_data_dump}{filename_pickled_df_OHLCV}\")\n",
    "df = pickle_load(path_data_dump, filename_pickled_df_OHLCV, verbose=verbose)\n",
    "print(f\"Full path to pickled symbols_df_OHLCV:  {path_data_dump}{filename_pickled_symbols_df_OHLCV}\")\n",
    "df_close = pickle_load(path_data_dump, filename_pickled_df_symbols_close, verbose=verbose)\n",
    "print(f\"Full path to pickled df_symbols_close:  {path_data_dump}{filename_pickled_df_symbols_close}\")\n",
    "symbols_df = pickle_load(path_data_dump, filename_pickled_symbols_df_OHLCV, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NOC.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OHLCV_downloaded.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
