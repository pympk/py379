{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/346907/splitting-time-series-data-into-train-test-validation-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_slices (df, n_samples, days_lookback, days_eval):\n",
    "#   \"\"\"Pad target_arr with leading numpy.nan to length arr_len.\n",
    "\n",
    "#   Args:\n",
    "#       df(dataframe): dataframe\n",
    "#       n_samples(int): number of slices to return\n",
    "#       days_lookback(int):  number of days to lookback for training\n",
    "#       days_eval(int): number of days to forward for evaluation \n",
    "\n",
    "#   Return:\n",
    "#       r_slices(list of tuples): target_arr padded to length arr_len\n",
    "#   \"\"\"\n",
    "  \n",
    "  \n",
    "#   import random\n",
    "#   from random import randint\n",
    "\n",
    "#   # random.seed(0)  \n",
    "#   n_sample = 0\n",
    "#   days_total = days_lookback + days_eval\n",
    "#   print(f'days_lookback: {days_lookback}, days_eval: {days_eval}, days_total: {days_total}, len(df): {len(df)}')\n",
    "\n",
    "#   if days_total > len(df):\n",
    "#     msg_err = f'days_total: {days_total} must be less or equal to len(df): {len(df)}'\n",
    "#     raise SystemExit(msg_err)\n",
    "\n",
    "#   # random slices of iloc for train and eval that fits the days_lookback, days_eval and total len(df) constraints\n",
    "#   r_slices = []\n",
    "#   while n_sample < n_samples:\n",
    "#     n_rand = randint(0, len(df))    \n",
    "#     start_train = n_rand - days_lookback\n",
    "#     end_train = n_rand\n",
    "#     start_eval = n_rand\n",
    "#     end_eval = n_rand + days_eval\n",
    "#     if 0 <= start_train and end_eval <= len(df):\n",
    "#       r_slices.append((start_train, end_train, end_eval))\n",
    "#       n_sample += 1\n",
    "\n",
    "#   return r_slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from yf_utils import random_slices\n",
    "#create DataFrame\n",
    "df = pd.DataFrame(np.arange(0,1000), columns=list('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slices = random_slices(df, n_samples=100, days_lookback=120, days_eval=20)\n",
    "my_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randint\n",
    "from myUtils import pickle_dump\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 0\n",
    "n_samples = 100\n",
    "days_lookback = 120\n",
    "days_eval = 20\n",
    "days_total = days_lookback + days_eval\n",
    "print(f'days_lookback: {days_lookback}, days_eval: {days_eval}, days_total: {days_total}, len(df): {len(df)}')\n",
    "\n",
    "if days_total > len(df):\n",
    "  msg_err = f'days_total: {days_total} must be less or equal to len(df): {len(df)}'\n",
    "  raise SystemExit(msg_err)\n",
    "\n",
    "# random slices of iloc for train and eval that fits the days_lookback, days_eval and total len(df) constraints\n",
    "l_slices = []  \n",
    "while n_sample < n_samples:\n",
    "\n",
    "\n",
    "\n",
    "  # random.seed(0)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  n_rand = randint(0, 250-1)\n",
    "  start_train = n_rand - days_lookback\n",
    "  end_train = n_rand\n",
    "  start_eval = n_rand\n",
    "  end_eval = n_rand + days_eval\n",
    "  if 0 <= start_train and end_eval <= len(df):\n",
    "    l_slices.append((start_train, end_train, end_eval))\n",
    "    # print(f'n_rand: {n_rand:>3},    start_train: {start_train:>3},    end_train: {end_train:>3},    start_eval: {start_eval:>3},    end_eval: {end_eval:>3},    n_sample: {n_sample:>3}')\n",
    "    # ======== valid n_rand, do test and validation here ========\n",
    "    # ======== valid n_rand, do test and validation here ========\n",
    "    n_sample += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 0\n",
    "n_samples = 100\n",
    "days_lookback = 120\n",
    "days_eval = 20\n",
    "days_total = days_lookback + days_eval\n",
    "print(f'days_lookback: {days_lookback}, days_eval: {days_eval}, days_total: {days_total}, len(df): {len(df)}')\n",
    "\n",
    "if days_total > len(df):\n",
    "  msg_err = f'days_total: {days_total} must be less or equal to len(df): {len(df)}'\n",
    "  raise SystemExit(msg_err)\n",
    "\n",
    "# random slices of iloc for train and eval that fits the days_lookback, days_eval and total len(df) constraints\n",
    "l_slices = []  \n",
    "while n_sample < n_samples:\n",
    "  n_rand = randint(0, 250-1)\n",
    "  start_train = n_rand - days_lookback\n",
    "  end_train = n_rand\n",
    "  start_eval = n_rand\n",
    "  end_eval = n_rand + days_eval\n",
    "  if 0 <= start_train and end_eval <= len(df):\n",
    "    l_slices.append((start_train, end_train, end_eval))\n",
    "    # print(f'n_rand: {n_rand:>3},    start_train: {start_train:>3},    end_train: {end_train:>3},    start_eval: {start_eval:>3},    end_eval: {end_eval:>3},    n_sample: {n_sample:>3}')\n",
    "    # ======== valid n_rand, do test and validation here ========\n",
    "    # ======== valid n_rand, do test and validation here ========\n",
    "    n_sample += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_slice in l_slices:\n",
    "  start_train = l_slice[0]\n",
    "  end_train = l_slice[1]\n",
    "  df_train = df.iloc[start_train:end_train]\n",
    "\n",
    "  start_eval = end_train\n",
    "  end_eval = l_slice[2]\n",
    "  df_eval = df.iloc[start_eval:end_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slices = random_slices(df, n_samples=100, days_lookback=120, days_eval=20)\n",
    "my_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(l_slices, path_data_dump, 'l_slices')\n",
    "l_slices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
