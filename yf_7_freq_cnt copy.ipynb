{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 14)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 800)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "\n",
    "# fp_df_eval_results = 'df_eval_results'\n",
    "fp_df_eval_sym_freq_results = 'df_eval_sym_freq_results'\n",
    "\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_df_train: 1050, len_df_val: 300, len_df_test: 150 \n"
     ]
    }
   ],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "\n",
    "###################################\n",
    "# df_train, df_val, df_test = _2_split_train_val_test(df_close_clean, s_train=1, s_val=0, s_test=0)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)\n",
    "###################################\n",
    "\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_add_total: ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'sym_freq_cnt', 'grp(retnStd/UI)_mean', 'grp(retnStd/UI)_std', 'grp(retnStd/UI)_mean/std', 'grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std', 'grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std', 'SPY_retnStd/UI', 'SPY_CAGR/retnStd', 'SPY_CAGR/UI']\n"
     ]
    }
   ],
   "source": [
    "col_add0 = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'sym_freq_cnt']\n",
    "col_add1 = ['grp(retnStd/UI)_mean',   'grp(retnStd/UI)_std',   'grp(retnStd/UI)_mean/std']\n",
    "col_add2 = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "col_add3 = ['grp(CAGR/UI)_mean',      'grp(CAGR/UI)_std',      'grp(CAGR/UI)_mean/std']\n",
    "col_add4 = ['SPY_retnStd/UI', 'SPY_CAGR/retnStd', 'SPY_CAGR/UI']\n",
    "col_add_total = col_add0 + col_add1 + col_add2 + col_add3 + col_add4\n",
    "print(f'col_add_total: {col_add_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if store_results:  # record results to df\n",
    "# my_cols = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std', 'SPY_CAGR/UI']\n",
    "# df_eval_results = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df_eval_sym_freq_results = pickle_load(path_data_dump, fp_df_eval_sym_freq_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose = False  # True prints more output\n",
    "verbose = True  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "store_results = False\n",
    "# store_results = True\n",
    "\n",
    "# number of max lookback tuples to create for iloc start_train:end_train:end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "n_samples = 2\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback end_train\n",
    "# days_lookbacks = [15, 30, 60, 120]\n",
    "# days_lookbacks = [30, 60, 120]\n",
    "# days_lookbacks = [60, 120]\n",
    "# days_lookbacks = [120]\n",
    "# days_lookbacks = [60]\n",
    "# days_lookbacks = [30]\n",
    "# days_lookbacks = [15]\n",
    "days_lookbacks = [15, 30]\n",
    "# days_lookbacks = [15, 29]\n",
    "# days_lookbacks = [15, 31]\n",
    "# days_lookbacks = [14, 30]\n",
    "# days_lookbacks = [16, 32]\n",
    "# days_lookbacks = [14, 28]\n",
    "\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from end_train are used to evaluate effectiveness of the training\n",
    "# days_eval = 10\n",
    "days_eval = 5\n",
    "# days_eval = 4\n",
    "# days_eval = 3\n",
    "# days_eval = 2  \n",
    "\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "syms_start = 0  #  start index of n_top_syms for evaluation\n",
    "# syms_start = 1  #  start index of n_top_syms for evaluation\n",
    "\n",
    "# syms_end = n_top_syms  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 1  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 2  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 3  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 4  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 5  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 6  #  end index of n_top_syms for evaluation\n",
    "syms_end = 10  #  end index of n_top_syms for evaluation\n",
    "\n",
    "# freq_cnt = 6  # frequency of symbol in top_set_syms_n_freq "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a sets of iloc lookback slices (start_train:end_train:end_eval), where  \n",
    "end_train - start_train = days_lookback  \n",
    "end_eval - end_train = days_eval  \n",
    "for example,  \n",
    "if given:  \n",
    " n_samples = 2  \n",
    " days_lookbacks = [30, 60, 120]  \n",
    " days_eval = 10  \n",
    "a possible result is:  \n",
    " max_lookback_slices:  \n",
    " [(150, 270, 280), (5, 125, 135)]  \n",
    " where 270-150=125-5=max(days_lookbacks), 280-270=135-125=days_eval  \n",
    " sets_lookback_slices:  \n",
    " [[(240, 270, 280), (210, 270, 280), (150, 270, 280)], [(95, 125, 135), (65, 125, 135), (5, 125, 135)]]  \n",
    "  where in a set, 270-240=days_lookbacks[0], 270-210=days_lookbacks[1], 270-150=days_lookbacks[2]  \n",
    "  and 270, i.e. end_train, is constant for the set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_lookback_slices:\n",
      "[(475, 505, 510), (790, 820, 825)]\n",
      "sets_lookback_slices:\n",
      "[[(490, 505, 510), (475, 505, 510)], [(805, 820, 825), (790, 820, 825)]]\n"
     ]
    }
   ],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}')\n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate lists, n_samples long, of the highest performance ranked symbols. The performance metrics are: CAGR/UI, CAGR/retnStd, retnStd/UI. n_top_syms of the best performing symbols from each metric are combined. The symbols are sorted by their number of appearances in the combined pool, and are placed in a list. A slice of the best performing symbols is selected by syms_start:syms_end, i.e. top_set_syms_n_freq[syms_start:syms_end].     \n",
    "\n",
    "The performance metrics are calculated based on slices in sets_lookback_slices.  The first two numbers are ilocs for training. The last two numbers are ilocs for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days lookback: 15\n",
      "lb_slices:     [(490, 505, 510), (475, 505, 510)]\n",
      "lb_slice:      (490, 505, 510)\n",
      "days eval:     5\n",
      "start_train:   490\n",
      "end_train:     505\n",
      "perf_ranks: {'period-15': {'r_CAGR/UI': array(['QURE', 'JYNT', 'NSTG', 'W', 'MO', 'CDNS', 'OLED', 'NXST', 'MELI',\n",
      "       'LNTH', 'PLUG', 'ANF', 'PPL', 'IONS', 'TCOM', 'RCII', 'COLL',\n",
      "       'NZF', 'ETSY', 'GRMN'], dtype=object), 'r_CAGR/retnStd': array(['QURE', 'JYNT', 'NSTG', 'W', 'LNTH', 'PCG', 'HAIN', 'PLUG', 'ETSY',\n",
      "       'MO', 'NXST', 'OLED', 'MELI', 'ANF', 'GOGO', 'TNDM', 'TCOM',\n",
      "       'CDNS', 'COLL', 'IONS'], dtype=object), 'r_retnStd/UI': array(['MO', 'CDNS', 'NSTG', 'JYNT', 'GRMN', 'OLED', 'QURE', 'PPL', 'NZF',\n",
      "       'NXST', 'MELI', 'W', 'LYV', 'BEP', 'IONS', 'AY', 'FTSM', 'RCII',\n",
      "       'ANF', 'NEE'], dtype=object)}}\n",
      "most_common_syms: [('QURE', 3), ('JYNT', 3), ('NSTG', 3), ('W', 3), ('MO', 3), ('CDNS', 3), ('OLED', 3), ('NXST', 3), ('MELI', 3), ('ANF', 3), ('IONS', 3), ('LNTH', 2), ('PLUG', 2), ('PPL', 2), ('TCOM', 2), ('RCII', 2), ('COLL', 2), ('NZF', 2), ('ETSY', 2), ('GRMN', 2), ('PCG', 1), ('HAIN', 1), ('GOGO', 1), ('TNDM', 1), ('LYV', 1), ('BEP', 1), ('AY', 1), ('FTSM', 1), ('NEE', 1)]\n",
      "+++ finish lookback slice 15 +++\n",
      "\n",
      "days lookback: 30\n",
      "lb_slices:     [(490, 505, 510), (475, 505, 510)]\n",
      "lb_slice:      (475, 505, 510)\n",
      "days eval:     5\n",
      "start_train:   475\n",
      "end_train:     505\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['QURE', 'JYNT', 'LSCC', 'W', 'NSTG', 'OLED', 'CDNS', 'PCG', 'NXST',\n",
      "       'NYT', 'PLUG', 'PEG', 'MO', 'IRBT', 'RAMP', 'BTI', 'APPS', 'MAS',\n",
      "       'MARA', 'AVXL'], dtype=object), 'r_CAGR/retnStd': array(['QURE', 'JYNT', 'PCG', 'NSTG', 'W', 'LSCC', 'AVXL', 'IRBT', 'CDNS',\n",
      "       'MARA', 'KDNY', 'OLED', 'APPS', 'PLUG', 'LNTH', 'RAMP', 'MO',\n",
      "       'BTI', 'NXST', 'TNDM'], dtype=object), 'r_retnStd/UI': array(['GRMN', 'OLED', 'NYT', 'LSCC', 'JYNT', 'PEG', 'NXST', 'W', 'CDNS',\n",
      "       'G', 'AZN', 'NSTG', 'FTSM', 'MSI', 'LYV', 'MAS', 'QURE', 'BBY',\n",
      "       'NEE', 'PM'], dtype=object)}}\n",
      "most_common_syms: [('QURE', 3), ('JYNT', 3), ('LSCC', 3), ('W', 3), ('NSTG', 3), ('OLED', 3), ('CDNS', 3), ('NXST', 3), ('PCG', 2), ('NYT', 2), ('PLUG', 2), ('PEG', 2), ('MO', 2), ('IRBT', 2), ('RAMP', 2), ('BTI', 2), ('APPS', 2), ('MAS', 2), ('MARA', 2), ('AVXL', 2), ('KDNY', 1), ('LNTH', 1), ('TNDM', 1), ('GRMN', 1), ('G', 1), ('AZN', 1), ('FTSM', 1), ('MSI', 1), ('LYV', 1), ('BBY', 1), ('NEE', 1), ('PM', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "grp_most_common_syms: [[('QURE', 3), ('JYNT', 3), ('NSTG', 3), ('W', 3), ('MO', 3), ('CDNS', 3), ('OLED', 3), ('NXST', 3), ('MELI', 3), ('ANF', 3), ('IONS', 3), ('LNTH', 2), ('PLUG', 2), ('PPL', 2), ('TCOM', 2), ('RCII', 2), ('COLL', 2), ('NZF', 2), ('ETSY', 2), ('GRMN', 2), ('PCG', 1), ('HAIN', 1), ('GOGO', 1), ('TNDM', 1), ('LYV', 1), ('BEP', 1), ('AY', 1), ('FTSM', 1), ('NEE', 1)], [('QURE', 3), ('JYNT', 3), ('LSCC', 3), ('W', 3), ('NSTG', 3), ('OLED', 3), ('CDNS', 3), ('NXST', 3), ('PCG', 2), ('NYT', 2), ('PLUG', 2), ('PEG', 2), ('MO', 2), ('IRBT', 2), ('RAMP', 2), ('BTI', 2), ('APPS', 2), ('MAS', 2), ('MARA', 2), ('AVXL', 2), ('KDNY', 1), ('LNTH', 1), ('TNDM', 1), ('GRMN', 1), ('G', 1), ('AZN', 1), ('FTSM', 1), ('MSI', 1), ('LYV', 1), ('BBY', 1), ('NEE', 1), ('PM', 1)]]\n",
      "**** finish lookback slices [(490, 505, 510), (475, 505, 510)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(490, 505, 510), (475, 505, 510)]:\n",
      "[('CDNS', 6), ('JYNT', 6), ('NSTG', 6), ('NXST', 6), ('OLED', 6), ('QURE', 6), ('W', 6), ('MO', 5), ('PLUG', 4), ('ANF', 3), ('GRMN', 3), ('IONS', 3), ('LNTH', 3), ('LSCC', 3), ('MELI', 3), ('PCG', 3), ('APPS', 2), ('AVXL', 2), ('BTI', 2), ('COLL', 2)]\n",
      "top 20 ranked symbols from set [(490, 505, 510), (475, 505, 510)]:\n",
      "['CDNS', 'JYNT', 'NSTG', 'NXST', 'OLED', 'QURE', 'W', 'MO', 'PLUG', 'ANF']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(490, 505, 510), (475, 505, 510)] =====\n",
      "\n",
      "\n",
      "days lookback: 15\n",
      "lb_slices:     [(805, 820, 825), (790, 820, 825)]\n",
      "lb_slice:      (805, 820, 825)\n",
      "days eval:     5\n",
      "start_train:   805\n",
      "end_train:     820\n",
      "perf_ranks: {'period-15': {'r_CAGR/UI': array(['NVG', 'CHRD', 'CPE', 'ROCC', 'ENLC', 'IVR', 'CAR', 'MGI', 'NCLH',\n",
      "       'UAL', 'TA', 'AAL', 'APPS', 'DBRG', 'SM', 'DCP', 'GDEN', 'ALK',\n",
      "       'BA', 'RC'], dtype=object), 'r_CAGR/retnStd': array(['CHRD', 'CPE', 'ROCC', 'IVR', 'CAR', 'ENLC', 'NCLH', 'MGI', 'UAL',\n",
      "       'AAL', 'TA', 'SM', 'DBRG', 'GOGO', 'APPS', 'DCP', 'SKYW', 'RC',\n",
      "       'PLAY', 'SITC'], dtype=object), 'r_retnStd/UI': array(['NVG', 'AJG', 'BAH', 'CUZ', 'ALB', 'DISH', 'CSQ', 'CLS', 'NZF',\n",
      "       'EVT', 'GDEN', 'UPS', 'ETG', 'ABR', 'NMZ', 'ISD', 'IRM', 'NSA',\n",
      "       'ENLC', 'TA'], dtype=object)}}\n",
      "most_common_syms: [('ENLC', 3), ('TA', 3), ('NVG', 2), ('CHRD', 2), ('CPE', 2), ('ROCC', 2), ('IVR', 2), ('CAR', 2), ('MGI', 2), ('NCLH', 2), ('UAL', 2), ('AAL', 2), ('APPS', 2), ('DBRG', 2), ('SM', 2), ('DCP', 2), ('GDEN', 2), ('RC', 2), ('ALK', 1), ('BA', 1), ('GOGO', 1), ('SKYW', 1), ('PLAY', 1), ('SITC', 1), ('AJG', 1), ('BAH', 1), ('CUZ', 1), ('ALB', 1), ('DISH', 1), ('CSQ', 1), ('CLS', 1), ('NZF', 1), ('EVT', 1), ('UPS', 1), ('ETG', 1), ('ABR', 1), ('NMZ', 1), ('ISD', 1), ('IRM', 1), ('NSA', 1)]\n",
      "+++ finish lookback slice 15 +++\n",
      "\n",
      "days lookback: 30\n",
      "lb_slices:     [(805, 820, 825), (790, 820, 825)]\n",
      "lb_slice:      (790, 820, 825)\n",
      "days eval:     5\n",
      "start_train:   790\n",
      "end_train:     820\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['CPE', 'ROCC', 'SM', 'CHRD', 'CWH', 'TRGP', 'OVV', 'GEL', 'IVR',\n",
      "       'GOGO', 'ENLC', 'PTEN', 'CZR', 'CELH', 'NEX', 'USAC', 'MUR', 'MGI',\n",
      "       'GPRE', 'NCLH'], dtype=object), 'r_CAGR/retnStd': array(['CPE', 'ROCC', 'SM', 'CHRD', 'CWH', 'TRGP', 'OVV', 'ENLC', 'GEL',\n",
      "       'IVR', 'GOGO', 'PTEN', 'NCLH', 'CZR', 'CELH', 'NEX', 'PLCE', 'CAR',\n",
      "       'DCP', 'MUR'], dtype=object), 'r_retnStd/UI': array(['MELI', 'EBAY', 'MUC', 'PYPL', 'AJG', 'TWLO', 'TRGP', 'ROP',\n",
      "       'FTSM', 'NYT', 'AMX', 'CWH', 'CCS', 'SQ', 'SUPN', 'RAMP', 'STKL',\n",
      "       'HZNP', 'SPLK', 'AON'], dtype=object)}}\n",
      "most_common_syms: [('CWH', 3), ('TRGP', 3), ('CPE', 2), ('ROCC', 2), ('SM', 2), ('CHRD', 2), ('OVV', 2), ('GEL', 2), ('IVR', 2), ('GOGO', 2), ('ENLC', 2), ('PTEN', 2), ('CZR', 2), ('CELH', 2), ('NEX', 2), ('MUR', 2), ('NCLH', 2), ('USAC', 1), ('MGI', 1), ('GPRE', 1), ('PLCE', 1), ('CAR', 1), ('DCP', 1), ('MELI', 1), ('EBAY', 1), ('MUC', 1), ('PYPL', 1), ('AJG', 1), ('TWLO', 1), ('ROP', 1), ('FTSM', 1), ('NYT', 1), ('AMX', 1), ('CCS', 1), ('SQ', 1), ('SUPN', 1), ('RAMP', 1), ('STKL', 1), ('HZNP', 1), ('SPLK', 1), ('AON', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "grp_most_common_syms: [[('ENLC', 3), ('TA', 3), ('NVG', 2), ('CHRD', 2), ('CPE', 2), ('ROCC', 2), ('IVR', 2), ('CAR', 2), ('MGI', 2), ('NCLH', 2), ('UAL', 2), ('AAL', 2), ('APPS', 2), ('DBRG', 2), ('SM', 2), ('DCP', 2), ('GDEN', 2), ('RC', 2), ('ALK', 1), ('BA', 1), ('GOGO', 1), ('SKYW', 1), ('PLAY', 1), ('SITC', 1), ('AJG', 1), ('BAH', 1), ('CUZ', 1), ('ALB', 1), ('DISH', 1), ('CSQ', 1), ('CLS', 1), ('NZF', 1), ('EVT', 1), ('UPS', 1), ('ETG', 1), ('ABR', 1), ('NMZ', 1), ('ISD', 1), ('IRM', 1), ('NSA', 1)], [('CWH', 3), ('TRGP', 3), ('CPE', 2), ('ROCC', 2), ('SM', 2), ('CHRD', 2), ('OVV', 2), ('GEL', 2), ('IVR', 2), ('GOGO', 2), ('ENLC', 2), ('PTEN', 2), ('CZR', 2), ('CELH', 2), ('NEX', 2), ('MUR', 2), ('NCLH', 2), ('USAC', 1), ('MGI', 1), ('GPRE', 1), ('PLCE', 1), ('CAR', 1), ('DCP', 1), ('MELI', 1), ('EBAY', 1), ('MUC', 1), ('PYPL', 1), ('AJG', 1), ('TWLO', 1), ('ROP', 1), ('FTSM', 1), ('NYT', 1), ('AMX', 1), ('CCS', 1), ('SQ', 1), ('SUPN', 1), ('RAMP', 1), ('STKL', 1), ('HZNP', 1), ('SPLK', 1), ('AON', 1)]]\n",
      "**** finish lookback slices [(805, 820, 825), (790, 820, 825)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(805, 820, 825), (790, 820, 825)]:\n",
      "[('ENLC', 5), ('CHRD', 4), ('CPE', 4), ('IVR', 4), ('NCLH', 4), ('ROCC', 4), ('SM', 4), ('CAR', 3), ('CWH', 3), ('DCP', 3), ('GOGO', 3), ('MGI', 3), ('TA', 3), ('TRGP', 3), ('AAL', 2), ('AJG', 2), ('APPS', 2), ('CELH', 2), ('CZR', 2), ('DBRG', 2)]\n",
      "top 20 ranked symbols from set [(805, 820, 825), (790, 820, 825)]:\n",
      "['ENLC', 'CHRD', 'CPE', 'IVR', 'NCLH', 'ROCC', 'SM', 'CAR', 'CWH', 'DCP']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(805, 820, 825), (790, 820, 825)] =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # list of lists of top_set_symbols, there are n_samples lists in list\n",
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for lb_slices in sets_lookback_slices:\n",
    "  grp_most_common_syms = []  \n",
    "  for lb_slice in lb_slices:  # lb_slice, e.g. (246, 276, 286)\n",
    "    start_train = lb_slice[0]\n",
    "    end_train = lb_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = lb_slice[2]\n",
    "    lookback = end_train - start_train\n",
    "    d_eval = end_eval - start_eval\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback: {lookback}')\n",
    "      print(f'lb_slices:     {lb_slices}')\n",
    "      print(f'lb_slice:      {lb_slice}')\n",
    "      print(f'days eval:     {d_eval}')    \n",
    "      print(f'start_train:   {start_train}')\n",
    "      print(f'end_train:     {end_train}')\n",
    "      # print(f'start_eval:    {start_eval}')\n",
    "      # print(f'end_eval:      {end_eval}')`\n",
    "\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, most_common_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "    grp_most_common_syms.append(most_common_syms)\n",
    "    \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_common_syms: {most_common_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "    # grp_most_common_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "  # group symbols from set of days_lookbacks (i.e. lb_slices) and sum frequency of the symbols\n",
    "  set_most_common_syms = _6_grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "  # get the top few most-frequent symbol:frequency pairs\n",
    "  top_set_syms_n_freq = set_most_common_syms[0:n_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq\n",
    "\n",
    "###################################  \n",
    "  # top_set_syms = [i[0] for i in top_set_syms_n_freq]\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "###################################  \n",
    "  \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_set_sym_freq_cnt(top_set_syms_n_freq):\n",
    "    sym_freq_cnt_6 = []\n",
    "    sym_freq_cnt_5 = []\n",
    "    sym_freq_cnt_4 = []\n",
    "    sym_freq_cnt_3 = []\n",
    "    sym_freq_cnt_2 = []\n",
    "\n",
    "    for sym_n_freq in top_set_syms_n_freq:\n",
    "        _sym = sym_n_freq[0]\n",
    "        _freq = sym_n_freq[1]\n",
    "        # print(_sym, _freq)\n",
    "        if _freq == 6:\n",
    "            sym_freq_cnt_6.append(_sym)\n",
    "        elif _freq == 5:\n",
    "            sym_freq_cnt_5.append(_sym)\n",
    "        elif _freq == 4:\n",
    "            sym_freq_cnt_4.append(_sym)\n",
    "        elif _freq == 3:\n",
    "            sym_freq_cnt_3.append(_sym)          \n",
    "        else:\n",
    "            sym_freq_cnt_2.append(_sym)\n",
    "\n",
    "    l_sym_freq_cnt = []\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_6)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_5)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_4)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_3)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_2)    \n",
    "\n",
    "    # if verbose:\n",
    "    #     print(f'sym_freq_cnt_6: {sym_freq_cnt_6}')\n",
    "    #     print(f'sym_freq_cnt_5: {sym_freq_cnt_5}')\n",
    "    #     print(f'sym_freq_cnt_4: {sym_freq_cnt_4}')\n",
    "    #     print(f'sym_freq_cnt_3: {sym_freq_cnt_3}')\n",
    "    #     print(f'sym_freq_cnt_2: {sym_freq_cnt_2}')\n",
    "\n",
    "    # return sym_freq_cnt_6, sym_freq_cnt_5, sym_freq_cnt_4, sym_freq_cnt_3, sym_freq_cnt_2\n",
    "    return l_sym_freq_cnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for top_set_syms_n_freq in grp_top_set_syms_n_freq:\n",
    "#   l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "#   print(f'sym_freq_6: {l_sym_freq_cnt[0]}')\n",
    "#   print(f'sym_freq_5: {l_sym_freq_cnt[1]}')\n",
    "#   print(f'sym_freq_4: {l_sym_freq_cnt[2]}')\n",
    "#   print(f'sym_freq_3: {l_sym_freq_cnt[3]}')\n",
    "#   print(f'sym_freq_2: {l_sym_freq_cnt[4]}\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "1 of 2 max_lookback_slice\n",
      "max_lookback_slice: (475, 505, 510)\n",
      "max lookback dates: 2019-01-25, 2019-03-11, 2019-03-18\n",
      "df_eval dates (inclusive): 2019-03-11 - 2019-03-15\n",
      "top_set_syms_n_freq: [('CDNS', 6), ('JYNT', 6), ('NSTG', 6), ('NXST', 6), ('OLED', 6), ('QURE', 6), ('W', 6), ('MO', 5), ('PLUG', 4), ('ANF', 3), ('GRMN', 3), ('IONS', 3), ('LNTH', 3), ('LSCC', 3), ('MELI', 3), ('PCG', 3), ('APPS', 2), ('AVXL', 2), ('BTI', 2), ('COLL', 2)]\n",
      "\n",
      "sym_freq_6: ['CDNS', 'JYNT', 'NSTG', 'NXST', 'OLED', 'QURE', 'W']\n",
      "sym_freq_5: ['MO']\n",
      "sym_freq_4: ['PLUG']\n",
      "sym_freq_3: ['ANF', 'GRMN', 'IONS', 'LNTH', 'LSCC', 'MELI', 'PCG']\n",
      "\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:        10.843,       351.988,     3,816.551\n",
      "start_eval: 505,  date: 2019-03-11\n",
      "end_eval:   510,  date: 2019-03-18,  df_eval last date: 2019-03-15\n",
      "frequency count of symbol(s): 6\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                 CDNS   JYNT       NSTG        NXST        OLED       QURE           W         SPY\n",
      "Date                                                                                              \n",
      "2019-03-11  59.959999  14.90  29.740000   98.942307  150.833237  65.230003  170.169998  266.508209\n",
      "2019-03-12  60.619999  14.52  27.740000  100.226654  153.641708  65.500000  171.570007  267.513245\n",
      "2019-03-13  60.660000  14.00  26.920000  101.491959  154.584473  64.959999  168.720001  269.283997\n",
      "2019-03-14  61.160000  14.04  26.709999  102.053276  153.720535  63.549999  165.320007  269.111633\n",
      "2019-03-15  60.990002  14.44  27.510000  101.406357  155.021423  63.349998  166.009995  270.441284\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         2.104,         1.965,         1.071\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        87.268,       165.191,         0.528\n",
      "grp(CAGR/UI):      mean, std, mean/std:       435.617,       582.902,         0.747\n",
      "start_eval: 505,  date: 2019-03-11\n",
      "end_eval:   510,  date: 2019-03-18,  df_eval last date: 2019-03-15\n",
      "frequency count of symbol(s): 5\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                   MO         SPY\n",
      "Date                             \n",
      "2019-03-11  44.681034  266.508209\n",
      "2019-03-12  44.473629  267.513245\n",
      "2019-03-13  44.776768  269.283997\n",
      "2019-03-14  44.992149  269.111633\n",
      "2019-03-15  45.271358  270.441284\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         2.582,           nan,           nan\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       174.980,           nan,           nan\n",
      "grp(CAGR/UI):      mean, std, mean/std:       451.722,           nan,           nan\n",
      "start_eval: 505,  date: 2019-03-11\n",
      "end_eval:   510,  date: 2019-03-18,  df_eval last date: 2019-03-15\n",
      "frequency count of symbol(s): 4\n",
      "\n",
      "df_eval_n_SPY:\n",
      "            PLUG         SPY\n",
      "Date                        \n",
      "2019-03-11  2.11  266.508209\n",
      "2019-03-12  2.20  267.513245\n",
      "2019-03-13  2.38  269.283997\n",
      "2019-03-14  2.59  269.111633\n",
      "2019-03-15  2.20  270.441284\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         1.671,           nan,           nan\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        64.043,           nan,           nan\n",
      "grp(CAGR/UI):      mean, std, mean/std:       107.046,           nan,           nan\n",
      "start_eval: 505,  date: 2019-03-11\n",
      "end_eval:   510,  date: 2019-03-18,  df_eval last date: 2019-03-15\n",
      "frequency count of symbol(s): 3\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                  ANF       GRMN       IONS       LNTH   LSCC        MELI        PCG         SPY\n",
      "Date                                                                                            \n",
      "2019-03-11  25.280819  78.881218  73.919998  23.770000  13.00  481.109985  19.379999  266.508209\n",
      "2019-03-12  25.347248  79.511444  74.879997  23.910000  12.71  483.480011  19.219999  267.513245\n",
      "2019-03-13  25.366226  78.956482  76.610001  23.930000  13.00  507.929993  19.459999  269.283997\n",
      "2019-03-14  25.100513  78.606232  77.440002  23.959999  12.79  493.790009  19.510000  269.111633\n",
      "2019-03-15  25.043573  78.805023  78.540001  24.100000  12.91  488.730011  19.650000  270.441284\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:           inf,           nan,           nan\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       596.046,     1,397.175,         0.427\n",
      "grp(CAGR/UI):      mean, std, mean/std:           inf,           nan,           nan\n",
      "================================================== \n",
      "\n",
      "2 of 2 max_lookback_slice\n",
      "max_lookback_slice: (790, 820, 825)\n",
      "max lookback dates: 2020-04-27, 2020-06-09, 2020-06-16\n",
      "df_eval dates (inclusive): 2020-06-09 - 2020-06-15\n",
      "top_set_syms_n_freq: [('ENLC', 5), ('CHRD', 4), ('CPE', 4), ('IVR', 4), ('NCLH', 4), ('ROCC', 4), ('SM', 4), ('CAR', 3), ('CWH', 3), ('DCP', 3), ('GOGO', 3), ('MGI', 3), ('TA', 3), ('TRGP', 3), ('AAL', 2), ('AJG', 2), ('APPS', 2), ('CELH', 2), ('CZR', 2), ('DBRG', 2)]\n",
      "\n",
      "sym_freq_6: []\n",
      "sym_freq_5: ['ENLC']\n",
      "sym_freq_4: ['CHRD', 'CPE', 'IVR', 'NCLH', 'ROCC', 'SM']\n",
      "sym_freq_3: ['CAR', 'CWH', 'DCP', 'GOGO', 'MGI', 'TA', 'TRGP']\n",
      "\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:         0.786,       -27.481,       -21.590\n",
      "start_eval: 820,  date: 2020-06-09\n",
      "end_eval:   825,  date: 2020-06-16,  df_eval last date: 2020-06-15\n",
      "frequency count of symbol(s): 5\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                ENLC         SPY\n",
      "Date                            \n",
      "2020-06-09  2.833429  314.697266\n",
      "2020-06-10  2.636891  312.941284\n",
      "2020-06-11  2.350272  294.900513\n",
      "2020-06-12  2.399407  298.432159\n",
      "2020-06-15  2.726970  301.218170\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         1.005,           nan,           nan\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        -7.848,           nan,           nan\n",
      "grp(CAGR/UI):      mean, std, mean/std:        -7.886,           nan,           nan\n",
      "start_eval: 820,  date: 2020-06-09\n",
      "end_eval:   825,  date: 2020-06-16,  df_eval last date: 2020-06-15\n",
      "frequency count of symbol(s): 4\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                CHRD   CPE        IVR       NCLH       ROCC        SM         SPY\n",
      "Date                                                                             \n",
      "2020-06-09  1.197349  18.5  39.218109  24.129999  14.412326  5.973618  314.697266\n",
      "2020-06-10  0.922798  17.1  37.615948  20.650000  12.490018  5.050784  312.941284\n",
      "2020-06-11  0.747390  14.2  30.023100  17.250000   9.750979  4.276793  294.900513\n",
      "2020-06-12  0.899918  15.1  33.645374  20.500000  12.564719  4.594328  298.432159\n",
      "2020-06-15  0.892291  15.2  34.272308  19.990000  12.928264  4.802710  301.218170\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         0.876,         0.251,         3.488\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        -6.834,         2.014,        -3.393\n",
      "grp(CAGR/UI):      mean, std, mean/std:        -5.684,         1.144,        -4.969\n",
      "start_eval: 820,  date: 2020-06-09\n",
      "end_eval:   825,  date: 2020-06-16,  df_eval last date: 2020-06-15\n",
      "frequency count of symbol(s): 3\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                  CAR        CWH        DCP  GOGO   MGI         TA       TRGP         SPY\n",
      "Date                                                                                     \n",
      "2020-06-09  29.120001  20.618242  12.237597  3.14  3.74  19.000000  23.553432  314.697266\n",
      "2020-06-10  27.090000  20.033209  12.187546  3.00  3.34  16.980000  22.280010  312.941284\n",
      "2020-06-11  23.100000  17.684719  10.010305  2.31  2.77  14.900000  18.984669  294.900513\n",
      "2020-06-12  26.190001  19.674007  10.268905  2.61  3.15  16.190001  19.081875  298.432159\n",
      "2020-06-15  26.350000  21.239843  10.711024  2.92  3.14  16.650000  21.346817  301.218170\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         1.001,         0.278,         3.603\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        -2.412,        15.710,        -0.154\n",
      "grp(CAGR/UI):      mean, std, mean/std:         0.918,        22.089,         0.042\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from yf_utils import _7_perf_eval\n",
    "\n",
    "print('z_grp_top_set_syms_n_freq:')\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "\n",
    "for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "\n",
    "  start_train = _lookback_slice[0]\n",
    "  end_train = _lookback_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  d_start_train = df_train.index[start_train].strftime('%Y-%m-%d')\n",
    "  d_end_train = df_train.index[end_train].strftime('%Y-%m-%d')\n",
    "  d_start_eval = d_end_train\n",
    "  d_end_eval = df_train.index[end_eval].strftime('%Y-%m-%d')\n",
    "  d_df_eval_start = d_end_train\n",
    "  d_df_eval_end = df_train.index[end_eval - 1].strftime('%Y-%m-%d')  \n",
    "  print(f'max lookback dates: {d_start_train}, {d_end_train}, {d_end_eval}')\n",
    "  print(f'df_eval dates (inclusive): {d_df_eval_start} - {d_df_eval_end}')    \n",
    "  print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}\\n')\n",
    "\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(_top_set_syms_n_freq)\n",
    "  print(f'sym_freq_6: {l_sym_freq_cnt[0]}')\n",
    "  print(f'sym_freq_5: {l_sym_freq_cnt[1]}')\n",
    "  print(f'sym_freq_4: {l_sym_freq_cnt[2]}')\n",
    "  print(f'sym_freq_3: {l_sym_freq_cnt[3]}\\n')\n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df_train[start_eval:end_eval][_sym_idx]\n",
    "  _, SPY_retnStd_d_UI, SPY_CAGR_d_retnStd, SPY_CAGR_d_UI = _7_perf_eval(df_SPY)\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI: {SPY_retnStd_d_UI[0]:>13,.3f}, {SPY_CAGR_d_retnStd[0]:>13,.3f}, {SPY_CAGR_d_UI[0]:>13,.3f}')\n",
    "\n",
    "  # drop last list in l_sym_freq_cnt from zip\n",
    "  zip_cnt_n_syms = zip([6,5,4,3], l_sym_freq_cnt[:-1])  \n",
    "  for item in zip_cnt_n_syms:\n",
    "    sym_freq_cnt = item[0]\n",
    "    syms = item[1]\n",
    "    if syms:  # iterate ONLY if there are symbols in syms\n",
    "      df_eval = df_train[start_eval:end_eval][syms]      \n",
    "\n",
    "      if verbose:\n",
    "        # print(f'start_eval: {start_eval}')\n",
    "        # print(f'end_eval:   {end_eval}')  \n",
    "        print(f'start_eval: {start_eval},  date: {d_end_train}')\n",
    "        print(f'end_eval:   {end_eval},  date: {d_end_eval},  df_eval last date: {d_df_eval_end}')\n",
    "        print(f'frequency count of symbol(s): {sym_freq_cnt}')      \n",
    "        # print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "        syms_n_SPY = syms + ['SPY']\n",
    "        df_eval_n_SPY = df_train[start_eval:end_eval][syms_n_SPY]   \n",
    "        print(f'\\ndf_eval_n_SPY:\\n{df_eval_n_SPY}\\n')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "      _, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = _7_perf_eval(df_eval)\n",
    "      print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>13,.3f}, {grp_retnStd_d_UI[1]  :>13,.3f}, {grp_retnStd_d_UI[2]  :>13,.3f}')\n",
    "      print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>13,.3f}, {grp_CAGR_d_retnStd[1]:>13,.3f}, {grp_CAGR_d_retnStd[2]:>13,.3f}')\n",
    "      print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>13,.3f}, {grp_CAGR_d_UI[1]     :>13,.3f}, {grp_CAGR_d_UI[2]     :>13,.3f}')\n",
    "\n",
    "      if store_results:  # record results to df\n",
    "        # row_add = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, grp_CAGR_d_UI[0], grp_CAGR_d_UI[1], grp_CAGR_d_UI[2], SPY_CAGR_d_UI[0]]\n",
    "        # df_eval_results.loc[len(df_eval_results)] = row_add\n",
    "        # row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end]\n",
    "        row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, sym_freq_cnt]        \n",
    "        row_add1      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "        row_add2      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "        row_add3      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "        row_add4      = [SPY_retnStd_d_UI[0],   SPY_CAGR_d_retnStd[0], SPY_CAGR_d_UI[0]]\n",
    "        row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4\n",
    "        print(f'row_add_total: {row_add_total}')\n",
    "        df_eval_sym_freq_results.loc[len(df_eval_sym_freq_results)] = row_add_total\n",
    "        # print(f'appended row_add to df_eval_results:\\n{row_add}\\n')\n",
    "        print(f'appended row_add to df_eval_sym_freq_results:\\n{row_add_total}\\n')\n",
    "  \n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR</th>\n",
       "      <th>CWH</th>\n",
       "      <th>DCP</th>\n",
       "      <th>GOGO</th>\n",
       "      <th>MGI</th>\n",
       "      <th>TA</th>\n",
       "      <th>TRGP</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-09</th>\n",
       "      <td>29.120001</td>\n",
       "      <td>20.618242</td>\n",
       "      <td>12.237597</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.74</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.553432</td>\n",
       "      <td>314.697266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <td>27.090000</td>\n",
       "      <td>20.033209</td>\n",
       "      <td>12.187546</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.34</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>22.280010</td>\n",
       "      <td>312.941284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-11</th>\n",
       "      <td>23.100000</td>\n",
       "      <td>17.684719</td>\n",
       "      <td>10.010305</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.77</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>18.984669</td>\n",
       "      <td>294.900513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-12</th>\n",
       "      <td>26.190001</td>\n",
       "      <td>19.674007</td>\n",
       "      <td>10.268905</td>\n",
       "      <td>2.61</td>\n",
       "      <td>3.15</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>19.081875</td>\n",
       "      <td>298.432159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-15</th>\n",
       "      <td>26.350000</td>\n",
       "      <td>21.239843</td>\n",
       "      <td>10.711024</td>\n",
       "      <td>2.92</td>\n",
       "      <td>3.14</td>\n",
       "      <td>16.650000</td>\n",
       "      <td>21.346817</td>\n",
       "      <td>301.218170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CAR        CWH        DCP  GOGO   MGI         TA       TRGP         SPY\n",
       "Date                                                                                     \n",
       "2020-06-09  29.120001  20.618242  12.237597  3.14  3.74  19.000000  23.553432  314.697266\n",
       "2020-06-10  27.090000  20.033209  12.187546  3.00  3.34  16.980000  22.280010  312.941284\n",
       "2020-06-11  23.100000  17.684719  10.010305  2.31  2.77  14.900000  18.984669  294.900513\n",
       "2020-06-12  26.190001  19.674007  10.268905  2.61  3.15  16.190001  19.081875  298.432159\n",
       "2020-06-15  26.350000  21.239843  10.711024  2.92  3.14  16.650000  21.346817  301.218170"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_n_SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>days_eval</th>\n",
       "      <th>n_top_syms</th>\n",
       "      <th>sym_freq_cnt</th>\n",
       "      <th>grp(retnStd/UI)_mean</th>\n",
       "      <th>grp(retnStd/UI)_std</th>\n",
       "      <th>...</th>\n",
       "      <th>grp(CAGR/retnStd)_mean/std</th>\n",
       "      <th>grp(CAGR/UI)_mean</th>\n",
       "      <th>grp(CAGR/UI)_std</th>\n",
       "      <th>grp(CAGR/UI)_mean/std</th>\n",
       "      <th>SPY_retnStd/UI</th>\n",
       "      <th>SPY_CAGR/retnStd</th>\n",
       "      <th>SPY_CAGR/UI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>1.839609</td>\n",
       "      <td>1.200176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457669</td>\n",
       "      <td>4217.585391</td>\n",
       "      <td>9293.682079</td>\n",
       "      <td>0.453812</td>\n",
       "      <td>4.432934</td>\n",
       "      <td>15610.320615</td>\n",
       "      <td>69199.519440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1.225661</td>\n",
       "      <td>0.621977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453751</td>\n",
       "      <td>1078.314728</td>\n",
       "      <td>2354.160275</td>\n",
       "      <td>0.458046</td>\n",
       "      <td>4.432934</td>\n",
       "      <td>15610.320615</td>\n",
       "      <td>69199.519440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.170976</td>\n",
       "      <td>0.626847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450569</td>\n",
       "      <td>-4.720139</td>\n",
       "      <td>23.846366</td>\n",
       "      <td>-0.197940</td>\n",
       "      <td>4.432934</td>\n",
       "      <td>15610.320615</td>\n",
       "      <td>69199.519440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428024</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.432934</td>\n",
       "      <td>15610.320615</td>\n",
       "      <td>69199.519440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2.019770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.569910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698592</td>\n",
       "      <td>-89.881304</td>\n",
       "      <td>-62.790393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267980</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.556020</td>\n",
       "      <td>33.249721</td>\n",
       "      <td>84.986956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.330611</td>\n",
       "      <td>0.065047</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.561872</td>\n",
       "      <td>-8.658595</td>\n",
       "      <td>0.198763</td>\n",
       "      <td>-43.562360</td>\n",
       "      <td>0.268802</td>\n",
       "      <td>-57.248979</td>\n",
       "      <td>-15.388623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.426338</td>\n",
       "      <td>0.320247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.205543</td>\n",
       "      <td>-10.659839</td>\n",
       "      <td>1.213056</td>\n",
       "      <td>-8.787588</td>\n",
       "      <td>0.268802</td>\n",
       "      <td>-57.248979</td>\n",
       "      <td>-15.388623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.235424</td>\n",
       "      <td>0.333404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.812435</td>\n",
       "      <td>-9.995761</td>\n",
       "      <td>7.609587</td>\n",
       "      <td>-1.313575</td>\n",
       "      <td>0.268802</td>\n",
       "      <td>-57.248979</td>\n",
       "      <td>-15.388623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>400</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.558187</td>\n",
       "      <td>0.400404</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.661848</td>\n",
       "      <td>-15.849125</td>\n",
       "      <td>8.563217</td>\n",
       "      <td>-1.850838</td>\n",
       "      <td>0.268802</td>\n",
       "      <td>-57.248979</td>\n",
       "      <td>-15.388623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1449 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_samples days_lookbacks days_eval n_top_syms sym_freq_cnt  grp(retnStd/UI)_mean  grp(retnStd/UI)_std  ...  grp(CAGR/retnStd)_mean/std  grp(CAGR/UI)_mean  grp(CAGR/UI)_std  grp(CAGR/UI)_mean/std  SPY_retnStd/UI  SPY_CAGR/retnStd   SPY_CAGR/UI\n",
       "0          400       [15, 30]         5         20            6         1.839609              1.200176      ...         0.457669                 4217.585391        9293.682079          0.453812              4.432934     15610.320615   69199.519440\n",
       "1          400       [15, 30]         5         20            5         1.225661              0.621977      ...         0.453751                 1078.314728        2354.160275          0.458046              4.432934     15610.320615   69199.519440\n",
       "2          400       [15, 30]         5         20            4         1.170976              0.626847      ...        -0.450569                   -4.720139          23.846366         -0.197940              4.432934     15610.320615   69199.519440\n",
       "3          400       [15, 30]         5         20            3              inf                   NaN      ...         0.428024                         inf                NaN               NaN              4.432934     15610.320615   69199.519440\n",
       "4          400       [15, 30]         5         20            6         2.019770                   NaN      ...              NaN                  283.569910                NaN               NaN              0.698592       -89.881304     -62.790393\n",
       "...        ...            ...       ...        ...          ...              ...                   ...      ...              ...                         ...                ...               ...                   ...              ...            ...\n",
       "1444       400       [15, 30]         5         20            3              inf                   NaN      ...         0.267980                         inf                NaN               NaN              2.556020        33.249721      84.986956\n",
       "1445       400       [15, 30]         5         20            6         0.330611              0.065047      ...        -4.561872                   -8.658595           0.198763        -43.562360              0.268802       -57.248979     -15.388623\n",
       "1446       400       [15, 30]         5         20            5         0.426338              0.320247      ...        -1.205543                  -10.659839           1.213056         -8.787588              0.268802       -57.248979     -15.388623\n",
       "1447       400       [15, 30]         5         20            4         0.235424              0.333404      ...        -0.812435                   -9.995761           7.609587         -1.313575              0.268802       -57.248979     -15.388623\n",
       "1448       400       [15, 30]         5         20            3         0.558187              0.400404      ...        -1.661848                  -15.849125           8.563217         -1.850838              0.268802       -57.248979     -15.388623\n",
       "\n",
       "[1449 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_sym_freq_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating Empty DataFrame and Storing it in variable df\n",
    "# df_eval_results = pd.DataFrame(columns=col_add_total)\n",
    "pickle_dump(df_eval_sym_freq_results, path_data_dump, fp_df_eval_sym_freq_results)\n",
    "df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pandas-groupby-a-simple-but-detailed-tutorial-314b8f37005d\n",
    "# https://towardsdatascience.com/accessing-data-in-a-multiindex-dataframe-in-pandas-569e8767201d\n",
    "# https://towardsdatascience.com/summarizing-data-with-pandas-crosstab-efc8b9abecf\n",
    "# https://towardsdatascience.com/how-to-flatten-multiindex-columns-and-rows-in-pandas-f5406c50e569\n",
    "# https://datascientyst.com/list-aggregation-functions-aggfunc-groupby-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(df.columns): {len(df.columns)}')\n",
    "print(f'df.columns: {df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(df['days_lookbacks'], df['grp(CAGR/UI)_mean'])\n",
    "tbl = df.groupby(['days_lookbacks', 'days_eval', 'sym_freq_cnt'])\\\n",
    "        .agg({'grp(CAGR/retnStd)_mean':     ['mean', 'std'],\n",
    "              'grp(CAGR/retnStd)_mean/std': ['mean', 'std'],\n",
    "              'SPY_CAGR/retnStd':           ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl['SPY_m/s'] = tbl['SPY_CAGR/retnStd', 'mean'] / tbl['SPY_CAGR/retnStd', 'std'] \n",
    "tbl['grp-SPY_m/s'] = tbl['grp(CAGR/retnStd)_mean/std', 'mean'] - tbl['SPY_m/s'] \n",
    "tbl.sort_values(by='grp-SPY_m/s', ascending=False, inplace=True)\n",
    "# tbl.sort_values(by='days_lookbacks', ascending=False, inplace=True)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/31674195/plot-normal-distribution-given-mean-and-sigma-python\n",
    "# # loc is mean, scale is standard deviation\n",
    "# import pylab\n",
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "# # x = np.linspace(-10000,100000,1000)\n",
    "# x = np.linspace(-40e+10,50e+10,1000)\n",
    "# y = norm.pdf(x, loc=2.562777e+10, scale=1.036925e+11)    # loc = mean, scale = standard deviation\n",
    "# # z = norm.pdf(x, loc=3.540615e+10, scale=1.194430e+11)    # for example\n",
    "# # z1 = norm.pdf(x, loc=298.805901, scale=826.875749)    # for example\n",
    "# # z1 = norm.pdf(x, loc=1.021825, scale=1.505096)    # for example\n",
    "# pylab.plot(x,y, 'b')\n",
    "# # pylab.plot(x,z, 'g')\n",
    "# # pylab.plot(x,z1, 'r')\n",
    "# pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get values of _cols, where grp(CAGR/retnStd)_mean is max after filtering out inf\n",
    "# _cols = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "# # _df_no_inf = df.loc[df['grp(CAGR/retnStd)_mean'] != np.inf]  # df with filter out inf in column grp(CAGR/UI)_mean \n",
    "# # _idx = _df_no_inf['grp(CAGR/retnStd)_mean'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# _idx = df['grp(CAGR/retnStd)_mean'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# grp_inf_replacement = df.loc[[_idx], _cols].squeeze()  # convert df (only has 1 row) to series\n",
    "# print(f'_idx: {_idx}')\n",
    "# grp_inf_replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get values of _cols, where SPY_CAGR/retnStd is max after filtering out inf\n",
    "# _cols = ['SPY_CAGR/retnStd']\n",
    "# # _df_no_inf = df.loc[df['SPY_CAGR/retnStd'] != np.inf]  # df with filter out inf in column grp(CAGR/UI)_mean \n",
    "# _idx = df['SPY_CAGR/retnStd'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# SPY_inf_replacement = df.loc[[_idx], _cols].squeeze()  # convert df (only has 1 row) to series\n",
    "# print(f'_idx: {_idx}')\n",
    "# SPY_inf_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # https://stackoverflow.com/questions/50773107/how-to-replace-infinite-value-with-maximum-value-of-a-pandas-column\n",
    "# # replace inf in column grp(CAGR/UI)_mean\n",
    "# df['grp(CAGR/UI)_mean'].replace(np.inf, grp_inf_replacement['grp(CAGR/UI)_mean'], inplace=True)\n",
    "# # replace NaN in column grp(CAGR/UI)_std\n",
    "# df['grp(CAGR/UI)_std'].replace(np.nan, grp_inf_replacement['grp(CAGR/UI)_std'], inplace=True)\n",
    "# # replace NaN in column grp(CAGR/UI)_mean/std\n",
    "# df['grp(CAGR/UI)_mean/std'].replace(np.nan, grp_inf_replacement['grp(CAGR/UI)_mean/std'], inplace=True)\n",
    "# # replace inf in column SPY_CAGR/UI\n",
    "# df['SPY_CAGR/UI'].replace(np.inf, SPY_inf_replacement, inplace=True)\n",
    "# df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'n_samples:             {n_samples:>13}')\n",
    "# print(f'days_lookbacks:        {days_lookbacks}')\n",
    "# print(f'days_eval:             {days_eval:>13}')\n",
    "# print(f'n_top_syms:            {n_top_syms:>13}')\n",
    "# print(f'syms_start:            {syms_start:>13}')\n",
    "# print(f'syms_end:              {syms_end:>13}')\n",
    "# print(f'grp(CAGR/UI)_mean:     {grp_CAGR_d_UI[0]:>13,.3f}')\n",
    "# print(f'grp(CAGR/UI)_std:      {grp_CAGR_d_UI[1]:>13,.3f}')\n",
    "# print(f'grp(CAGR/UI)_mean/std: {grp_CAGR_d_UI[2]:>13,.3f}')\n",
    "# print(f'SPY_CAGR/UI:           {SPY_CAGR_d_UI[0]:>13,.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
