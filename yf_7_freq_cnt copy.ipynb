{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 790)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "\n",
    "# fp_df_eval_results = 'df_eval_results'\n",
    "fp_df_eval_sym_freq_results = 'df_eval_sym_freq_results'\n",
    "\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_df_train: 1050, len_df_val: 300, len_df_test: 150 \n"
     ]
    }
   ],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "\n",
    "###################################\n",
    "# df_train, df_val, df_test = _2_split_train_val_test(df_close_clean, s_train=1, s_val=0, s_test=0)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)\n",
    "###################################\n",
    "\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_add_total:\n",
      "['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'sym_freq_cnt', 'grp(CAGR)_mean', 'grp(CAGR)_std', 'grp(CAGR)_mean/std', 'grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std', 'grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std', 'grp(retnStd/UI)_mean', 'grp(retnStd/UI)_std', 'grp(retnStd/UI)_mean/std', 'SPY_CAGR', 'SPY_CAGR/UI', 'SPY_CAGR/retnStd', 'SPY_retnStd/UI'], total columns: 23\n"
     ]
    }
   ],
   "source": [
    "col_add0 = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'sym_freq_cnt']\n",
    "col_add1 = ['grp(CAGR)_mean',         'grp(CAGR)_std',         'grp(CAGR)_mean/std']\n",
    "col_add2 = ['grp(CAGR/UI)_mean',      'grp(CAGR/UI)_std',      'grp(CAGR/UI)_mean/std']\n",
    "col_add3 = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "col_add4 = ['grp(retnStd/UI)_mean',   'grp(retnStd/UI)_std',   'grp(retnStd/UI)_mean/std']\n",
    "col_add5 = ['SPY_CAGR', 'SPY_CAGR/UI', 'SPY_CAGR/retnStd', 'SPY_retnStd/UI']\n",
    "\n",
    "col_add_total = col_add0 + col_add1 + col_add2 + col_add3 + col_add4 + col_add5\n",
    "print(f'col_add_total:\\n{col_add_total}, total columns: {len(col_add_total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# TODO why sym_freq_cnt max is 6\n",
    "####################################\n",
    "\n",
    "# df_eval_sym_freq_results = pickle_load(path_data_dump, fp_df_eval_sym_freq_results)\n",
    "# df_eval_sym_freq_results\n",
    "# # df_eval_sym_freq_results.sort_values(by='sym_freq_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True  # True prints more output\n",
    "# verbose = False  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "store_results = False\n",
    "# store_results = True\n",
    "\n",
    "# number of max lookback tuples to create for iloc start_train:end_train:end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "n_samples = 1\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback end_train\n",
    "# days_lookbacks = [15, 30, 60, 120]\n",
    "# days_lookbacks = [30, 60, 120]\n",
    "# days_lookbacks = [60, 120]\n",
    "# days_lookbacks = [120]\n",
    "# days_lookbacks = [60]\n",
    "# days_lookbacks = [30]\n",
    "# days_lookbacks = [15]\n",
    "# days_lookbacks = [15, 30]\n",
    "days_lookbacks = [15, 30, 60]\n",
    "# days_lookbacks = [28]\n",
    "# days_lookbacks = [32]\n",
    "# days_lookbacks = [31]\n",
    "# days_lookbacks = [29]\n",
    "# days_lookbacks = [15, 29]\n",
    "# days_lookbacks = [15, 31]\n",
    "# days_lookbacks = [14, 30]\n",
    "# days_lookbacks = [16, 32]\n",
    "# days_lookbacks = [14, 28]\n",
    "\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from end_train are used to evaluate effectiveness of the training\n",
    "# days_eval = 10\n",
    "# days_eval = 6\n",
    "# days_eval = 5\n",
    "days_eval = 4\n",
    "# days_eval = 3\n",
    "# days_eval = 2  \n",
    "\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "syms_start = 0  #  start index of n_top_syms for evaluation\n",
    "# syms_start = 1  #  start index of n_top_syms for evaluation\n",
    "\n",
    "# syms_end = n_top_syms  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 1  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 2  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 3  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 4  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 5  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 6  #  end index of n_top_syms for evaluation\n",
    "syms_end = 10  #  end index of n_top_syms for evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a sets of iloc lookback slices (start_train:end_train:end_eval), where  \n",
    "end_train - start_train = days_lookback  \n",
    "end_eval - end_train = days_eval  \n",
    "for example,  \n",
    "if given:  \n",
    " n_samples = 2  \n",
    " days_lookbacks = [30, 60, 120]  \n",
    " days_eval = 10  \n",
    "a possible result is:  \n",
    " max_lookback_slices:  \n",
    " [(150, 270, 280), (5, 125, 135)]  \n",
    " where 270-150=125-5=max(days_lookbacks), 280-270=135-125=days_eval  \n",
    " sets_lookback_slices:  \n",
    " [[(240, 270, 280), (210, 270, 280), (150, 270, 280)], [(95, 125, 135), (65, 125, 135), (5, 125, 135)]]  \n",
    "  where in a set, 270-240=days_lookbacks[0], 270-210=days_lookbacks[1], 270-150=days_lookbacks[2]  \n",
    "  and 270, i.e. end_train, is constant for the set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_lookback_slices:\n",
      "[(860, 920, 924)]\n",
      "sets_lookback_slices:\n",
      "[[(905, 920, 924), (890, 920, 924), (860, 920, 924)]]\n"
     ]
    }
   ],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}')\n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate lists, n_samples long, of the highest performance ranked symbols. The performance metrics are: CAGR/UI, CAGR/retnStd, retnStd/UI. n_top_syms of the best performing symbols from each metric are combined. The symbols are sorted by their number of appearances in the combined pool, and are placed in a list. A slice of the best performing symbols is selected by syms_start:syms_end, i.e. top_set_syms_n_freq[syms_start:syms_end].     \n",
    "\n",
    "The performance metrics are calculated based on slices in sets_lookback_slices.  The first two numbers are ilocs for training. The last two numbers are ilocs for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days lookback:    15\n",
      "lb_slices:        [(905, 920, 924), (890, 920, 924), (860, 920, 924)]\n",
      "lb_slice:         (905, 920, 924)\n",
      "days eval:        4\n",
      "iloc_start_train: 905\n",
      "iloc_end_train:   920\n",
      "date_start_train: 2020-10-14\n",
      "date_end_train:   2020-11-03\n",
      "perf_ranks: {'period-15': {'r_CAGR/UI': array(['AVXL', 'ALGN', 'ARLP', 'ARWR', 'TCBI', 'TPR', 'LOB', 'PNFP',\n",
      "       'DLB', 'DBRG', 'UBSI', 'YY', 'UMBF', 'NSP', 'FLR', 'PEN', 'SONY',\n",
      "       'BPOP', 'INDB', 'SSB'], dtype=object), 'r_CAGR/retnStd': array(['AVXL', 'ARWR', 'ARLP', 'ALGN', 'TPR', 'TCBI', 'LOB', 'PNFP',\n",
      "       'FLR', 'SSB', 'DLB', 'BANC', 'UMBF', 'UBSI', 'COLB', 'INDB',\n",
      "       'BPOP', 'OZK', 'UCBI', 'CMA'], dtype=object), 'r_retnStd/UI': array(['PNM', 'TCBI', 'AVXL', 'LOB', 'DBRG', 'ALGN', 'NSP', 'YY', 'TPR',\n",
      "       'PKI', 'DLB', 'MATX', 'MAT', 'PEN', 'SCI', 'SONY', 'WD', 'HOG',\n",
      "       'CB', 'SQM'], dtype=object)}}\n",
      "most_common_syms: [('AVXL', 3), ('ALGN', 3), ('TCBI', 3), ('TPR', 3), ('LOB', 3), ('DLB', 3), ('ARLP', 2), ('ARWR', 2), ('PNFP', 2), ('DBRG', 2), ('UBSI', 2), ('YY', 2), ('UMBF', 2), ('NSP', 2), ('FLR', 2), ('PEN', 2), ('SONY', 2), ('BPOP', 2), ('INDB', 2), ('SSB', 2), ('BANC', 1), ('COLB', 1), ('OZK', 1), ('UCBI', 1), ('CMA', 1), ('PNM', 1), ('PKI', 1), ('MATX', 1), ('MAT', 1), ('SCI', 1), ('WD', 1), ('HOG', 1), ('CB', 1), ('SQM', 1)]\n",
      "+++ finish lookback slice 15 +++\n",
      "\n",
      "days lookback:    30\n",
      "lb_slices:        [(905, 920, 924), (890, 920, 924), (860, 920, 924)]\n",
      "lb_slice:         (890, 920, 924)\n",
      "days eval:        4\n",
      "iloc_start_train: 890\n",
      "iloc_end_train:   920\n",
      "date_start_train: 2020-09-23\n",
      "date_end_train:   2020-11-03\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['LOB', 'MGI', 'DBRG', 'MATX', 'EXAS', 'TCBI', 'SPWR', 'NSP', 'PNM',\n",
      "       'PPBI', 'WD', 'ALGN', 'TPR', 'PNFP', 'EXLS', 'LSCC', 'FLR', 'UMBF',\n",
      "       'FOLD', 'OLN'], dtype=object), 'r_CAGR/retnStd': array(['LOB', 'MGI', 'SPWR', 'EXAS', 'DBRG', 'TCBI', 'MATX', 'PPBI',\n",
      "       'FLR', 'DAR', 'PNFP', 'DQ', 'OLN', 'TEX', 'UMBF', 'AVXL', 'TPR',\n",
      "       'FOLD', 'ACRS', 'DDS'], dtype=object), 'r_retnStd/UI': array(['PNM', 'LOB', 'MATX', 'NSP', 'DBRG', 'ALGN', 'TCBI', 'EXAS',\n",
      "       'EXLS', 'WD', 'MAT', 'CROX', 'LSCC', 'GRMN', 'DUK', 'HOG', 'X',\n",
      "       'GNRC', 'STAA', 'SQM'], dtype=object)}}\n",
      "most_common_syms: [('LOB', 3), ('DBRG', 3), ('MATX', 3), ('EXAS', 3), ('TCBI', 3), ('MGI', 2), ('SPWR', 2), ('NSP', 2), ('PNM', 2), ('PPBI', 2), ('WD', 2), ('ALGN', 2), ('TPR', 2), ('PNFP', 2), ('EXLS', 2), ('LSCC', 2), ('FLR', 2), ('UMBF', 2), ('FOLD', 2), ('OLN', 2), ('DAR', 1), ('DQ', 1), ('TEX', 1), ('AVXL', 1), ('ACRS', 1), ('DDS', 1), ('MAT', 1), ('CROX', 1), ('GRMN', 1), ('DUK', 1), ('HOG', 1), ('X', 1), ('GNRC', 1), ('STAA', 1), ('SQM', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "days lookback:    60\n",
      "lb_slices:        [(905, 920, 924), (890, 920, 924), (860, 920, 924)]\n",
      "lb_slice:         (860, 920, 924)\n",
      "days eval:        4\n",
      "iloc_start_train: 860\n",
      "iloc_end_train:   920\n",
      "date_start_train: 2020-08-11\n",
      "date_end_train:   2020-11-03\n",
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['LOB', 'GME', 'GOGO', 'SPWR', 'BLFS', 'OLN', 'STAA', 'CROX',\n",
      "       'ALGN', 'BKE', 'FDX', 'PWR', 'BGNE', 'PCTY', 'SLM', 'MEOH', 'CTRN',\n",
      "       'DAR', 'SAGE', 'TPR'], dtype=object), 'r_CAGR/retnStd': array(['GME', 'GOGO', 'LOB', 'SPWR', 'OLN', 'NVCR', 'TPR', 'FDX', 'BLFS',\n",
      "       'PCTY', 'BGNE', 'CROX', 'DQ', 'EAT', 'PWR', 'DDS', 'BOOT', 'STAA',\n",
      "       'HIBB', 'MEOH'], dtype=object), 'r_retnStd/UI': array(['ALGN', 'STAA', 'LOB', 'BLFS', 'BKE', 'GKOS', 'GME', 'CROX',\n",
      "       'QNST', 'SCHW', 'AQN', 'BFAM', 'AMN', 'PWR', 'GOGO', 'SLM', 'CORT',\n",
      "       'SAGE', 'PSA', 'DAR'], dtype=object)}}\n",
      "most_common_syms: [('LOB', 3), ('GME', 3), ('GOGO', 3), ('BLFS', 3), ('STAA', 3), ('CROX', 3), ('PWR', 3), ('SPWR', 2), ('OLN', 2), ('ALGN', 2), ('BKE', 2), ('FDX', 2), ('BGNE', 2), ('PCTY', 2), ('SLM', 2), ('MEOH', 2), ('DAR', 2), ('SAGE', 2), ('TPR', 2), ('CTRN', 1), ('NVCR', 1), ('DQ', 1), ('EAT', 1), ('DDS', 1), ('BOOT', 1), ('HIBB', 1), ('GKOS', 1), ('QNST', 1), ('SCHW', 1), ('AQN', 1), ('BFAM', 1), ('AMN', 1), ('CORT', 1), ('PSA', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "grp_most_common_syms: [[('AVXL', 3), ('ALGN', 3), ('TCBI', 3), ('TPR', 3), ('LOB', 3), ('DLB', 3), ('ARLP', 2), ('ARWR', 2), ('PNFP', 2), ('DBRG', 2), ('UBSI', 2), ('YY', 2), ('UMBF', 2), ('NSP', 2), ('FLR', 2), ('PEN', 2), ('SONY', 2), ('BPOP', 2), ('INDB', 2), ('SSB', 2), ('BANC', 1), ('COLB', 1), ('OZK', 1), ('UCBI', 1), ('CMA', 1), ('PNM', 1), ('PKI', 1), ('MATX', 1), ('MAT', 1), ('SCI', 1), ('WD', 1), ('HOG', 1), ('CB', 1), ('SQM', 1)], [('LOB', 3), ('DBRG', 3), ('MATX', 3), ('EXAS', 3), ('TCBI', 3), ('MGI', 2), ('SPWR', 2), ('NSP', 2), ('PNM', 2), ('PPBI', 2), ('WD', 2), ('ALGN', 2), ('TPR', 2), ('PNFP', 2), ('EXLS', 2), ('LSCC', 2), ('FLR', 2), ('UMBF', 2), ('FOLD', 2), ('OLN', 2), ('DAR', 1), ('DQ', 1), ('TEX', 1), ('AVXL', 1), ('ACRS', 1), ('DDS', 1), ('MAT', 1), ('CROX', 1), ('GRMN', 1), ('DUK', 1), ('HOG', 1), ('X', 1), ('GNRC', 1), ('STAA', 1), ('SQM', 1)], [('LOB', 3), ('GME', 3), ('GOGO', 3), ('BLFS', 3), ('STAA', 3), ('CROX', 3), ('PWR', 3), ('SPWR', 2), ('OLN', 2), ('ALGN', 2), ('BKE', 2), ('FDX', 2), ('BGNE', 2), ('PCTY', 2), ('SLM', 2), ('MEOH', 2), ('DAR', 2), ('SAGE', 2), ('TPR', 2), ('CTRN', 1), ('NVCR', 1), ('DQ', 1), ('EAT', 1), ('DDS', 1), ('BOOT', 1), ('HIBB', 1), ('GKOS', 1), ('QNST', 1), ('SCHW', 1), ('AQN', 1), ('BFAM', 1), ('AMN', 1), ('CORT', 1), ('PSA', 1)]]\n",
      "**** finish lookback slices [(905, 920, 924), (890, 920, 924), (860, 920, 924)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(905, 920, 924), (890, 920, 924), (860, 920, 924)]:\n",
      "[('LOB', 9), ('ALGN', 7), ('TPR', 7), ('TCBI', 6), ('DBRG', 5), ('AVXL', 4), ('CROX', 4), ('FLR', 4), ('MATX', 4), ('NSP', 4), ('OLN', 4), ('PNFP', 4), ('SPWR', 4), ('STAA', 4), ('UMBF', 4), ('BLFS', 3), ('DAR', 3), ('DLB', 3), ('EXAS', 3), ('GME', 3)]\n",
      "top 20 ranked symbols from set [(905, 920, 924), (890, 920, 924), (860, 920, 924)]:\n",
      "['LOB', 'ALGN', 'TPR', 'TCBI', 'DBRG', 'AVXL', 'CROX', 'FLR', 'MATX', 'NSP']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(905, 920, 924), (890, 920, 924), (860, 920, 924)] =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # list of lists of top_set_symbols, there are n_samples lists in list\n",
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for lb_slices in sets_lookback_slices:\n",
    "  grp_most_common_syms = []  \n",
    "  for lb_slice in lb_slices:  # lb_slice, e.g. (246, 276, 286)\n",
    "    start_train = lb_slice[0]\n",
    "    end_train = lb_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = lb_slice[2]\n",
    "    lookback = end_train - start_train\n",
    "    d_eval = end_eval - start_eval\n",
    "\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    date_start_train = _df.index[0].strftime('%Y-%m-%d')\n",
    "    date_end_train = _df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback:    {lookback}')\n",
    "      print(f'lb_slices:        {lb_slices}')\n",
    "      print(f'lb_slice:         {lb_slice}')\n",
    "      print(f'days eval:        {d_eval}')    \n",
    "      print(f'iloc_start_train: {start_train}')\n",
    "      print(f'iloc_end_train:   {end_train}')\n",
    "      print(f'date_start_train: {date_start_train}')\n",
    "      print(f'date_end_train:   {date_end_train}')\n",
    "\n",
    "\n",
    "    perf_ranks, most_common_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "    grp_most_common_syms.append(most_common_syms)\n",
    "    \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_common_syms: {most_common_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "    # grp_most_common_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "  # group symbols from set of days_lookbacks (i.e. lb_slices) and sum frequency of the symbols\n",
    "  set_most_common_syms = _6_grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "  # get the top few most-frequent symbol:frequency pairs\n",
    "  top_set_syms_n_freq = set_most_common_syms[0:n_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq\n",
    "\n",
    "###################################  \n",
    "  # top_set_syms = [i[0] for i in top_set_syms_n_freq]\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "###################################  \n",
    "  \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_set_sym_freq_cnt(top_set_syms_n_freq):\n",
    "    sym_freq_cnt_6 = []\n",
    "    sym_freq_cnt_5 = []\n",
    "    sym_freq_cnt_4 = []\n",
    "    sym_freq_cnt_3 = []\n",
    "    sym_freq_cnt_2 = []\n",
    "\n",
    "    for sym_n_freq in top_set_syms_n_freq:\n",
    "        _sym = sym_n_freq[0]\n",
    "        _freq = sym_n_freq[1]\n",
    "        # print(_sym, _freq)\n",
    "        if _freq == 6:\n",
    "            sym_freq_cnt_6.append(_sym)\n",
    "        elif _freq == 5:\n",
    "            sym_freq_cnt_5.append(_sym)\n",
    "        elif _freq == 4:\n",
    "            sym_freq_cnt_4.append(_sym)\n",
    "        elif _freq == 3:\n",
    "            sym_freq_cnt_3.append(_sym)          \n",
    "        else:\n",
    "            sym_freq_cnt_2.append(_sym)\n",
    "\n",
    "    l_sym_freq_cnt = []\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_6)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_5)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_4)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_3)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_2)    \n",
    "\n",
    "    # if verbose:\n",
    "    #     print(f'sym_freq_cnt_6: {sym_freq_cnt_6}')\n",
    "    #     print(f'sym_freq_cnt_5: {sym_freq_cnt_5}')\n",
    "    #     print(f'sym_freq_cnt_4: {sym_freq_cnt_4}')\n",
    "    #     print(f'sym_freq_cnt_3: {sym_freq_cnt_3}')\n",
    "    #     print(f'sym_freq_cnt_2: {sym_freq_cnt_2}')\n",
    "\n",
    "    # return sym_freq_cnt_6, sym_freq_cnt_5, sym_freq_cnt_4, sym_freq_cnt_3, sym_freq_cnt_2\n",
    "    return l_sym_freq_cnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sym_freq_6: ['TCBI']\n",
      "sym_freq_5: ['DBRG']\n",
      "sym_freq_4: ['AVXL', 'CROX', 'FLR', 'MATX', 'NSP', 'OLN', 'PNFP', 'SPWR', 'STAA', 'UMBF']\n",
      "sym_freq_3: ['BLFS', 'DAR', 'DLB', 'EXAS', 'GME']\n",
      "sym_freq_2: ['LOB', 'ALGN', 'TPR']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for top_set_syms_n_freq in grp_top_set_syms_n_freq:\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "  print(f'sym_freq_6: {l_sym_freq_cnt[0]}')\n",
    "  print(f'sym_freq_5: {l_sym_freq_cnt[1]}')\n",
    "  print(f'sym_freq_4: {l_sym_freq_cnt[2]}')\n",
    "  print(f'sym_freq_3: {l_sym_freq_cnt[3]}')\n",
    "  print(f'sym_freq_2: {l_sym_freq_cnt[4]}\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "1 of 1 max_lookback_slice\n",
      "max_lookback_slice: (860, 920, 924)\n",
      "max lookback dates: 2020-08-11, 2020-11-04, 2020-11-10\n",
      "df_eval dates (inclusive): 2020-11-04 - 2020-11-09\n",
      "top_set_syms_n_freq: [('LOB', 9), ('ALGN', 7), ('TPR', 7), ('TCBI', 6), ('DBRG', 5), ('AVXL', 4), ('CROX', 4), ('FLR', 4), ('MATX', 4), ('NSP', 4), ('OLN', 4), ('PNFP', 4), ('SPWR', 4), ('STAA', 4), ('UMBF', 4), ('BLFS', 3), ('DAR', 3), ('DLB', 3), ('EXAS', 3), ('GME', 3)]\n",
      "\n",
      "sym_freq_6: ['TCBI']\n",
      "sym_freq_5: ['DBRG']\n",
      "sym_freq_4: ['AVXL', 'CROX', 'FLR', 'MATX', 'NSP', 'OLN', 'PNFP', 'SPWR', 'STAA', 'UMBF']\n",
      "sym_freq_3: ['BLFS', 'DAR', 'DLB', 'EXAS', 'GME']\n",
      "\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR:              71.5,           1,613.3,          115420.2,              13.2\n",
      "start_eval: 920,  date: 2020-11-04\n",
      "end_eval:   924,  date: 2020-11-10,  df_eval last date: 2020-11-09\n",
      "frequency count of symbol(s): 6\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                 TCBI         SPY\n",
      "Date                             \n",
      "2020-11-04  43.970001  339.853241\n",
      "2020-11-05  44.549999  346.481323\n",
      "2020-11-06  44.020000  346.402161\n",
      "2020-11-09  51.380001  350.754944\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:              13.3,               0.0,               inf\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       6,066,781.3,               0.0,               inf\n",
      "grp(CAGR/UI):      mean, std, mean/std:      80,753,796.8,               0.0,               inf\n",
      "grp(CAGR):         mean, std, mean/std:         480,352.6,               0.0,               inf\n",
      "start_eval: 920,  date: 2020-11-04\n",
      "end_eval:   924,  date: 2020-11-10,  df_eval last date: 2020-11-09\n",
      "frequency count of symbol(s): 5\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                 DBRG         SPY\n",
      "Date                             \n",
      "2020-11-04  14.695085  339.853241\n",
      "2020-11-05  14.934678  346.481323\n",
      "2020-11-06  14.974609  346.402161\n",
      "2020-11-09  14.974609  350.754944\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:          14,279.3,               0.0,               inf\n",
      "grp(CAGR/retnStd): mean, std, mean/std:             541.9,               0.0,               inf\n",
      "grp(CAGR/UI):      mean, std, mean/std:       7,737,257.2,               0.0,               inf\n",
      "grp(CAGR):         mean, std, mean/std:               3.9,               0.0,               inf\n",
      "start_eval: 920,  date: 2020-11-04\n",
      "end_eval:   924,  date: 2020-11-10,  df_eval last date: 2020-11-09\n",
      "frequency count of symbol(s): 4\n",
      "\n",
      "df_eval_n_SPY:\n",
      "            AVXL       CROX    FLR       MATX        NSP        OLN       PNFP       SPWR       STAA       UMBF         SPY\n",
      "Date                                                                                                                       \n",
      "2020-11-04  6.34  56.040001  12.37  53.189377  83.634636  16.927307  42.882740  16.570000  73.190002  58.983372  339.853241\n",
      "2020-11-05  7.58  58.830002  13.01  54.931046  85.053970  19.438608  45.082626  19.389999  72.160004  61.125408  346.481323\n",
      "2020-11-06  4.91  58.330002  12.65  54.392887  83.933952  19.994541  44.375877  20.330000  79.769997  59.311432  346.402161\n",
      "2020-11-09  4.91  55.250000  13.50  57.533760  88.935432  19.781631  50.905834  19.260000  80.889999  65.216507  350.754944\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:               5.1,               3.4,               1.5\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       3,780,287.9,       8,063,701.5,               0.5\n",
      "grp(CAGR/UI):      mean, std, mean/std:      33,420,179.3,      70,934,062.6,               0.5\n",
      "grp(CAGR):         mean, std, mean/std:         260,902.8,         539,445.7,               0.5\n",
      "start_eval: 920,  date: 2020-11-04\n",
      "end_eval:   924,  date: 2020-11-10,  df_eval last date: 2020-11-09\n",
      "frequency count of symbol(s): 3\n",
      "\n",
      "df_eval_n_SPY:\n",
      "                 BLFS        DAR        DLB        EXAS     GME         SPY\n",
      "Date                                                                       \n",
      "2020-11-04  31.990000  43.720001  79.343079  123.150002  2.7275  339.853241\n",
      "2020-11-05  31.389999  45.730000  82.470184  126.680000  2.8625  346.481323\n",
      "2020-11-06  33.830002  44.360001  82.382790  123.970001  2.9650  346.402161\n",
      "2020-11-09  32.099998  46.599998  83.596733  123.160004  2.8725  350.754944\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:               7.9,              11.8,               0.7\n",
      "grp(CAGR/retnStd): mean, std, mean/std:           2,534.7,           2,372.2,               1.1\n",
      "grp(CAGR/UI):      mean, std, mean/std:          33,769.9,          58,249.4,               0.6\n",
      "grp(CAGR):         mean, std, mean/std:              73.5,              77.2,               1.0\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from myUtils import symb_perf_stats_vectorized_v8\n",
    "\n",
    "print('z_grp_top_set_syms_n_freq:')\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "\n",
    "for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "  start_train = _lookback_slice[0]\n",
    "  end_train = _lookback_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  d_start_train = df_train.index[start_train].strftime('%Y-%m-%d')\n",
    "  d_end_train = df_train.index[end_train].strftime('%Y-%m-%d')\n",
    "  d_start_eval = d_end_train\n",
    "  d_end_eval = df_train.index[end_eval].strftime('%Y-%m-%d')\n",
    "  d_df_eval_start = d_end_train\n",
    "  d_df_eval_end = df_train.index[end_eval - 1].strftime('%Y-%m-%d')  \n",
    "  print(f'max lookback dates: {d_start_train}, {d_end_train}, {d_end_eval}')\n",
    "  print(f'df_eval dates (inclusive): {d_df_eval_start} - {d_df_eval_end}')    \n",
    "  print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}\\n')\n",
    "\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(_top_set_syms_n_freq)\n",
    "  print(f'sym_freq_6: {l_sym_freq_cnt[0]}')\n",
    "  print(f'sym_freq_5: {l_sym_freq_cnt[1]}')\n",
    "  print(f'sym_freq_4: {l_sym_freq_cnt[2]}')\n",
    "  print(f'sym_freq_3: {l_sym_freq_cnt[3]}\\n')\n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df_train[start_eval:end_eval][_sym_idx]\n",
    "\n",
    "  (\n",
    "    _symbols,\n",
    "    _period_yr,\n",
    "    _retn,\n",
    "    _DD,\n",
    "    _UI,\n",
    "    _MDD,\n",
    "    _retnMean,\n",
    "    _retnStd,\n",
    "    _retnStd_div_UI,\n",
    "    _CAGR,\n",
    "    _CAGR_div_retnStd,\n",
    "    _CAGR_div_UI,\n",
    "    SPY_retnStd_d_UI,     \n",
    "    SPY_CAGR,\n",
    "    SPY_CAGR_d_retnStd,\n",
    "    SPY_CAGR_d_UI,\n",
    "  ) = symb_perf_stats_vectorized_v8(df_SPY)  \n",
    "\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR: {SPY_retnStd_d_UI[0]:>17,.1f}, {SPY_CAGR_d_retnStd[0]:>17,.1f}, {SPY_CAGR_d_UI[0]:>17.1f}, {SPY_CAGR[0]:>17.1f}')\n",
    "\n",
    "  # drop last list, with frequency count 2 or less, in l_sym_freq_cnt from zip\n",
    "  zip_cnt_n_syms = zip([6,5,4,3], l_sym_freq_cnt[:-1])  \n",
    "  for item in zip_cnt_n_syms:\n",
    "    sym_freq_cnt = item[0]\n",
    "    syms = item[1]\n",
    "    if syms:  # iterate ONLY if there are symbols in syms\n",
    "      df_eval = df_train[start_eval:end_eval][syms]      \n",
    "\n",
    "      if verbose:\n",
    "        print(f'start_eval: {start_eval},  date: {d_end_train}')\n",
    "        print(f'end_eval:   {end_eval},  date: {d_end_eval},  df_eval last date: {d_df_eval_end}')\n",
    "        print(f'frequency count of symbol(s): {sym_freq_cnt}')      \n",
    "        # print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "        syms_n_SPY = syms + ['SPY']\n",
    "        df_eval_n_SPY = df_train[start_eval:end_eval][syms_n_SPY]   \n",
    "        print(f'\\ndf_eval_n_SPY:\\n{df_eval_n_SPY}\\n')\n",
    "\n",
    "      (\n",
    "        _symbols,\n",
    "        _period_yr,\n",
    "        _retn,\n",
    "        _DD,\n",
    "        _UI,\n",
    "        _MDD,\n",
    "        _retnMean,\n",
    "        _retnStd,\n",
    "        _retnStd_div_UI,\n",
    "        _CAGR,\n",
    "        _CAGR_div_retnStd,\n",
    "        _CAGR_div_UI,\n",
    "        grp_retnStd_d_UI,     \n",
    "        grp_CAGR,\n",
    "        grp_CAGR_d_retnStd,\n",
    "        grp_CAGR_d_UI,\n",
    "      ) = symb_perf_stats_vectorized_v8(df_eval)  \n",
    "      print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>17,.1f}, {grp_retnStd_d_UI[1]  :>17,.1f}, {grp_retnStd_d_UI[2]  :>17,.1f}')\n",
    "      print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>17,.1f}, {grp_CAGR_d_retnStd[1]:>17,.1f}, {grp_CAGR_d_retnStd[2]:>17,.1f}')\n",
    "      print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>17,.1f}, {grp_CAGR_d_UI[1]     :>17,.1f}, {grp_CAGR_d_UI[2]     :>17,.1f}')\n",
    "      print(f'grp(CAGR):         mean, std, mean/std: {grp_CAGR[0]          :>17,.1f}, {grp_CAGR[1]          :>17,.1f}, {grp_CAGR[2]          :>17,.1f}')\n",
    "\n",
    "      if store_results:  # record results to df\n",
    "        row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt]\n",
    "        row_add1      = [grp_CAGR[0],           grp_CAGR[1],           grp_CAGR[2]]\n",
    "        row_add2      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "        row_add3      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "        row_add4      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "        row_add5      = [SPY_CAGR[0], SPY_CAGR_d_UI[0], SPY_CAGR_d_retnStd[0], SPY_retnStd_d_UI[0]]\n",
    "        row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4 + row_add5\n",
    "        print(f'row_add_total: {row_add_total}')\n",
    "        df_eval_sym_freq_results.loc[len(df_eval_sym_freq_results)] = row_add_total\n",
    "        print(f'appended row_add to df_eval_sym_freq_results:\\n{row_add_total}\\n')\n",
    "  \n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if store_results:  # record results to df\n",
    "  pickle_dump(df_eval_sym_freq_results, path_data_dump, fp_df_eval_sym_freq_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pandas-groupby-a-simple-but-detailed-tutorial-314b8f37005d\n",
    "# https://towardsdatascience.com/accessing-data-in-a-multiindex-dataframe-in-pandas-569e8767201d\n",
    "# https://towardsdatascience.com/summarizing-data-with-pandas-crosstab-efc8b9abecf\n",
    "# https://towardsdatascience.com/how-to-flatten-multiindex-columns-and-rows-in-pandas-f5406c50e569\n",
    "# https://datascientyst.com/list-aggregation-functions-aggfunc-groupby-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results)\n",
    "# df.sort_values(by='sym_freq_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.crosstab(df['days_lookbacks'], df['grp(CAGR/UI)_mean'])\n",
    "# tbl = df.groupby(['days_lookbacks', 'days_eval', 'sym_freq_cnt'])\\\n",
    "#         .agg({'grp(CAGR)_mean':          ['count', 'mean', 'std',],\n",
    "#               'grp(CAGR/UI)_mean':       ['mean', 'std',],\n",
    "#               'grp(CAGR/retnStd)_mean':  ['mean', 'std',],\n",
    "#               'SPY_CAGR':                ['mean', 'std',],\n",
    "#               'SPY_CAGR/UI':             ['mean', 'std',],\n",
    "#               'SPY_CAGR/retnStd':        ['mean', 'std',],                           \n",
    "#               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tbl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11312\\1189757121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtbl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tbl' is not defined"
     ]
    }
   ],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl['dif_CAGR_mean'] = tbl['grp(CAGR)_mean', 'mean'] - tbl['SPY_CAGR', 'mean']\n",
    "# tbl['dif_CAGR/UI_mean'] = tbl['grp(CAGR/UI)_mean', 'mean'] - tbl['SPY_CAGR/UI', 'mean'] \n",
    "# tbl['dif_CAGR/retnStd_mean'] = tbl['grp(CAGR/retnStd)_mean', 'mean'] - tbl['SPY_CAGR/retnStd', 'mean'] \n",
    "# tbl['grp_CAGR/UI_mean/std'] = tbl['grp(CAGR/UI)_mean', 'mean'] / tbl['grp(CAGR/UI)_mean', 'std']  \n",
    "# tbl['SPY_CAGR/UI_mean/std'] = tbl['SPY_CAGR/UI', 'mean'] / tbl['SPY_CAGR/UI', 'std'] \n",
    "# tbl['dif_CAGR/UI_mean/std'] = tbl['grp_CAGR/UI_mean/std']  - tbl['SPY_CAGR/UI_mean/std'] \n",
    "# # tbl.sort_values(by='dif_CAGR/UI_mean', ascending=False, inplace=True)\n",
    "# # tbl.sort_values(by='dif_CAGR/UI_mean/std', ascending=False, inplace=True)\n",
    "# # tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl.sort_values(by='dif_CAGR/UI_mean', ascending=False, inplace=True)\n",
    "# tbl.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl.sort_values(by='dif_CAGR/UI_mean/std', ascending=False, inplace=True)\n",
    "# tbl.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "  # from IPython.display import display, HTML\n",
    "  # from myUtils import symb_perf_stats_vectorized_v8\n",
    "  df = df_eval.copy()\n",
    "  df_SPY = df_SPY.copy()  \n",
    "  _my_df = [df_eval, df_SPY]\n",
    "  for _df in _my_df:\n",
    "    # print(f'_df:\\n{_df}')\n",
    "    (\n",
    "      symbols,\n",
    "      period_yr,\n",
    "      retn,\n",
    "      DD,\n",
    "      UI,\n",
    "      MDD,\n",
    "      retnMean,\n",
    "      retnStd,\n",
    "      retnStd_div_UI,\n",
    "      CAGR,\n",
    "      CAGR_div_retnStd,\n",
    "      CAGR_div_UI,\n",
    "      grp_retnStd_div_UI,     \n",
    "      grp_CAGR,\n",
    "      grp_CAGR_div_retnStd,\n",
    "      grp_CAGR_div_UI,\n",
    "    ) = symb_perf_stats_vectorized_v8(_df)\n",
    "\n",
    "    # display(HTML(_df.to_html()))\n",
    "    print(f'_df:\\n{_df}\\n')\n",
    "    print(f'symbols:\\n{symbols}\\n')\n",
    "    print(f'period_yr:\\n{period_yr}\\n')\n",
    "    print(f'retn:\\n{retn}\\n')\n",
    "    print(f'DD:\\n{DD}\\n')\n",
    "    print(f'UI:\\n{UI}\\n')\n",
    "    print(f'MDD:\\n{MDD}\\n')\n",
    "    print(f'retnMean:\\n{retnMean}\\n')\n",
    "    print(f'retnStd:\\n{retnStd}\\n')\n",
    "    print(f'retnStd_div_UI:\\n{retnStd_div_UI}\\n')\n",
    "    print(f'CAGR:\\n{CAGR}\\n')\n",
    "    print(f'CAGR_div_retnStd:\\n{CAGR_div_retnStd}\\n')\n",
    "    print(f'CAGR_div_UI:\\n{CAGR_div_UI}\\n')\n",
    "    print(f'grp_retnStd_div_UI:\\n{grp_retnStd_div_UI}\\n')\n",
    "    print(f'grp_CAGR:\\n{grp_CAGR}\\n')\n",
    "    print(f'grp_CAGR_div_retnStd:\\n{grp_CAGR_div_retnStd}\\n')\n",
    "    print(f'grp_CAGR_div_UI:\\n{grp_CAGR_div_UI}\\n')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/31674195/plot-normal-distribution-given-mean-and-sigma-python\n",
    "# # loc is mean, scale is standard deviation\n",
    "# import pylab\n",
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "# # x = np.linspace(-10000,100000,1000)\n",
    "# x = np.linspace(-40e+10,50e+10,1000)\n",
    "# y = norm.pdf(x, loc=2.562777e+10, scale=1.036925e+11)    # loc = mean, scale = standard deviation\n",
    "# # z = norm.pdf(x, loc=3.540615e+10, scale=1.194430e+11)    # for example\n",
    "# # z1 = norm.pdf(x, loc=298.805901, scale=826.875749)    # for example\n",
    "# # z1 = norm.pdf(x, loc=1.021825, scale=1.505096)    # for example\n",
    "# pylab.plot(x,y, 'b')\n",
    "# # pylab.plot(x,z, 'g')\n",
    "# # pylab.plot(x,z1, 'r')\n",
    "# pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get values of _cols, where grp(CAGR/retnStd)_mean is max after filtering out inf\n",
    "# _cols = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "# # _df_no_inf = df.loc[df['grp(CAGR/retnStd)_mean'] != np.inf]  # df with filter out inf in column grp(CAGR/UI)_mean \n",
    "# # _idx = _df_no_inf['grp(CAGR/retnStd)_mean'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# _idx = df['grp(CAGR/retnStd)_mean'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# grp_inf_replacement = df.loc[[_idx], _cols].squeeze()  # convert df (only has 1 row) to series\n",
    "# print(f'_idx: {_idx}')\n",
    "# grp_inf_replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get values of _cols, where SPY_CAGR/retnStd is max after filtering out inf\n",
    "# _cols = ['SPY_CAGR/retnStd']\n",
    "# # _df_no_inf = df.loc[df['SPY_CAGR/retnStd'] != np.inf]  # df with filter out inf in column grp(CAGR/UI)_mean \n",
    "# _idx = df['SPY_CAGR/retnStd'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# SPY_inf_replacement = df.loc[[_idx], _cols].squeeze()  # convert df (only has 1 row) to series\n",
    "# print(f'_idx: {_idx}')\n",
    "# SPY_inf_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
