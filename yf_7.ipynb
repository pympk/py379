{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "verbose = True  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of max lookback tuples to create for iloc start_train:end_train:end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "n_samples = 2  \n",
    "# n_samples = 100\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback end_train\n",
    "days_lookbacks = [30, 120, 60]\n",
    "\n",
    "# number of days from end_train are used to evaluate effectiveness of the training\n",
    "days_eval = 10  \n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "# set_top_syms = 5\n",
    "set_top_syms = 5  \n",
    "\n",
    "syms_start = 0  #  start index of set_top_syms for evaluation\n",
    "syms_end = 4  #  end index of set_top_syms for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sets of iloc lookback slices (start_train:end_train:end_eval), where\n",
    "# end_train - start_train = days_lookback\n",
    "# end_eval - end_train = days_eval\n",
    "# for example,\n",
    "# if given:\n",
    "#  n_samples = 2\n",
    "#  days_lookbacks = [30, 60, 120]\n",
    "#  days_eval = 10\n",
    "# a possible result is:\n",
    "#  max_lookback_slices:\n",
    "#  [(150, 270, 280), (5, 125, 135)]\n",
    "#  sets_lookback_slices:\n",
    "#  [[(240, 270, 280), (210, 270, 280), (150, 270, 280)], [(95, 125, 135), (65, 125, 135), (5, 125, 135)]]  \n",
    "max_lookback_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval)\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}')\n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate n_samples of lists of the highest performance ranked symbols. The performance metrics are: CAGR/UI, CAGR/retnStd, retnStd/UI. The top symbols, specified by set_top_syms, from each metric are combined. Symbols are sorted by their frequency and place into a list. The top symbols are the ones with the most frequent counts. The list of top symbols are return as specified by syms_start:syms_end, i.e. top_set_syms_n_freq[syms_start:syms_end].            \n",
    "\n",
    "The sets_lookback_slices are iloc for training and evaluation dataframes. The sets is randomly generated.   \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days lookback: 30\n",
      "lb_slices:     [(340, 370, 380), (310, 370, 380), (250, 370, 380)]\n",
      "lb_slice:      (340, 370, 380)\n",
      "days eval:     10\n",
      "start_train:   340\n",
      "end_train:     370\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['NTRA', 'BLFS', 'TNDM', 'XENE', 'RAMP'], dtype=object), 'r_CAGR/retnStd': array(['NTRA', 'BLFS', 'TNDM', 'XENE', 'ARWR'], dtype=object), 'r_retnStd/UI': array(['RPM', 'RCII', 'DRI', 'RAMP', 'KDP'], dtype=object)}}\n",
      "most_common_syms: [('NTRA', 2), ('BLFS', 2), ('TNDM', 2), ('XENE', 2), ('RAMP', 2), ('ARWR', 1), ('RPM', 1), ('RCII', 1), ('DRI', 1), ('KDP', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "days lookback: 60\n",
      "lb_slices:     [(340, 370, 380), (310, 370, 380), (250, 370, 380)]\n",
      "lb_slice:      (310, 370, 380)\n",
      "days eval:     10\n",
      "start_train:   310\n",
      "end_train:     370\n",
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['TNDM', 'WWE', 'BLFS', 'ARWR', 'CYRX'], dtype=object), 'r_CAGR/retnStd': array(['TNDM', 'BLFS', 'ARWR', 'CYRX', 'WWE'], dtype=object), 'r_retnStd/UI': array(['RAMP', 'WWE', 'KDP', 'ABR', 'TTD'], dtype=object)}}\n",
      "most_common_syms: [('WWE', 3), ('TNDM', 2), ('BLFS', 2), ('ARWR', 2), ('CYRX', 2), ('RAMP', 1), ('KDP', 1), ('ABR', 1), ('TTD', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "days lookback: 120\n",
      "lb_slices:     [(340, 370, 380), (310, 370, 380), (250, 370, 380)]\n",
      "lb_slice:      (250, 370, 380)\n",
      "days eval:     10\n",
      "start_train:   250\n",
      "end_train:     370\n",
      "perf_ranks: {'period-120': {'r_CAGR/UI': array(['TNDM', 'WWE', 'XENE', 'AXON', 'BLFS'], dtype=object), 'r_CAGR/retnStd': array(['TNDM', 'BLFS', 'XENE', 'WWE', 'ENPH'], dtype=object), 'r_retnStd/UI': array(['KDP', 'FTSM', 'AXON', 'ETSY', 'WWE'], dtype=object)}}\n",
      "most_common_syms: [('WWE', 3), ('TNDM', 2), ('XENE', 2), ('AXON', 2), ('BLFS', 2), ('ENPH', 1), ('KDP', 1), ('FTSM', 1), ('ETSY', 1)]\n",
      "+++ finish lookback slice 120 +++\n",
      "\n",
      "grp_most_common_syms: [[('NTRA', 2), ('BLFS', 2), ('TNDM', 2), ('XENE', 2), ('RAMP', 2), ('ARWR', 1), ('RPM', 1), ('RCII', 1), ('DRI', 1), ('KDP', 1)], [('WWE', 3), ('TNDM', 2), ('BLFS', 2), ('ARWR', 2), ('CYRX', 2), ('RAMP', 1), ('KDP', 1), ('ABR', 1), ('TTD', 1)], [('WWE', 3), ('TNDM', 2), ('XENE', 2), ('AXON', 2), ('BLFS', 2), ('ENPH', 1), ('KDP', 1), ('FTSM', 1), ('ETSY', 1)]]\n",
      "**** finish lookback slices [(340, 370, 380), (310, 370, 380), (250, 370, 380)] ****\n",
      "\n",
      "top 5 ranked symbols and frequency from set [(340, 370, 380), (310, 370, 380), (250, 370, 380)]:\n",
      "[('BLFS', 6), ('TNDM', 6), ('WWE', 6), ('XENE', 4), ('ARWR', 3)]\n",
      "top 5 ranked symbols from set [(340, 370, 380), (310, 370, 380), (250, 370, 380)]:\n",
      "['BLFS', 'TNDM', 'WWE', 'XENE']\n",
      "===== finish top 5 ranked symbols from days_lookback set [(340, 370, 380), (310, 370, 380), (250, 370, 380)] =====\n",
      "\n",
      "\n",
      "days lookback: 30\n",
      "lb_slices:     [(948, 978, 988), (918, 978, 988), (858, 978, 988)]\n",
      "lb_slice:      (948, 978, 988)\n",
      "days eval:     10\n",
      "start_train:   948\n",
      "end_train:     978\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['CHRD', 'SM', 'JWN', 'CPE', 'MARA'], dtype=object), 'r_CAGR/retnStd': array(['CHRD', 'SM', 'JWN', 'CPE', 'MARA'], dtype=object), 'r_retnStd/UI': array(['CHRD', 'PERI', 'MYI', 'ZD', 'IFN'], dtype=object)}}\n",
      "most_common_syms: [('CHRD', 3), ('SM', 2), ('JWN', 2), ('CPE', 2), ('MARA', 2), ('PERI', 1), ('MYI', 1), ('ZD', 1), ('IFN', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "days lookback: 60\n",
      "lb_slices:     [(948, 978, 988), (918, 978, 988), (858, 978, 988)]\n",
      "lb_slice:      (918, 978, 988)\n",
      "days eval:     10\n",
      "start_train:   918\n",
      "end_train:     978\n",
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['CHRD', 'FATE', 'DBRG', 'RCKT', 'SM'], dtype=object), 'r_CAGR/retnStd': array(['CHRD', 'SM', 'FATE', 'MARA', 'NTLA'], dtype=object), 'r_retnStd/UI': array(['CHRD', 'RCKT', 'DBRG', 'FATE', 'TCBI'], dtype=object)}}\n",
      "most_common_syms: [('CHRD', 3), ('FATE', 3), ('DBRG', 2), ('RCKT', 2), ('SM', 2), ('MARA', 1), ('NTLA', 1), ('TCBI', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "days lookback: 120\n",
      "lb_slices:     [(948, 978, 988), (918, 978, 988), (858, 978, 988)]\n",
      "lb_slice:      (858, 978, 988)\n",
      "days eval:     10\n",
      "start_train:   858\n",
      "end_train:     978\n",
      "perf_ranks: {'period-120': {'r_CAGR/UI': array(['CHRD', 'SPWR', 'LOB', 'BBWI', 'DAR'], dtype=object), 'r_CAGR/retnStd': array(['SPWR', 'LOB', 'APPS', 'MARA', 'NVCR'], dtype=object), 'r_retnStd/UI': array(['CHRD', 'BBWI', 'MATX', 'DAR', 'XYL'], dtype=object)}}\n",
      "most_common_syms: [('CHRD', 2), ('SPWR', 2), ('LOB', 2), ('BBWI', 2), ('DAR', 2), ('APPS', 1), ('MARA', 1), ('NVCR', 1), ('MATX', 1), ('XYL', 1)]\n",
      "+++ finish lookback slice 120 +++\n",
      "\n",
      "grp_most_common_syms: [[('CHRD', 3), ('SM', 2), ('JWN', 2), ('CPE', 2), ('MARA', 2), ('PERI', 1), ('MYI', 1), ('ZD', 1), ('IFN', 1)], [('CHRD', 3), ('FATE', 3), ('DBRG', 2), ('RCKT', 2), ('SM', 2), ('MARA', 1), ('NTLA', 1), ('TCBI', 1)], [('CHRD', 2), ('SPWR', 2), ('LOB', 2), ('BBWI', 2), ('DAR', 2), ('APPS', 1), ('MARA', 1), ('NVCR', 1), ('MATX', 1), ('XYL', 1)]]\n",
      "**** finish lookback slices [(948, 978, 988), (918, 978, 988), (858, 978, 988)] ****\n",
      "\n",
      "top 5 ranked symbols and frequency from set [(948, 978, 988), (918, 978, 988), (858, 978, 988)]:\n",
      "[('CHRD', 8), ('MARA', 4), ('SM', 4), ('FATE', 3), ('BBWI', 2)]\n",
      "top 5 ranked symbols from set [(948, 978, 988), (918, 978, 988), (858, 978, 988)]:\n",
      "['CHRD', 'MARA', 'SM', 'FATE']\n",
      "===== finish top 5 ranked symbols from days_lookback set [(948, 978, 988), (918, 978, 988), (858, 978, 988)] =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # list of lists of top_set_symbols, there are n_samples lists in list\n",
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for lb_slices in sets_lookback_slices:\n",
    "  grp_most_common_syms = []  \n",
    "  for lb_slice in lb_slices:  # lb_slice, e.g. (246, 276, 286)\n",
    "    start_train = lb_slice[0]\n",
    "    end_train = lb_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = lb_slice[2]\n",
    "    lookback = end_train - start_train\n",
    "    d_eval = end_eval - start_eval\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback: {lookback}')\n",
    "      print(f'lb_slices:     {lb_slices}')\n",
    "      print(f'lb_slice:      {lb_slice}')\n",
    "      print(f'days eval:     {d_eval}')    \n",
    "      print(f'start_train:   {start_train}')\n",
    "      print(f'end_train:     {end_train}')\n",
    "      # print(f'start_eval:    {start_eval}')\n",
    "      # print(f'end_eval:      {end_eval}')`\n",
    "\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, most_common_syms = _5_perf_ranks(_df, n_top_syms=set_top_syms)\n",
    "    grp_most_common_syms.append(most_common_syms)\n",
    "    \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_common_syms: {most_common_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "    # grp_most_common_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "  # group symbols from set of days_lookbacks (i.e. lb_slices) and sum frequency of the symbols\n",
    "  set_most_common_syms = _6_grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "  # get the top few most-frequent symbol:frequency pairs\n",
    "  top_set_syms_n_freq = set_most_common_syms[0:set_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq\n",
    "\n",
    "###################################  \n",
    "  # top_set_syms = [i[0] for i in top_set_syms_n_freq]\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "###################################  \n",
    "  \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {set_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {set_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {set_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms:\n",
      "((250, 370, 380), ['BLFS', 'TNDM', 'WWE', 'XENE'])\n",
      "((858, 978, 988), ['CHRD', 'MARA', 'SM', 'FATE'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "for item in z_grp_top_set_syms:\n",
    "  print(item)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms:\n",
      "1 of 2 max_lookback_slice\n",
      "max_lookback_slice: (250, 370, 380)\n",
      "max lookback dates: 2018-01-25, 2018-07-18, 2018-08-01\n",
      "df_eval dates (inclusive): 2018-07-18 - 2018-07-31\n",
      "top_set_syms: ['BLFS', 'TNDM', 'WWE', 'XENE']\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         0.769,         0.167,         4.617\n",
      "grp(CAGR/retnStd): mean, std, mean/std:         4.582,        32.376,         0.142\n",
      "grp(CAGR/UI):      mean, std, mean/std:         7.243,        30.672,         0.236\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:         0.800,         4.670,         3.735\n",
      "================================================== \n",
      "\n",
      "2 of 2 max_lookback_slice\n",
      "max_lookback_slice: (858, 978, 988)\n",
      "max lookback dates: 2020-06-25, 2020-12-15, 2020-12-30\n",
      "df_eval dates (inclusive): 2020-12-15 - 2020-12-29\n",
      "top_set_syms: ['CHRD', 'MARA', 'SM', 'FATE']\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         0.971,         0.362,         2.681\n",
      "grp(CAGR/retnStd): mean, std, mean/std:   622,439.580, 1,244,897.024,         0.500\n",
      "grp(CAGR/UI):      mean, std, mean/std:   784,969.840, 1,569,951.086,         0.500\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:         0.861,        61.218,        52.683\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from yf_utils import _7_perf_eval\n",
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "# z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms[26:29])\n",
    "\n",
    "for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms):\n",
    "# for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms[26:29]):\n",
    "\n",
    "  start_train = _lookback_slice[0]\n",
    "  end_train = _lookback_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  d_start_train = df_train.index[start_train].strftime('%Y-%m-%d')\n",
    "  d_end_train = df_train.index[end_train].strftime('%Y-%m-%d')\n",
    "  d_start_eval = d_end_train\n",
    "  d_end_eval = df_train.index[end_eval].strftime('%Y-%m-%d')\n",
    "  d_df_eval_start = d_end_train\n",
    "  d_df_eval_end = df_train.index[end_eval - 1].strftime('%Y-%m-%d')  \n",
    "  print(f'max lookback dates: {d_start_train}, {d_end_train}, {d_end_eval}')\n",
    "  print(f'df_eval dates (inclusive): {d_df_eval_start} - {d_df_eval_end}')    \n",
    "  print(f'top_set_syms: {_top_set_syms}\\n')\n",
    "\n",
    "  df_eval = df_train[start_eval:end_eval][_top_set_syms]\n",
    "\n",
    "  if verbose:\n",
    "    # print(f'start_eval: {start_eval}')\n",
    "    # print(f'end_eval:   {end_eval}')  \n",
    "    print(f'start_eval: {start_eval},  date: {d_end_train}')\n",
    "    print(f'end_eval:   {end_eval},  date: {d_end_eval},  df_eval last date: {d_df_eval_end}')      \n",
    "    print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "\n",
    "  _, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = _7_perf_eval(df_eval)\n",
    "  print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]:>13,.3f}, {grp_retnStd_d_UI[1]:>13,.3f}, {grp_retnStd_d_UI[2]:>13,.3f}')\n",
    "  print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>13,.3f}, {grp_CAGR_d_retnStd[1]:>13,.3f}, {grp_CAGR_d_retnStd[2]:>13,.3f}')\n",
    "  print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]:>13,.3f}, {grp_CAGR_d_UI[1]:>13,.3f}, {grp_CAGR_d_UI[2]:>13,.3f}')\n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df_train[start_eval:end_eval][_sym_idx]\n",
    "  _, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = _7_perf_eval(df_SPY)\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI: {grp_retnStd_d_UI[0]:>13,.3f}, {grp_CAGR_d_retnStd[0]:>13,.3f}, {grp_CAGR_d_UI[0]:>13,.3f}')\n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
