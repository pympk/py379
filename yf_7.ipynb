{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices, _5_perf_ranks\n",
    "from yf_utils import _6_grp_tuples_sort_sum\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "# verbose = True  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_df_c = 'df_close_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pickle_load(path_data_dump, filename_pickled_df_c)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_c)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "# n_samples = 200  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "days_lookbacks = [30, 120, 60]  # number of lookback days for training\n",
    "days_eval = 10  # number of days to evaluate effectiveness of the training\n",
    "set_top_syms = 5  # number of the most-common symbols from days_lookbacks' performance rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create n_samples of iloc start_train:end_train:end_eval using max value in days_loobacks\n",
    "max_lookback_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval)\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}')\n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # list of lists of top_set_symbols, there are n_samples lists in list\n",
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for lb_slices in sets_lookback_slices:\n",
    "  grp_most_common_syms = []  \n",
    "  for lb_slice in lb_slices:  # lb_slice, e.g. (246, 276, 286)\n",
    "    start_train = lb_slice[0]\n",
    "    end_train = lb_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = lb_slice[2]\n",
    "    lookback = end_train - start_train\n",
    "    eval = end_eval - start_eval\n",
    "\n",
    "    if verbose:\n",
    "      print(f'lb_slices:     {lb_slices}')\n",
    "      print(f'lb_slice:      {lb_slice}')\n",
    "      print(f'days lookback: {lookback}')\n",
    "      print(f'days eval:     {eval}')    \n",
    "      print(f'start_train:   {start_train}')\n",
    "      print(f'end_train:     {end_train}')\n",
    "      # print(f'start_eval:    {start_eval}')\n",
    "      # print(f'end_eval:      {end_eval}')`\n",
    "\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, most_common_syms = _5_perf_ranks(_df, n_top_syms=10)\n",
    "    grp_most_common_syms.append(most_common_syms)\n",
    "    \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_common_syms: {most_common_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "    # grp_most_common_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "  # group symbols from set of days_lookbacks (i.e. lb_slices) and sum frequency of the symbols\n",
    "  set_most_common_syms = _6_grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "  # get the top few most-frequent symbol:frequency pairs\n",
    "  top_set_syms_n_freq = set_most_common_syms[0:set_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq]\n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {set_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {set_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {set_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms:\n",
      "((42, 162, 172), ['XOMA', 'CUTR', 'DVAX', 'RDNT', 'AVEO'])\n",
      "((95, 215, 225), ['ENPH', 'GDS', 'MRTX', 'OSTK', 'ALGN'])\n",
      "((552, 672, 682), ['ETN', 'FTSM', 'SHAK', 'CAL', 'HOV'])\n",
      "((877, 997, 1007), ['DAC', 'MARA', 'MSTR', 'BEEM', 'CHRD'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "for item in z_grp_top_set_syms:\n",
    "  print(item)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms:\n",
      "1 of 4 max_lookback_slice\n",
      "max_lookback_slice: (42, 162, 172)\n",
      "top_set_syms: ['XOMA', 'CUTR', 'DVAX', 'RDNT', 'AVEO']\n",
      "start_eval: 162\n",
      "end_eval:   172\n",
      "symbol: XOMA\n",
      "symbol: CUTR\n",
      "symbol: DVAX\n",
      "symbol: RDNT\n",
      "symbol: AVEO\n",
      "top symbols from max_lookback_slice: ['XOMA', 'CUTR', 'DVAX', 'RDNT', 'AVEO']\n",
      "\n",
      "2 of 4 max_lookback_slice\n",
      "max_lookback_slice: (95, 215, 225)\n",
      "top_set_syms: ['ENPH', 'GDS', 'MRTX', 'OSTK', 'ALGN']\n",
      "start_eval: 215\n",
      "end_eval:   225\n",
      "symbol: ENPH\n",
      "symbol:  GDS\n",
      "symbol: MRTX\n",
      "symbol: OSTK\n",
      "symbol: ALGN\n",
      "top symbols from max_lookback_slice: ['ENPH', 'GDS', 'MRTX', 'OSTK', 'ALGN']\n",
      "\n",
      "3 of 4 max_lookback_slice\n",
      "max_lookback_slice: (552, 672, 682)\n",
      "top_set_syms: ['ETN', 'FTSM', 'SHAK', 'CAL', 'HOV']\n",
      "start_eval: 672\n",
      "end_eval:   682\n",
      "symbol:  ETN\n",
      "symbol: FTSM\n",
      "symbol: SHAK\n",
      "symbol:  CAL\n",
      "symbol:  HOV\n",
      "top symbols from max_lookback_slice: ['ETN', 'FTSM', 'SHAK', 'CAL', 'HOV']\n",
      "\n",
      "4 of 4 max_lookback_slice\n",
      "max_lookback_slice: (877, 997, 1007)\n",
      "top_set_syms: ['DAC', 'MARA', 'MSTR', 'BEEM', 'CHRD']\n",
      "start_eval: 997\n",
      "end_eval:   1007\n",
      "symbol:  DAC\n",
      "symbol: MARA\n",
      "symbol: MSTR\n",
      "symbol: BEEM\n",
      "symbol: CHRD\n",
      "top symbols from max_lookback_slice: ['DAC', 'MARA', 'MSTR', 'BEEM', 'CHRD']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms):\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  print(f'top_set_syms: {_top_set_syms}')\n",
    "  print(f'start_eval: {_lookback_slice[1]}')\n",
    "  print(f'end_eval:   {_lookback_slice[2]}')\n",
    "  l_syms = []  # list to accumlate top set symbbols\n",
    "  for sym in _top_set_syms:\n",
    "    l_syms.append(sym)\n",
    "    print(f'symbol: {sym:>4}')\n",
    "  print(f'top symbols from max_lookback_slice: {l_syms}')  \n",
    "  print('')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "1 of 4 max_lookback_slice\n",
      "max_lookback_slice: (42, 162, 172)\n",
      "top_set_syms_n_freq: [('XOMA', 6), ('CUTR', 5), ('DVAX', 5), ('RDNT', 5), ('AVEO', 4)]\n",
      "start_eval: 162\n",
      "end_eval:   172\n",
      "symbol: XOMA,  freq:  6\n",
      "symbol: CUTR,  freq:  5\n",
      "symbol: DVAX,  freq:  5\n",
      "symbol: RDNT,  freq:  5\n",
      "symbol: AVEO,  freq:  4\n",
      "top symbols from max_lookback_slice: ['XOMA', 'CUTR', 'DVAX', 'RDNT', 'AVEO']\n",
      "\n",
      "2 of 4 max_lookback_slice\n",
      "max_lookback_slice: (95, 215, 225)\n",
      "top_set_syms_n_freq: [('ENPH', 6), ('GDS', 6), ('MRTX', 6), ('OSTK', 6), ('ALGN', 5)]\n",
      "start_eval: 215\n",
      "end_eval:   225\n",
      "symbol: ENPH,  freq:  6\n",
      "symbol:  GDS,  freq:  6\n",
      "symbol: MRTX,  freq:  6\n",
      "symbol: OSTK,  freq:  6\n",
      "symbol: ALGN,  freq:  5\n",
      "top symbols from max_lookback_slice: ['ENPH', 'GDS', 'MRTX', 'OSTK', 'ALGN']\n",
      "\n",
      "3 of 4 max_lookback_slice\n",
      "max_lookback_slice: (552, 672, 682)\n",
      "top_set_syms_n_freq: [('ETN', 6), ('FTSM', 6), ('SHAK', 5), ('CAL', 3), ('HOV', 3)]\n",
      "start_eval: 672\n",
      "end_eval:   682\n",
      "symbol:  ETN,  freq:  6\n",
      "symbol: FTSM,  freq:  6\n",
      "symbol: SHAK,  freq:  5\n",
      "symbol:  CAL,  freq:  3\n",
      "symbol:  HOV,  freq:  3\n",
      "top symbols from max_lookback_slice: ['ETN', 'FTSM', 'SHAK', 'CAL', 'HOV']\n",
      "\n",
      "4 of 4 max_lookback_slice\n",
      "max_lookback_slice: (877, 997, 1007)\n",
      "top_set_syms_n_freq: [('DAC', 6), ('MARA', 6), ('MSTR', 6), ('BEEM', 5), ('CHRD', 5)]\n",
      "start_eval: 997\n",
      "end_eval:   1007\n",
      "symbol:  DAC,  freq:  6\n",
      "symbol: MARA,  freq:  6\n",
      "symbol: MSTR,  freq:  6\n",
      "symbol: BEEM,  freq:  5\n",
      "symbol: CHRD,  freq:  5\n",
      "top symbols from max_lookback_slice: ['DAC', 'MARA', 'MSTR', 'BEEM', 'CHRD']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('z_grp_top_set_syms_n_freq:')\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}')\n",
    "  print(f'start_eval: {_lookback_slice[1]}')\n",
    "  print(f'end_eval:   {_lookback_slice[2]}')\n",
    "  l_syms = []  # list to accumlate top set symbbols\n",
    "  for sym_n_freq in _top_set_syms_n_freq:\n",
    "    l_syms.append(sym_n_freq[0])\n",
    "    print(f'symbol: {sym_n_freq[0]:>4},  freq: {sym_n_freq[1]:>2}')\n",
    "  print(f'top symbols from max_lookback_slice: {l_syms}')  \n",
    "  print('')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms:\n",
      "1 of 4 max_lookback_slice\n",
      "max_lookback_slice: (42, 162, 172)\n",
      "top_set_syms: ['XOMA', 'CUTR', 'DVAX', 'RDNT', 'AVEO']\n",
      "start_eval: 162\n",
      "end_eval:   172\n",
      "\n",
      "df_eval:\n",
      "                 XOMA       CUTR       DVAX   RDNT       AVEO\n",
      "Date                                                         \n",
      "2017-09-14  18.719999  37.450001  20.650000  11.20  35.000000\n",
      "2017-09-15  19.400000  38.549999  20.799999  11.15  35.500000\n",
      "2017-09-18  19.090000  40.250000  20.750000  11.10  37.700001\n",
      "2017-09-19  18.990000  40.349998  20.850000  11.00  38.400002\n",
      "2017-09-20  20.150000  40.500000  21.049999  10.85  37.700001\n",
      "2017-09-21  20.799999  39.900002  20.799999  11.00  37.200001\n",
      "2017-09-22  19.570000  39.849998  20.500000  11.10  36.000000\n",
      "2017-09-25  19.400000  39.650002  21.049999  11.05  35.599998\n",
      "2017-09-26  19.290001  39.650002  20.600000  11.60  35.099998\n",
      "2017-09-27  19.299999  40.450001  20.650000  11.85  36.299999\n",
      "\n",
      "\n",
      "2 of 4 max_lookback_slice\n",
      "max_lookback_slice: (95, 215, 225)\n",
      "top_set_syms: ['ENPH', 'GDS', 'MRTX', 'OSTK', 'ALGN']\n",
      "start_eval: 215\n",
      "end_eval:   225\n",
      "\n",
      "df_eval:\n",
      "            ENPH        GDS       MRTX       OSTK        ALGN\n",
      "Date                                                         \n",
      "2017-11-29  2.87  19.600000  16.850000  52.000000  258.369995\n",
      "2017-11-30  2.90  20.450001  17.150000  47.099998  260.880005\n",
      "2017-12-01  2.90  20.450001  16.750000  42.299999  254.070007\n",
      "2017-12-04  2.65  20.129999  16.100000  46.099998  225.800003\n",
      "2017-12-05  2.76  19.780001  16.049999  45.849998  227.360001\n",
      "2017-12-06  2.70  17.820000  15.900000  42.650002  233.009995\n",
      "2017-12-07  2.80  18.209999  16.299999  45.650002  241.380005\n",
      "2017-12-08  2.77  18.639999  16.150000  45.080002  238.429993\n",
      "2017-12-11  2.70  19.549999  15.950000  55.000000  233.660004\n",
      "2017-12-12  2.72  18.969999  15.900000  53.450001  234.369995\n",
      "\n",
      "\n",
      "3 of 4 max_lookback_slice\n",
      "max_lookback_slice: (552, 672, 682)\n",
      "top_set_syms: ['ETN', 'FTSM', 'SHAK', 'CAL', 'HOV']\n",
      "start_eval: 672\n",
      "end_eval:   682\n",
      "\n",
      "df_eval:\n",
      "                  ETN       FTSM       SHAK        CAL        HOV\n",
      "Date                                                             \n",
      "2019-09-25  77.860420  58.858990  99.360001  22.480049  19.760000\n",
      "2019-09-26  77.690887  58.868778  97.529999  21.871710  19.240000\n",
      "2019-09-27  78.180626  58.868778  95.519997  22.033304  18.420000\n",
      "2019-09-30  78.312485  58.878578  98.040001  22.251925  19.250000\n",
      "2019-10-01  76.099205  58.898170  93.620003  21.539026  18.629999\n",
      "2019-10-02  73.236084  58.907978  92.519997  20.664536  18.490000\n",
      "2019-10-03  73.904755  58.927578  94.169998  21.234854  18.480000\n",
      "2019-10-04  74.705322  58.932487  94.660004  20.417400  18.790001\n",
      "2019-10-07  73.744659  58.927578  93.129997  20.521954  19.910000\n",
      "2019-10-08  71.813919  58.937374  92.300003  20.322342  22.570000\n",
      "\n",
      "\n",
      "4 of 4 max_lookback_slice\n",
      "max_lookback_slice: (877, 997, 1007)\n",
      "top_set_syms: ['DAC', 'MARA', 'MSTR', 'BEEM', 'CHRD']\n",
      "start_eval: 997\n",
      "end_eval:   1007\n",
      "\n",
      "df_eval:\n",
      "                  DAC       MARA        MSTR       BEEM       CHRD\n",
      "Date                                                              \n",
      "2021-01-08  26.680532  26.389999  531.640015  70.099998  42.240002\n",
      "2021-01-11  29.399075  23.360001  495.489990  71.139999  42.380001\n",
      "2021-01-12  32.020519  26.150000  514.239990  70.330002  44.820000\n",
      "2021-01-13  29.107800  23.000000  519.260010  69.750000  44.380001\n",
      "2021-01-14  28.243694  24.440001  631.000000  67.290001  45.500000\n",
      "2021-01-15  27.981550  22.389999  578.070007  60.709999  44.410000\n",
      "2021-01-19  28.573801  22.350000  592.210022  61.549999  43.369999\n",
      "2021-01-20  28.651476  19.270000  550.820007  61.580002  41.740002\n",
      "2021-01-21  27.534931  17.559999  520.460022  66.000000  39.980000\n",
      "2021-01-22  29.204891  18.299999  577.030029  65.790001  39.360001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms):\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  print(f'top_set_syms: {_top_set_syms}')\n",
    "\n",
    "\n",
    "  start_eval = _lookback_slice[1]\n",
    "  end_eval = _lookback_slice[2]\n",
    "  df_eval = df_train[start_eval:end_eval][_top_set_syms]\n",
    "  if verbose:\n",
    "    print(f'start_eval: {start_eval}')\n",
    "    print(f'end_eval:   {end_eval}')  \n",
    "    print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "\n",
    "\n",
    "  df_perf1, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = perf_eval(df_temp)\n",
    "  print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]:>10.6f}, {grp_retnStd_d_UI[1]:>10.6f}, {grp_retnStd_d_UI[2]:>10.6f}')\n",
    "  print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>10.6f}, {grp_CAGR_d_retnStd[1]:>10.6f}, {grp_CAGR_d_retnStd[2]:>10.6f}')\n",
    "  print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]:>10.6f}, {grp_CAGR_d_UI[1]:>10.6f}, {grp_CAGR_d_UI[2]:>10.6f}')\n",
    "  df_perf1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  print('')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['XOMA', 'CUTR', 'DVAX', 'RDNT', 'AVEO'],\n",
       " ['ENPH', 'GDS', 'MRTX', 'OSTK', 'ALGN'],\n",
       " ['ETN', 'FTSM', 'SHAK', 'CAL', 'HOV'],\n",
       " ['DAC', 'MARA', 'MSTR', 'BEEM', 'CHRD']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_top_set_syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42, 162, 172), (95, 215, 225), (552, 672, 682), (877, 997, 1007)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_lookback_slices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
