{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "\n",
    "# from yf_utils import _2_split_train_val_test, _3_random_slices, _4_perf_ranks\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices\n",
    "# from trash import _4_perf_ranks_1\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_df_c = 'df_close_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pickle_load(path_data_dump, filename_pickled_df_c)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2\n",
    "# days_lookback = 60\n",
    "days_lookbacks = [60, 120]\n",
    "days_eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_dic = {}\n",
    "for days_lookback in days_lookbacks:\n",
    "  my_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=days_lookback, days_eval=days_eval)\n",
    "  slices_dic[days_lookback] = my_slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{60: [(332, 392, 402), (638, 698, 708)],\n",
       " 120: [(524, 644, 654), (667, 787, 797)]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks_dic = {}\n",
    "ranked_perf_ranks_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from trash import _4_perf_ranks_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _4_perf_ranks(df_close, days_lookbacks, n_top_syms=200, verbose=False):\n",
    "    \"\"\"Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending\n",
    "     performance) and ranked_perf_ranks_dict(dic. of symbols ranked in\n",
    "     descending frequency in a combined pool of symbols in perf_ranks_dict).\n",
    "\n",
    "    Args:\n",
    "        df_close(dataframe): dataframe of symbols' close with\n",
    "         DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "         column names, and symbols' close as column values.\n",
    "        days_lookbacks(list of positive integers): list of number of days to\n",
    "        look-back, e.g. [15, 30], for performance calculation.\n",
    "        n_top_syms(int): number of top symbols to keep in perf_ranks_dict \n",
    "\n",
    "    Return:\n",
    "        perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending\n",
    "         performance.\n",
    "         First dic keys are:\n",
    "          'period' + str(days_lookbacks[0]), ... ,\n",
    "          'period' + str(days_lookbacks[-1])\n",
    "         Second dic keys are:\n",
    "          'r_CAGR/UI', 'r_CAGR/retnStd' and 'r_retnStd/UI'\n",
    "         e.g.:\n",
    "          {\n",
    "            period-15': {\n",
    "                         'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                         'r_CAGR/retnStd': ['BBW', ... , 'CPRX'],\n",
    "                         'r_retnStd/UI':   ['ENR', ... , 'HSY']\n",
    "                        },\n",
    "            ... ,\n",
    "            'period-60': {\n",
    "                          'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                          'r_CAGR/retnStd': ['VCYT', ... , 'BERY'],\n",
    "                          'r_retnStd/UI':   ['MYOV', ... , 'NSC']\n",
    "                         }\n",
    "          }\n",
    "        ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending\n",
    "         frequency in a combined pool of symbols in perf_ranks_dict.  Key is\n",
    "         'ranked_perf_ranks_period' + str(days_lookbacks), e.g.:\n",
    "         {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from myUtils import symb_perf_stats_vectorized_v2\n",
    "\n",
    "    perf_ranks_dict = {}  # dic of performance ranks\n",
    "    syms_perf_rank = []  # list of lists to store top 100 ranked symbols\n",
    "\n",
    "    for days_lookback in days_lookbacks:\n",
    "        days_lookback = -1 * days_lookback\n",
    "        f_name = \"period\" + str(days_lookback)\n",
    "        _df_c = df_close[days_lookback::]\n",
    "        (\n",
    "            symbols,\n",
    "            period_yr,\n",
    "            drawdown,\n",
    "            UI,\n",
    "            max_drawdown,\n",
    "            retnStd,\n",
    "            retnStd_d_UI,\n",
    "            CAGR,\n",
    "            CAGR_d_retnStd,\n",
    "            CAGR_d_UI,        \n",
    "        ) = symb_perf_stats_vectorized_v2(_df_c)            \n",
    "\n",
    "\n",
    "        caches_perf_stats_vect = []\n",
    "        for symbol in symbols:\n",
    "            date_first = drawdown.index[0].strftime(\"%Y-%m-%d\")\n",
    "            date_last = drawdown.index[-1].strftime(\"%Y-%m-%d\")\n",
    "            cache = (\n",
    "                symbol,\n",
    "                date_first,\n",
    "                date_last,\n",
    "                period_yr,\n",
    "                CAGR[symbol],\n",
    "                UI[symbol],\n",
    "                retnStd_d_UI[symbol],\n",
    "                CAGR_d_retnStd[symbol],\n",
    "                CAGR_d_UI[symbol],\n",
    "            )\n",
    "            # append performance data (tuple) to caches_perf_stats (list)\n",
    "            caches_perf_stats_vect.append(cache)\n",
    "        column_names = [\n",
    "            \"symbol\",\n",
    "            \"first date\",\n",
    "            \"last date\",\n",
    "            \"Year\",\n",
    "            \"CAGR\",\n",
    "            \"UI\",\n",
    "            \"retnStd/UI\",\n",
    "            \"CAGR/retnStd\",\n",
    "            \"CAGR/UI\",\n",
    "        ]\n",
    "\n",
    "        # write symbols' performance stats to dataframe\n",
    "        df_ps = pd.DataFrame(caches_perf_stats_vect, columns=column_names)\n",
    "        df_ps[\"r_CAGR/UI\"] = df_ps[\"CAGR/UI\"].rank(ascending=False)\n",
    "        df_ps[\"r_CAGR/retnStd\"] = df_ps[\"CAGR/retnStd\"].rank(ascending=False)\n",
    "        df_ps[\"r_retnStd/UI\"] = df_ps[\"retnStd/UI\"].rank(ascending=False)\n",
    "\n",
    "        _dict = {}\n",
    "        cols_sort = [\"r_CAGR/UI\", \"r_CAGR/retnStd\", \"r_retnStd/UI\"]\n",
    "\n",
    "        # print(f'{f_name} top 100 symbols')\n",
    "        for col in cols_sort:\n",
    "            symbols_top_n = (\n",
    "\n",
    "                df_ps.sort_values(by=[col]).head(n_top_syms).symbol.values\n",
    "                # df_ps.sort_values(by=[col]).symbol.values\n",
    "\n",
    "            )\n",
    "            syms_perf_rank.append(list(symbols_top_n))\n",
    "            # print(f'{col}: {symbols_top_n}')\n",
    "            _dict[col] = symbols_top_n\n",
    "            perf_ranks_dict[f\"{f_name}\"] = _dict\n",
    "\n",
    "    syms_perf_rank  # list of lists of top n_top_syms symbols\n",
    "    l_syms_perf_rank = [\n",
    "        val for sublist in syms_perf_rank for val in sublist\n",
    "    ]  # flatten list of lists\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    cnt_symbol_freq = Counter(l_syms_perf_rank)  # count symbols and frequency\n",
    "    # print(cnt_symbol_freq)\n",
    "    \n",
    "    \n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "    l_tuples = (\n",
    "        cnt_symbol_freq.most_common()\n",
    "    )  # convert to e.g [('AKRO', 6), ('IMVT', 4), ... ('ADEA', 3)]\n",
    "    print(f'days_lookback: {days_lookback}')\n",
    "    print(f'len(l_tuples): {len(l_tuples)}')\n",
    "    print(l_tuples)\n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "\n",
    "\n",
    "\n",
    "    symbols_ranked_perf_ranks = [\n",
    "\n",
    "\n",
    "\n",
    "        symbol for symbol, count in l_tuples\n",
    "        # symbol, count for symbol, count in l_tuples\n",
    "\n",
    "\n",
    "    ]  # select just the symbols without the frequency counts\n",
    "\n",
    "    ranked_perf_ranks_dict = {}\n",
    "    f_name = f\"ranked_perf_ranks_period\" + str(\n",
    "        days_lookbacks\n",
    "    )  # key name, ranked_perf_ranks_dict\n",
    "    ranked_perf_ranks_dict[\n",
    "        f\"{f_name}\"\n",
    "    # values: list of most common symbols in all performance ranks in\n",
    "    #  descending order\n",
    "    ] = symbols_ranked_perf_ranks\n",
    "\n",
    "    # return perf_ranks_dict, ranked_perf_ranks_dict\n",
    "    return perf_ranks_dict, ranked_perf_ranks_dict, l_tuples    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{60: [(332, 392, 402), (638, 698, 708)],\n",
       " 120: [(524, 644, 654), (667, 787, 797)]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_lookback: -120\n",
      "len(l_tuples): 60\n",
      "[('ACRS', 6), ('RICK', 5), ('GME', 4), ('MARA', 4), ('PARA', 4), ('SM', 4), ('CPE', 4), ('SBNY', 4), ('NMM', 4), ('DAC', 4), ('TPL', 4), ('WBD', 3), ('HAFC', 3), ('MTZ', 3), ('CHRD', 3), ('WAL', 3), ('HOV', 2), ('TMST', 2), ('PBF', 2), ('UNFI', 2), ('PDCE', 2), ('MSTR', 2), ('FBK', 2), ('EWBC', 2), ('BANC', 2), ('PFC', 2), ('CTRN', 2), ('NBR', 2), ('PNFP', 2), ('TBK', 2), ('MTDR', 1), ('MCS', 1), ('SEED', 1), ('SNDA', 1), ('AMCX', 1), ('VRTV', 1), ('AJRD', 1), ('SFST', 1), ('AVEO', 1), ('DBI', 1), ('JSD', 1), ('MATW', 1), ('HMST', 1), ('KIO', 1), ('OPY', 1), ('LKFN', 1), ('HCI', 1), ('DBRG', 1), ('TCBI', 1), ('VERU', 1), ('SLCA', 1), ('ATKR', 1), ('CASH', 1), ('SLM', 1), ('INBK', 1), ('OZK', 1), ('KE', 1), ('CUBI', 1), ('TBBK', 1), ('BOH', 1)]\n"
     ]
    }
   ],
   "source": [
    "perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks(df_train, days_lookbacks=days_lookbacks, n_top_syms=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ACRS', 6),\n",
       " ('RICK', 5),\n",
       " ('GME', 4),\n",
       " ('MARA', 4),\n",
       " ('PARA', 4),\n",
       " ('SM', 4),\n",
       " ('CPE', 4),\n",
       " ('SBNY', 4),\n",
       " ('NMM', 4),\n",
       " ('DAC', 4),\n",
       " ('TPL', 4),\n",
       " ('WBD', 3),\n",
       " ('HAFC', 3),\n",
       " ('MTZ', 3),\n",
       " ('CHRD', 3),\n",
       " ('WAL', 3),\n",
       " ('HOV', 2),\n",
       " ('TMST', 2),\n",
       " ('PBF', 2),\n",
       " ('UNFI', 2),\n",
       " ('PDCE', 2),\n",
       " ('MSTR', 2),\n",
       " ('FBK', 2),\n",
       " ('EWBC', 2),\n",
       " ('BANC', 2),\n",
       " ('PFC', 2),\n",
       " ('CTRN', 2),\n",
       " ('NBR', 2),\n",
       " ('PNFP', 2),\n",
       " ('TBK', 2),\n",
       " ('MTDR', 1),\n",
       " ('MCS', 1),\n",
       " ('SEED', 1),\n",
       " ('SNDA', 1),\n",
       " ('AMCX', 1),\n",
       " ('VRTV', 1),\n",
       " ('AJRD', 1),\n",
       " ('SFST', 1),\n",
       " ('AVEO', 1),\n",
       " ('DBI', 1),\n",
       " ('JSD', 1),\n",
       " ('MATW', 1),\n",
       " ('HMST', 1),\n",
       " ('KIO', 1),\n",
       " ('OPY', 1),\n",
       " ('LKFN', 1),\n",
       " ('HCI', 1),\n",
       " ('DBRG', 1),\n",
       " ('TCBI', 1),\n",
       " ('VERU', 1),\n",
       " ('SLCA', 1),\n",
       " ('ATKR', 1),\n",
       " ('CASH', 1),\n",
       " ('SLM', 1),\n",
       " ('INBK', 1),\n",
       " ('OZK', 1),\n",
       " ('KE', 1),\n",
       " ('CUBI', 1),\n",
       " ('TBBK', 1),\n",
       " ('BOH', 1)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_tuples\n",
    "# len(l_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'period-60': {'r_CAGR/UI': array(['GME', 'ACRS', 'MARA', 'PARA', 'HOV', 'WBD', 'SM', 'CPE', 'SBNY',\n",
       "         'HAFC', 'RICK', 'NMM', 'TMST', 'DAC', 'PBF', 'UNFI', 'MTDR', 'TPL',\n",
       "         'PDCE', 'MCS'], dtype=object),\n",
       "  'r_CAGR/retnStd': array(['GME', 'MARA', 'ACRS', 'SM', 'PARA', 'HOV', 'CPE', 'WBD', 'UNFI',\n",
       "         'DAC', 'MSTR', 'SEED', 'SNDA', 'TPL', 'TMST', 'PBF', 'AMCX',\n",
       "         'VRTV', 'NMM', 'PDCE'], dtype=object),\n",
       "  'r_retnStd/UI': array(['ACRS', 'AJRD', 'SFST', 'SBNY', 'FBK', 'AVEO', 'MTZ', 'HAFC',\n",
       "         'DBI', 'RICK', 'JSD', 'MATW', 'HMST', 'EWBC', 'BANC', 'KIO', 'OPY',\n",
       "         'LKFN', 'PFC', 'HCI'], dtype=object)},\n",
       " 'period-120': {'r_CAGR/UI': array(['CHRD', 'MARA', 'GME', 'DAC', 'SM', 'ACRS', 'CPE', 'CTRN', 'WAL',\n",
       "         'NMM', 'RICK', 'TPL', 'PARA', 'NBR', 'PNFP', 'DBRG', 'SBNY', 'MTZ',\n",
       "         'TBK', 'TCBI'], dtype=object),\n",
       "  'r_CAGR/retnStd': array(['GME', 'MARA', 'SM', 'CHRD', 'DAC', 'CPE', 'ACRS', 'CTRN', 'NBR',\n",
       "         'MSTR', 'NMM', 'PARA', 'WBD', 'TPL', 'VERU', 'TBK', 'SLCA', 'RICK',\n",
       "         'ATKR', 'WAL'], dtype=object),\n",
       "  'r_retnStd/UI': array(['CHRD', 'ACRS', 'WAL', 'CASH', 'MTZ', 'PNFP', 'SBNY', 'EWBC',\n",
       "         'BANC', 'SLM', 'INBK', 'HAFC', 'RICK', 'OZK', 'KE', 'PFC', 'FBK',\n",
       "         'CUBI', 'TBBK', 'BOH'], dtype=object)}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days_lookback in slices_dic:\n",
    "  slices = slices_dic[days_lookback]\n",
    "  print(days_lookback, slices)\n",
    "  for my_slice in slices:\n",
    "    start_train = my_slice[0]\n",
    "    end_train = my_slice[1]\n",
    "    start_val = end_train\n",
    "    end_val = my_slice[2]\n",
    "    print(f'start_train: {start_train}')\n",
    "    print(f'end_train:   {end_train}')\n",
    "    # print(f'start_val:   {start_val}')\n",
    "    # print(f'end_val:     {end_val}')\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    l_days_lookback = []  # create a list for days_lookbacks\n",
    "    l_days_lookback.append(days_lookback)\n",
    "    perf_ranks, ranked_perf_ranks = _4_perf_ranks(_df, days_lookbacks=l_days_lookback)\n",
    "    perf_ranks_dic[days_lookback] = perf_ranks\n",
    "    ranked_perf_ranks_dic[days_lookback] = ranked_perf_ranks \n",
    "  print('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days_lookback in slices_dic:\n",
    "  slices = slices_dic[days_lookback]\n",
    "  print(days_lookback, slices)\n",
    "  for my_slice in slices:\n",
    "    start_train = my_slice[0]\n",
    "    end_train = my_slice[1]\n",
    "    start_val = end_train\n",
    "    end_val = my_slice[2]\n",
    "    print(f'start_train: {start_train}')\n",
    "    print(f'end_train:   {end_train}')\n",
    "    # print(f'start_val:   {start_val}')\n",
    "    # print(f'end_val:     {end_val}')\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, ranked_perf_ranks = _4_perf_ranks_1(_df, days_lookback=days_lookback)\n",
    "    perf_ranks_dic[days_lookback] = perf_ranks\n",
    "    ranked_perf_ranks_dic[days_lookback] = ranked_perf_ranks \n",
    "  print('')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my_slice in my_slices[0:2]:\n",
    "for my_slice in my_slices:\n",
    "  start_train = my_slice[0]\n",
    "  end_train = my_slice[1]\n",
    "  start_val = end_train\n",
    "  end_val = my_slice[2]\n",
    "  print(f'start_train: {start_train}')\n",
    "  print(f'end_train: {end_train}')\n",
    "  print(f'start_val: {start_val}')\n",
    "  print(f'end_val: {end_val}')\n",
    "\n",
    "  _df = df_train.iloc[start_train:end_train]\n",
    "  # print(_df) \n",
    "  perf_ranks_dict, ranked_perf_ranks_dict = _4_perf_ranks(_df, days_lookbacks=[60])\n",
    "  # print(perf_ranks_dict)\n",
    "  # print(ranked_perf_ranks_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(perf_ranks_dict)\n",
    "trash = perf_ranks_dict\n",
    "trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d848e2535a99fe7c7346179acd9000b04da131f0f89ee41d962201c665cb28e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
