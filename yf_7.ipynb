{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _4_perf_ranks(df_close, days_lookbacks, n_top_syms=200, verbose=False):\n",
    "    \"\"\"Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending\n",
    "     performance) and ranked_perf_ranks_dict(dic. of symbols ranked in\n",
    "     descending frequency in a combined pool of symbols in perf_ranks_dict).\n",
    "\n",
    "    Args:\n",
    "        df_close(dataframe): dataframe of symbols' close with\n",
    "         DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "         column names, and symbols' close as column values.\n",
    "        days_lookbacks(list of positive integers): list of number of days to\n",
    "        look-back, e.g. [15, 30], for performance calculation.\n",
    "        n_top_syms(int): number of top symbols to keep in perf_ranks_dict \n",
    "\n",
    "    Return:\n",
    "        perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending\n",
    "         performance.\n",
    "         First dic keys are:\n",
    "          'period' + str(days_lookbacks[0]), ... ,\n",
    "          'period' + str(days_lookbacks[-1])\n",
    "         Second dic keys are:\n",
    "          'r_CAGR/UI', 'r_CAGR/retnStd' and 'r_retnStd/UI'\n",
    "         e.g.:\n",
    "          {\n",
    "            period-15': {\n",
    "                         'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                         'r_CAGR/retnStd': ['BBW', ... , 'CPRX'],\n",
    "                         'r_retnStd/UI':   ['ENR', ... , 'HSY']\n",
    "                        },\n",
    "            ... ,\n",
    "            'period-60': {\n",
    "                          'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                          'r_CAGR/retnStd': ['VCYT', ... , 'BERY'],\n",
    "                          'r_retnStd/UI':   ['MYOV', ... , 'NSC']\n",
    "                         }\n",
    "          }\n",
    "        ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending\n",
    "         frequency in a combined pool of symbols in perf_ranks_dict.  Key is\n",
    "         'ranked_perf_ranks_period' + str(days_lookbacks), e.g.:\n",
    "         {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from myUtils import symb_perf_stats_vectorized_v2\n",
    "\n",
    "    perf_ranks_dict = {}  # dic of performance ranks\n",
    "    syms_perf_rank = []  # list of lists to store top 100 ranked symbols\n",
    "\n",
    "    for days_lookback in days_lookbacks:\n",
    "        days_lookback = -1 * days_lookback\n",
    "        f_name = \"period\" + str(days_lookback)\n",
    "        _df_c = df_close[days_lookback::]\n",
    "        (\n",
    "            symbols,\n",
    "            period_yr,\n",
    "            drawdown,\n",
    "            UI,\n",
    "            max_drawdown,\n",
    "            retnStd,\n",
    "            retnStd_d_UI,\n",
    "            CAGR,\n",
    "            CAGR_d_retnStd,\n",
    "            CAGR_d_UI,        \n",
    "        ) = symb_perf_stats_vectorized_v2(_df_c)            \n",
    "\n",
    "\n",
    "        caches_perf_stats_vect = []\n",
    "        for symbol in symbols:\n",
    "            date_first = drawdown.index[0].strftime(\"%Y-%m-%d\")\n",
    "            date_last = drawdown.index[-1].strftime(\"%Y-%m-%d\")\n",
    "            cache = (\n",
    "                symbol,\n",
    "                date_first,\n",
    "                date_last,\n",
    "                period_yr,\n",
    "                CAGR[symbol],\n",
    "                UI[symbol],\n",
    "                retnStd_d_UI[symbol],\n",
    "                CAGR_d_retnStd[symbol],\n",
    "                CAGR_d_UI[symbol],\n",
    "            )\n",
    "            # append performance data (tuple) to caches_perf_stats (list)\n",
    "            caches_perf_stats_vect.append(cache)\n",
    "        column_names = [\n",
    "            \"symbol\",\n",
    "            \"first date\",\n",
    "            \"last date\",\n",
    "            \"Year\",\n",
    "            \"CAGR\",\n",
    "            \"UI\",\n",
    "            \"retnStd/UI\",\n",
    "            \"CAGR/retnStd\",\n",
    "            \"CAGR/UI\",\n",
    "        ]\n",
    "\n",
    "        # write symbols' performance stats to dataframe\n",
    "        df_ps = pd.DataFrame(caches_perf_stats_vect, columns=column_names)\n",
    "        df_ps[\"r_CAGR/UI\"] = df_ps[\"CAGR/UI\"].rank(ascending=False)\n",
    "        df_ps[\"r_CAGR/retnStd\"] = df_ps[\"CAGR/retnStd\"].rank(ascending=False)\n",
    "        df_ps[\"r_retnStd/UI\"] = df_ps[\"retnStd/UI\"].rank(ascending=False)\n",
    "\n",
    "        _dict = {}\n",
    "        cols_sort = [\"r_CAGR/UI\", \"r_CAGR/retnStd\", \"r_retnStd/UI\"]\n",
    "\n",
    "        # print(f'{f_name} top 100 symbols')\n",
    "        for col in cols_sort:\n",
    "            symbols_top_n = (\n",
    "\n",
    "                df_ps.sort_values(by=[col]).head(n_top_syms).symbol.values\n",
    "                # df_ps.sort_values(by=[col]).symbol.values\n",
    "\n",
    "            )\n",
    "            syms_perf_rank.append(list(symbols_top_n))\n",
    "            # print(f'{col}: {symbols_top_n}')\n",
    "            _dict[col] = symbols_top_n\n",
    "            perf_ranks_dict[f\"{f_name}\"] = _dict\n",
    "\n",
    "    syms_perf_rank  # list of lists of top n_top_syms symbols\n",
    "    l_syms_perf_rank = [\n",
    "        val for sublist in syms_perf_rank for val in sublist\n",
    "    ]  # flatten list of lists\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    cnt_symbol_freq = Counter(l_syms_perf_rank)  # count symbols and frequency\n",
    "    # print(cnt_symbol_freq)\n",
    "    \n",
    "    \n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "    l_tuples = (\n",
    "        cnt_symbol_freq.most_common()\n",
    "    )  # convert to e.g [('AKRO', 6), ('IMVT', 4), ... ('ADEA', 3)]\n",
    "    print(f'days_lookback: {days_lookback}')\n",
    "    print(f'len(l_tuples): {len(l_tuples)}')\n",
    "    print(l_tuples)\n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "\n",
    "\n",
    "\n",
    "    symbols_ranked_perf_ranks = [\n",
    "\n",
    "\n",
    "\n",
    "        symbol for symbol, count in l_tuples\n",
    "        # symbol, count for symbol, count in l_tuples\n",
    "\n",
    "\n",
    "    ]  # select just the symbols without the frequency counts\n",
    "\n",
    "    ranked_perf_ranks_dict = {}\n",
    "    f_name = f\"ranked_perf_ranks_period\" + str(\n",
    "        days_lookbacks\n",
    "    )  # key name, ranked_perf_ranks_dict\n",
    "    ranked_perf_ranks_dict[\n",
    "        f\"{f_name}\"\n",
    "    # values: list of most common symbols in all performance ranks in\n",
    "    #  descending order\n",
    "    ] = symbols_ranked_perf_ranks\n",
    "\n",
    "    # return perf_ranks_dict, ranked_perf_ranks_dict\n",
    "    return perf_ranks_dict, ranked_perf_ranks_dict, l_tuples    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _4_perf_ranks_1(df_close, n_top_syms=200, verbose=False):\n",
    "    \"\"\"Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending\n",
    "     performance) and ranked_perf_ranks_dict(dic. of symbols ranked in\n",
    "     descending frequency in a combined pool of symbols in perf_ranks_dict).\n",
    "\n",
    "    Args:\n",
    "        df_close(dataframe): dataframe of symbols' close with\n",
    "         DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "         column names, and symbols' close as column values.\n",
    "        days_lookbacks(list of positive integers): list of number of days to\n",
    "        look-back, e.g. [15, 30], for performance calculation.\n",
    "        n_top_syms(int): number of top symbols to keep in perf_ranks_dict \n",
    "\n",
    "    Return:\n",
    "        perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending\n",
    "         performance.\n",
    "         First dic keys are:\n",
    "          'period' + str(days_lookbacks[0]), ... ,\n",
    "          'period' + str(days_lookbacks[-1])\n",
    "         Second dic keys are:\n",
    "          'r_CAGR/UI', 'r_CAGR/retnStd' and 'r_retnStd/UI'\n",
    "         e.g.:\n",
    "          {\n",
    "            period-15': {\n",
    "                         'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                         'r_CAGR/retnStd': ['BBW', ... , 'CPRX'],\n",
    "                         'r_retnStd/UI':   ['ENR', ... , 'HSY']\n",
    "                        },\n",
    "            ... ,\n",
    "            'period-60': {\n",
    "                          'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                          'r_CAGR/retnStd': ['VCYT', ... , 'BERY'],\n",
    "                          'r_retnStd/UI':   ['MYOV', ... , 'NSC']\n",
    "                         }\n",
    "          }\n",
    "        ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending\n",
    "         frequency in a combined pool of symbols in perf_ranks_dict.  Key is\n",
    "         'ranked_perf_ranks_period' + str(days_lookbacks), e.g.:\n",
    "         {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from myUtils import symb_perf_stats_vectorized_v2\n",
    "\n",
    "    perf_ranks_dict = {}  # dic of performance ranks\n",
    "    syms_perf_rank = []  # list of lists to store top 100 ranked symbols\n",
    "\n",
    "    # for days_lookback in days_lookbacks:\n",
    "    days_lookback = -1 * len(df_close)\n",
    "    f_name = \"period\" + str(days_lookback)\n",
    "    _df_c = df_close[days_lookback::]\n",
    "    (\n",
    "        symbols,\n",
    "        period_yr,\n",
    "        drawdown,\n",
    "        UI,\n",
    "        max_drawdown,\n",
    "        retnStd,\n",
    "        retnStd_d_UI,\n",
    "        CAGR,\n",
    "        CAGR_d_retnStd,\n",
    "        CAGR_d_UI,        \n",
    "    ) = symb_perf_stats_vectorized_v2(_df_c)            \n",
    "\n",
    "\n",
    "    caches_perf_stats_vect = []\n",
    "    for symbol in symbols:\n",
    "        date_first = drawdown.index[0].strftime(\"%Y-%m-%d\")\n",
    "        date_last = drawdown.index[-1].strftime(\"%Y-%m-%d\")\n",
    "        cache = (\n",
    "            symbol,\n",
    "            date_first,\n",
    "            date_last,\n",
    "            period_yr,\n",
    "            CAGR[symbol],\n",
    "            UI[symbol],\n",
    "            retnStd_d_UI[symbol],\n",
    "            CAGR_d_retnStd[symbol],\n",
    "            CAGR_d_UI[symbol],\n",
    "        )\n",
    "        # append performance data (tuple) to caches_perf_stats (list)\n",
    "        caches_perf_stats_vect.append(cache)\n",
    "    column_names = [\n",
    "        \"symbol\",\n",
    "        \"first date\",\n",
    "        \"last date\",\n",
    "        \"Year\",\n",
    "        \"CAGR\",\n",
    "        \"UI\",\n",
    "        \"retnStd/UI\",\n",
    "        \"CAGR/retnStd\",\n",
    "        \"CAGR/UI\",\n",
    "    ]\n",
    "\n",
    "    # write symbols' performance stats to dataframe\n",
    "    df_ps = pd.DataFrame(caches_perf_stats_vect, columns=column_names)\n",
    "    df_ps[\"r_CAGR/UI\"] = df_ps[\"CAGR/UI\"].rank(ascending=False)\n",
    "    df_ps[\"r_CAGR/retnStd\"] = df_ps[\"CAGR/retnStd\"].rank(ascending=False)\n",
    "    df_ps[\"r_retnStd/UI\"] = df_ps[\"retnStd/UI\"].rank(ascending=False)\n",
    "\n",
    "    _dict = {}\n",
    "    cols_sort = [\"r_CAGR/UI\", \"r_CAGR/retnStd\", \"r_retnStd/UI\"]\n",
    "\n",
    "    # print(f'{f_name} top 100 symbols')\n",
    "    for col in cols_sort:\n",
    "        symbols_top_n = (\n",
    "\n",
    "            df_ps.sort_values(by=[col]).head(n_top_syms).symbol.values\n",
    "            # df_ps.sort_values(by=[col]).symbol.values\n",
    "\n",
    "        )\n",
    "        syms_perf_rank.append(list(symbols_top_n))\n",
    "        # print(f'{col}: {symbols_top_n}')\n",
    "        _dict[col] = symbols_top_n\n",
    "        perf_ranks_dict[f\"{f_name}\"] = _dict\n",
    "\n",
    "    syms_perf_rank  # list of lists of top n_top_syms symbols\n",
    "    l_syms_perf_rank = [\n",
    "        val for sublist in syms_perf_rank for val in sublist\n",
    "    ]  # flatten list of lists\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    cnt_symbol_freq = Counter(l_syms_perf_rank)  # count symbols and frequency\n",
    "    # print(cnt_symbol_freq)\n",
    "    \n",
    "    \n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "    l_tuples = (\n",
    "        cnt_symbol_freq.most_common()\n",
    "    )  # convert to e.g [('AKRO', 6), ('IMVT', 4), ... ('ADEA', 3)]\n",
    "    print(f'days_lookback: {days_lookback}')\n",
    "    print(f'len(l_tuples): {len(l_tuples)}')\n",
    "    print(l_tuples)\n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "\n",
    "\n",
    "\n",
    "    symbols_ranked_perf_ranks = [\n",
    "\n",
    "\n",
    "\n",
    "        symbol for symbol, count in l_tuples\n",
    "        # symbol, count for symbol, count in l_tuples\n",
    "\n",
    "\n",
    "    ]  # select just the symbols without the frequency counts\n",
    "\n",
    "    ranked_perf_ranks_dict = {}\n",
    "    f_name = f\"ranked_perf_ranks_period\" + str(\n",
    "        days_lookback\n",
    "    )  # key name, ranked_perf_ranks_dict\n",
    "    ranked_perf_ranks_dict[\n",
    "        f\"{f_name}\"\n",
    "    # values: list of most common symbols in all performance ranks in\n",
    "    #  descending order\n",
    "    ] = symbols_ranked_perf_ranks\n",
    "\n",
    "    # return perf_ranks_dict, ranked_perf_ranks_dict\n",
    "    return perf_ranks_dict, ranked_perf_ranks_dict, l_tuples    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "\n",
    "# from yf_utils import _2_split_train_val_test, _3_random_slices, _4_perf_ranks\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices\n",
    "# from trash import _4_perf_ranks_1\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_df_c = 'df_close_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pickle_load(path_data_dump, filename_pickled_df_c)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_c)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_samples = 2  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "_days_lookbacks = [60, 120, 30]\n",
    "_days_eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(224, 344, 354), (582, 702, 712)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create n_samples of iloc start_train:end_train:end_eval using max value in days_loobacks\n",
    "max_train_eval_days = _3_random_slices(len_df_train, n_samples=_n_samples, days_lookback=max(_days_lookbacks), days_eval=_days_eval)\n",
    "max_train_eval_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookback_slices(max_slices, days_lookbacks, verbose=False):\n",
    "  \"\"\"Create \n",
    "  \n",
    "  \n",
    "  Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending\n",
    "    performance) and ranked_perf_ranks_dict(dic. of symbols ranked in\n",
    "    descending frequency in a combined pool of symbols in perf_ranks_dict).\n",
    "\n",
    "  Args:\n",
    "      df_close(dataframe): dataframe of symbols' close with\n",
    "        DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "        column names, and symbols' close as column values.\n",
    "      days_lookbacks(list of positive integers): list of number of days to\n",
    "      look-back, e.g. [15, 30], for performance calculation.\n",
    "      n_top_syms(int): number of top symbols to keep in perf_ranks_dict \n",
    "\n",
    "  Return:\n",
    "      perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending\n",
    "        performance.\n",
    "        First dic keys are:\n",
    "        'period' + str(days_lookbacks[0]), ... ,\n",
    "        'period' + str(days_lookbacks[-1])\n",
    "        Second dic keys are:\n",
    "        'r_CAGR/UI', 'r_CAGR/retnStd' and 'r_retnStd/UI'\n",
    "        e.g.:\n",
    "        {\n",
    "          period-15': {\n",
    "                        'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                        'r_CAGR/retnStd': ['BBW', ... , 'CPRX'],\n",
    "                        'r_retnStd/UI':   ['ENR', ... , 'HSY']\n",
    "                      },\n",
    "          ... ,\n",
    "          'period-60': {\n",
    "                        'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                        'r_CAGR/retnStd': ['VCYT', ... , 'BERY'],\n",
    "                        'r_retnStd/UI':   ['MYOV', ... , 'NSC']\n",
    "                        }\n",
    "        }\n",
    "      ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending\n",
    "        frequency in a combined pool of symbols in perf_ranks_dict.  Key is\n",
    "        'ranked_perf_ranks_period' + str(days_lookbacks), e.g.:\n",
    "        {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "  \"\"\"  \n",
    "  lb_slices = []\n",
    "  days_lookbacks.sort()  # sort list of integers in ascending order\n",
    "  for my_slice in max_slices:\n",
    "    # lb_slices.append(my_slice)\n",
    "    # if verbose:\n",
    "    #   print(f'days: {days_lookbacks[-1]}, {my_slice}')\n",
    "    for days in days_lookbacks:\n",
    "      new_slice = (my_slice[1]-days, my_slice[1], my_slice[2])\n",
    "      lb_slices.append(new_slice)\n",
    "      if verbose:\n",
    "        print(f'days: {days}, {new_slice}')      \n",
    "    if verbose:    \n",
    "     print('')\n",
    "  return lb_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(314, 344, 354),\n",
       " (284, 344, 354),\n",
       " (224, 344, 354),\n",
       " (672, 702, 712),\n",
       " (642, 702, 712),\n",
       " (582, 702, 712)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_slices = lookback_slices(max_slices=max_train_eval_days, days_lookbacks=_days_lookbacks, verbose=False)\n",
    "lb_slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks_dic = {}\n",
    "ranked_perf_ranks_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_train: 314\n",
      "end_train:   344\n",
      "start_eval:  344\n",
      "end_eval:    354\n",
      "\n",
      "days_lookback: -30\n",
      "len(l_tuples): 277\n",
      "[('STAA', 3), ('TNDM', 3), ('CRK', 3), ('WWE', 3), ('RETA', 3), ('CHRD', 3), ('OSPN', 3), ('CHDN', 3), ('BOOM', 3), ('KMPR', 3), ('GDS', 3), ('THC', 3), ('EXPO', 3), ('ENVA', 3), ('BCOR', 3), ('EVTC', 3), ('VTOL', 3), ('DINO', 3), ('TTD', 3), ('XHR', 3), ('TTGT', 3), ('LPLA', 3), ('HSKA', 3), ('SIVB', 3), ('SM', 3), ('OKE', 3), ('VLO', 3), ('EFC', 3), ('HSII', 3), ('PBF', 3), ('EFSC', 3), ('CMG', 3), ('AXON', 3), ('SHAK', 3), ('NVCR', 3), ('ENSG', 3), ('GDEN', 3), ('PERI', 3), ('CRMT', 3), ('PENN', 3), ('CDNA', 3), ('FFIV', 3), ('OXY', 3), ('HAE', 3), ('MED', 3), ('AXSM', 3), ('LNW', 3), ('NSTG', 3), ('DVN', 3), ('BOOT', 3), ('EVH', 3), ('SMCI', 3), ('TWIN', 3), ('MMSI', 3), ('ESI', 3), ('VCYT', 3), ('NBHC', 3), ('TWLO', 3), ('NSIT', 3), ('DMLP', 3), ('FCN', 3), ('FTSM', 3), ('HQY', 3), ('BPT', 3), ('MRO', 3), ('TPL', 3), ('EWBC', 3), ('CHE', 3), ('WMK', 3), ('MORN', 3), ('NSP', 3), ('EVR', 3), ('PEN', 3), ('CEQP', 3), ('USNA', 3), ('DNOW', 3), ('BOX', 3), ('TARO', 3), ('PK', 3), ('SLCA', 3), ('AMD', 3), ('NTG', 3), ('TSCO', 3), ('LXFR', 3), ('NOAH', 3), ('PSX', 3), ('RAMP', 3), ('CIVI', 3), ('SZC', 3), ('CQP', 3), ('ENLC', 3), ('FBP', 3), ('WBS', 3), ('CLS', 3), ('ULH', 3), ('LRN', 3), ('BGR', 3), ('EMO', 3), ('VICR', 3), ('CYBR', 3), ('FRC', 3), ('CSII', 3), ('TYG', 3), ('WAB', 3), ('AUB', 3), ('DK', 3), ('QTWO', 3), ('CTR', 3), ('MLI', 3), ('EVA', 3), ('RCKY', 3), ('RYI', 3), ('RELL', 3), ('RTO', 3), ('NNI', 3), ('TMP', 3), ('SCHL', 3), ('MCRI', 3), ('CDW', 3), ('GDDY', 3), ('WMB', 3), ('PACW', 3), ('FDUS', 3), ('NOG', 2), ('CVI', 2), ('HTHT', 2), ('ATCO', 2), ('JAKK', 2), ('DXCM', 2), ('NGVC', 2), ('SRDX', 2), ('CRS', 2), ('TG', 2), ('CPRX', 2), ('ARCB', 2), ('VNOM', 2), ('MATX', 2), ('NBIX', 2), ('CEM', 2), ('SBCF', 2), ('CARA', 2), ('AORT', 2), ('HZO', 2), ('PDCE', 2), ('TTEC', 2), ('TRU', 2), ('MGRC', 2), ('GLNG', 2), ('SBRA', 2), ('ADP', 2), ('SCHW', 2), ('PDS', 2), ('MASI', 2), ('ABR', 2), ('ET', 2), ('RRR', 2), ('ARWR', 2), ('BLFS', 2), ('SRG', 2), ('SAR', 2), ('GNK', 2), ('RGNX', 2), ('NEWR', 2), ('MYGN', 2), ('ULTA', 2), ('TSLX', 2), ('OPI', 2), ('GFF', 2), ('RJF', 2), ('MERC', 2), ('MYRG', 2), ('OHI', 2), ('EGRX', 2), ('RUN', 2), ('GOF', 2), ('CZR', 2), ('SHOO', 2), ('ENPH', 2), ('TOWN', 2), ('IMO', 2), ('CNMD', 2), ('ROCK', 2), ('SRV', 2), ('NVEC', 2), ('INGN', 2), ('EOI', 2), ('EPD', 2), ('NPK', 2), ('FCBC', 2), ('LULU', 2), ('GPRK', 2), ('BAX', 2), ('OMF', 2), ('CECE', 2), ('EOS', 2), ('FCF', 2), ('ORLY', 2), ('ZTO', 2), ('XNCR', 2), ('CBU', 2), ('PEB', 1), ('CRSP', 1), ('CTRE', 1), ('APPF', 1), ('MC', 1), ('GPRE', 1), ('TPB', 1), ('RCKT', 1), ('CHGG', 1), ('TRNO', 1), ('NEP', 1), ('UMH', 1), ('SBLK', 1), ('FRPT', 1), ('EGP', 1), ('MRTX', 1), ('MCFT', 1), ('W', 1), ('PTY', 1), ('GRC', 1), ('FR', 1), ('CNI', 1), ('NICE', 1), ('UGI', 1), ('SNEX', 1), ('LNN', 1), ('NEWT', 1), ('LOGI', 1), ('PHG', 1), ('LNG', 1), ('ASB', 1), ('DQ', 1), ('PRK', 1), ('SFNC', 1), ('JOUT', 1), ('BANR', 1), ('SLRC', 1), ('OFG', 1), ('CDNS', 1), ('UMBF', 1), ('WDS', 1), ('PAG', 1), ('NSC', 1), ('STBA', 1), ('CLAR', 1), ('IART', 1), ('HTGC', 1), ('BP', 1), ('STNG', 1), ('JBSS', 1), ('GSBC', 1), ('EHC', 1), ('V', 1), ('RH', 1), ('HVT', 1), ('QDEL', 1), ('AAWW', 1), ('BXMX', 1), ('ABBV', 1), ('WASH', 1), ('BSX', 1), ('FFBC', 1), ('CSL', 1), ('DCOM', 1), ('DAC', 1), ('WMC', 1), ('ARI', 1), ('FFIN', 1), ('CVX', 1), ('GDOT', 1), ('NSSC', 1), ('CADE', 1), ('HEQ', 1), ('BMRC', 1), ('PFGC', 1), ('ETX', 1), ('TNET', 1)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'days_lookback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3800\\3771517404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0m_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0mperf_ranks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranked_perf_ranks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_tuples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_4_perf_ranks_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[0mperf_ranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdays_lookback\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperf_ranks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m   \u001b[0mranked_perf_ranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdays_lookback\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mranked_perf_ranks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'days_lookback' is not defined"
     ]
    }
   ],
   "source": [
    "for lb_slice in lb_slices:\n",
    "  start_train = lb_slice[0]\n",
    "  end_train = lb_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = lb_slice[2]\n",
    "  print(f'start_train: {start_train}')\n",
    "  print(f'end_train:   {end_train}')\n",
    "  print(f'start_eval:  {start_eval}')\n",
    "  print(f'end_eval:    {end_eval}')\n",
    "  print('')\n",
    "  _df = df_train.iloc[start_train:end_train]\n",
    "  perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks_1(_df)    \n",
    "  perf_ranks[days_lookback] = perf_ranks\n",
    "  ranked_perf_ranks[days_lookback] = ranked_perf_ranks   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days_lookback in slices_dic:\n",
    "  slices = slices_dic[days_lookback]\n",
    "  print(days_lookback, slices)\n",
    "  for my_slice in slices:\n",
    "    start_train = my_slice[0]\n",
    "    end_train = my_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = my_slice[2]\n",
    "    print(f'start_train: {start_train}')\n",
    "    print(f'end_train:   {end_train}')\n",
    "    print(f'start_eval:   {start_eval}')\n",
    "    print(f'end_eval:     {end_eval}')\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "\n",
    "\n",
    "    # l_days_lookback = []  # create a list for days_lookbacks\n",
    "    # l_days_lookback.append(days_lookback)\n",
    "    # perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks(_df, days_lookbacks=l_days_lookbacks)\n",
    "    \n",
    "    \n",
    "    perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks(_df, days_lookbacks=days_lookbacks)    \n",
    "    perf_ranks[days_lookback] = perf_ranks\n",
    "    ranked_perf_ranks[days_lookback] = ranked_perf_ranks \n",
    "  print('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks(df_train, days_lookbacks=days_lookbacks, n_top_syms=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tuples\n",
    "# len(l_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days_lookback in slices_dic:\n",
    "  slices = slices_dic[days_lookback]\n",
    "  print(days_lookback, slices)\n",
    "  for my_slice in slices:\n",
    "    start_train = my_slice[0]\n",
    "    end_train = my_slice[1]\n",
    "    start_val = end_train\n",
    "    end_val = my_slice[2]\n",
    "    print(f'start_train: {start_train}')\n",
    "    print(f'end_train:   {end_train}')\n",
    "    # print(f'start_val:   {start_val}')\n",
    "    # print(f'end_val:     {end_val}')\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, ranked_perf_ranks = _4_perf_ranks_1(_df, days_lookback=days_lookback)\n",
    "    perf_ranks_dic[days_lookback] = perf_ranks\n",
    "    ranked_perf_ranks_dic[days_lookback] = ranked_perf_ranks \n",
    "  print('')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my_slice in my_slices[0:2]:\n",
    "for my_slice in my_slices:\n",
    "  start_train = my_slice[0]\n",
    "  end_train = my_slice[1]\n",
    "  start_val = end_train\n",
    "  end_val = my_slice[2]\n",
    "  print(f'start_train: {start_train}')\n",
    "  print(f'end_train: {end_train}')\n",
    "  print(f'start_val: {start_val}')\n",
    "  print(f'end_val: {end_val}')\n",
    "\n",
    "  _df = df_train.iloc[start_train:end_train]\n",
    "  # print(_df) \n",
    "  perf_ranks_dict, ranked_perf_ranks_dict = _4_perf_ranks(_df, days_lookbacks=[60])\n",
    "  # print(perf_ranks_dict)\n",
    "  # print(ranked_perf_ranks_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(perf_ranks_dict)\n",
    "trash = perf_ranks_dict\n",
    "trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d848e2535a99fe7c7346179acd9000b04da131f0f89ee41d962201c665cb28e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
