{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _4_perf_ranks(df_close, days_lookbacks, n_top_syms=200, verbose=False):\n",
    "    \"\"\"Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending\n",
    "     performance) and ranked_perf_ranks_dict(dic. of symbols ranked in\n",
    "     descending frequency in a combined pool of symbols in perf_ranks_dict).\n",
    "\n",
    "    Args:\n",
    "        df_close(dataframe): dataframe of symbols' close with\n",
    "         DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "         column names, and symbols' close as column values.\n",
    "        days_lookbacks(list of positive integers): list of number of days to\n",
    "        look-back, e.g. [15, 30], for performance calculation.\n",
    "        n_top_syms(int): number of top symbols to keep in perf_ranks_dict \n",
    "\n",
    "    Return:\n",
    "        perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending\n",
    "         performance.\n",
    "         First dic keys are:\n",
    "          'period' + str(days_lookbacks[0]), ... ,\n",
    "          'period' + str(days_lookbacks[-1])\n",
    "         Second dic keys are:\n",
    "          'r_CAGR/UI', 'r_CAGR/retnStd' and 'r_retnStd/UI'\n",
    "         e.g.:\n",
    "          {\n",
    "            period-15': {\n",
    "                         'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                         'r_CAGR/retnStd': ['BBW', ... , 'CPRX'],\n",
    "                         'r_retnStd/UI':   ['ENR', ... , 'HSY']\n",
    "                        },\n",
    "            ... ,\n",
    "            'period-60': {\n",
    "                          'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                          'r_CAGR/retnStd': ['VCYT', ... , 'BERY'],\n",
    "                          'r_retnStd/UI':   ['MYOV', ... , 'NSC']\n",
    "                         }\n",
    "          }\n",
    "        ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending\n",
    "         frequency in a combined pool of symbols in perf_ranks_dict.  Key is\n",
    "         'ranked_perf_ranks_period' + str(days_lookbacks), e.g.:\n",
    "         {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from myUtils import symb_perf_stats_vectorized_v2\n",
    "\n",
    "    perf_ranks_dict = {}  # dic of performance ranks\n",
    "    syms_perf_rank = []  # list of lists to store top 100 ranked symbols\n",
    "\n",
    "    for days_lookback in days_lookbacks:\n",
    "        days_lookback = -1 * days_lookback\n",
    "        f_name = \"period\" + str(days_lookback)\n",
    "        _df_c = df_close[days_lookback::]\n",
    "        (\n",
    "            symbols,\n",
    "            period_yr,\n",
    "            drawdown,\n",
    "            UI,\n",
    "            max_drawdown,\n",
    "            retnStd,\n",
    "            retnStd_d_UI,\n",
    "            CAGR,\n",
    "            CAGR_d_retnStd,\n",
    "            CAGR_d_UI,        \n",
    "        ) = symb_perf_stats_vectorized_v2(_df_c)            \n",
    "\n",
    "\n",
    "        caches_perf_stats_vect = []\n",
    "        for symbol in symbols:\n",
    "            date_first = drawdown.index[0].strftime(\"%Y-%m-%d\")\n",
    "            date_last = drawdown.index[-1].strftime(\"%Y-%m-%d\")\n",
    "            cache = (\n",
    "                symbol,\n",
    "                date_first,\n",
    "                date_last,\n",
    "                period_yr,\n",
    "                CAGR[symbol],\n",
    "                UI[symbol],\n",
    "                retnStd_d_UI[symbol],\n",
    "                CAGR_d_retnStd[symbol],\n",
    "                CAGR_d_UI[symbol],\n",
    "            )\n",
    "            # append performance data (tuple) to caches_perf_stats (list)\n",
    "            caches_perf_stats_vect.append(cache)\n",
    "        column_names = [\n",
    "            \"symbol\",\n",
    "            \"first date\",\n",
    "            \"last date\",\n",
    "            \"Year\",\n",
    "            \"CAGR\",\n",
    "            \"UI\",\n",
    "            \"retnStd/UI\",\n",
    "            \"CAGR/retnStd\",\n",
    "            \"CAGR/UI\",\n",
    "        ]\n",
    "\n",
    "        # write symbols' performance stats to dataframe\n",
    "        df_ps = pd.DataFrame(caches_perf_stats_vect, columns=column_names)\n",
    "        df_ps[\"r_CAGR/UI\"] = df_ps[\"CAGR/UI\"].rank(ascending=False)\n",
    "        df_ps[\"r_CAGR/retnStd\"] = df_ps[\"CAGR/retnStd\"].rank(ascending=False)\n",
    "        df_ps[\"r_retnStd/UI\"] = df_ps[\"retnStd/UI\"].rank(ascending=False)\n",
    "\n",
    "        _dict = {}\n",
    "        cols_sort = [\"r_CAGR/UI\", \"r_CAGR/retnStd\", \"r_retnStd/UI\"]\n",
    "\n",
    "        # print(f'{f_name} top 100 symbols')\n",
    "        for col in cols_sort:\n",
    "            symbols_top_n = (\n",
    "\n",
    "                df_ps.sort_values(by=[col]).head(n_top_syms).symbol.values\n",
    "                # df_ps.sort_values(by=[col]).symbol.values\n",
    "\n",
    "            )\n",
    "            syms_perf_rank.append(list(symbols_top_n))\n",
    "            # print(f'{col}: {symbols_top_n}')\n",
    "            _dict[col] = symbols_top_n\n",
    "            perf_ranks_dict[f\"{f_name}\"] = _dict\n",
    "\n",
    "    syms_perf_rank  # list of lists of top n_top_syms symbols\n",
    "    l_syms_perf_rank = [\n",
    "        val for sublist in syms_perf_rank for val in sublist\n",
    "    ]  # flatten list of lists\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    cnt_symbol_freq = Counter(l_syms_perf_rank)  # count symbols and frequency\n",
    "    # print(cnt_symbol_freq)\n",
    "    \n",
    "    \n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "    l_tuples = (\n",
    "        cnt_symbol_freq.most_common()\n",
    "    )  # convert to e.g [('AKRO', 6), ('IMVT', 4), ... ('ADEA', 3)]\n",
    "    print(f'days_lookback: {days_lookback}')\n",
    "    print(f'len(l_tuples): {len(l_tuples)}')\n",
    "    print(l_tuples)\n",
    "    ####################### all symbols in l_tuples have the same count of 3 #############\n",
    "\n",
    "\n",
    "\n",
    "    symbols_ranked_perf_ranks = [\n",
    "\n",
    "\n",
    "\n",
    "        symbol for symbol, count in l_tuples\n",
    "        # symbol, count for symbol, count in l_tuples\n",
    "\n",
    "\n",
    "    ]  # select just the symbols without the frequency counts\n",
    "\n",
    "    ranked_perf_ranks_dict = {}\n",
    "    f_name = f\"ranked_perf_ranks_period\" + str(\n",
    "        days_lookbacks\n",
    "    )  # key name, ranked_perf_ranks_dict\n",
    "    ranked_perf_ranks_dict[\n",
    "        f\"{f_name}\"\n",
    "    # values: list of most common symbols in all performance ranks in\n",
    "    #  descending order\n",
    "    ] = symbols_ranked_perf_ranks\n",
    "\n",
    "    # return perf_ranks_dict, ranked_perf_ranks_dict\n",
    "    return perf_ranks_dict, ranked_perf_ranks_dict, l_tuples    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "\n",
    "# from yf_utils import _2_split_train_val_test, _3_random_slices, _4_perf_ranks\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices\n",
    "# from trash import _4_perf_ranks_1\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_df_c = 'df_close_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pickle_load(path_data_dump, filename_pickled_df_c)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_c)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_samples = 2  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "_days_lookbacks = [60, 120, 30]\n",
    "_days_eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(522, 642, 652), (201, 321, 331)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create n_samples of iloc start_train:end_train:end_eval using max value in days_loobacks\n",
    "max_slices = _3_random_slices(len_df_train, n_samples=_n_samples, days_lookback=max(_days_lookbacks), days_eval=_days_eval)\n",
    "max_slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookback_slices(max_slices, days_lookbacks, verbose=False):\n",
    "  \"\"\"Create \n",
    "  \n",
    "  \n",
    "  Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending\n",
    "    performance) and ranked_perf_ranks_dict(dic. of symbols ranked in\n",
    "    descending frequency in a combined pool of symbols in perf_ranks_dict).\n",
    "\n",
    "  Args:\n",
    "      df_close(dataframe): dataframe of symbols' close with\n",
    "        DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "        column names, and symbols' close as column values.\n",
    "      days_lookbacks(list of positive integers): list of number of days to\n",
    "      look-back, e.g. [15, 30], for performance calculation.\n",
    "      n_top_syms(int): number of top symbols to keep in perf_ranks_dict \n",
    "\n",
    "  Return:\n",
    "      perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending\n",
    "        performance.\n",
    "        First dic keys are:\n",
    "        'period' + str(days_lookbacks[0]), ... ,\n",
    "        'period' + str(days_lookbacks[-1])\n",
    "        Second dic keys are:\n",
    "        'r_CAGR/UI', 'r_CAGR/retnStd' and 'r_retnStd/UI'\n",
    "        e.g.:\n",
    "        {\n",
    "          period-15': {\n",
    "                        'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                        'r_CAGR/retnStd': ['BBW', ... , 'CPRX'],\n",
    "                        'r_retnStd/UI':   ['ENR', ... , 'HSY']\n",
    "                      },\n",
    "          ... ,\n",
    "          'period-60': {\n",
    "                        'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                        'r_CAGR/retnStd': ['VCYT', ... , 'BERY'],\n",
    "                        'r_retnStd/UI':   ['MYOV', ... , 'NSC']\n",
    "                        }\n",
    "        }\n",
    "      ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending\n",
    "        frequency in a combined pool of symbols in perf_ranks_dict.  Key is\n",
    "        'ranked_perf_ranks_period' + str(days_lookbacks), e.g.:\n",
    "        {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "  \"\"\"  \n",
    "  lb_slices = []\n",
    "  days_lookbacks.sort()  # sort list of integers in ascending order\n",
    "  for my_slice in max_slices:\n",
    "    lb_slices.append(my_slice)\n",
    "    if verbose:\n",
    "      print(f'days: {days_lookbacks[-1]}, {my_slice}')\n",
    "    for days in reversed(days_lookbacks[:-1]):\n",
    "      new_slice = (my_slice[1]-days, my_slice[1], my_slice[2])\n",
    "      lb_slices.append(new_slice)\n",
    "      if verbose:\n",
    "        print(f'days: {days}, {new_slice}')      \n",
    "    if verbose:    \n",
    "     print('')\n",
    "  return lb_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(522, 642, 652),\n",
       " (582, 642, 652),\n",
       " (612, 642, 652),\n",
       " (201, 321, 331),\n",
       " (261, 321, 331),\n",
       " (291, 321, 331)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lb_slices = lookback_slices(max_slices=max_slices, days_lookbacks=_days_lookbacks, verbose=False)\n",
    "my_lb_slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_slice in my_slices:\n",
    "  start_train = my_slice[0]\n",
    "  end_train = my_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = my_slice[2]\n",
    "  print(f'start_train: {start_train}')\n",
    "  print(f'end_train:   {end_train}')\n",
    "  print(f'start_eval:   {start_eval}')\n",
    "  print(f'end_eval:     {end_eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_dic = {}\n",
    "for days_lookback in days_lookbacks:\n",
    "  my_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval)\n",
    "  slices_dic[days_lookback] = my_slices\n",
    "slices_dic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks_dic = {}\n",
    "ranked_perf_ranks_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days_lookback in slices_dic:\n",
    "  slices = slices_dic[days_lookback]\n",
    "  print(days_lookback, slices)\n",
    "  for my_slice in slices:\n",
    "    start_train = my_slice[0]\n",
    "    end_train = my_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = my_slice[2]\n",
    "    print(f'start_train: {start_train}')\n",
    "    print(f'end_train:   {end_train}')\n",
    "    print(f'start_eval:   {start_eval}')\n",
    "    print(f'end_eval:     {end_eval}')\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "\n",
    "\n",
    "    # l_days_lookback = []  # create a list for days_lookbacks\n",
    "    # l_days_lookback.append(days_lookback)\n",
    "    # perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks(_df, days_lookbacks=l_days_lookbacks)\n",
    "    \n",
    "    \n",
    "    perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks(_df, days_lookbacks=days_lookbacks)    \n",
    "    perf_ranks[days_lookback] = perf_ranks\n",
    "    ranked_perf_ranks[days_lookback] = ranked_perf_ranks \n",
    "  print('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks, ranked_perf_ranks, l_tuples = _4_perf_ranks(df_train, days_lookbacks=days_lookbacks, n_top_syms=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tuples\n",
    "# len(l_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for days_lookback in slices_dic:\n",
    "  slices = slices_dic[days_lookback]\n",
    "  print(days_lookback, slices)\n",
    "  for my_slice in slices:\n",
    "    start_train = my_slice[0]\n",
    "    end_train = my_slice[1]\n",
    "    start_val = end_train\n",
    "    end_val = my_slice[2]\n",
    "    print(f'start_train: {start_train}')\n",
    "    print(f'end_train:   {end_train}')\n",
    "    # print(f'start_val:   {start_val}')\n",
    "    # print(f'end_val:     {end_val}')\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, ranked_perf_ranks = _4_perf_ranks_1(_df, days_lookback=days_lookback)\n",
    "    perf_ranks_dic[days_lookback] = perf_ranks\n",
    "    ranked_perf_ranks_dic[days_lookback] = ranked_perf_ranks \n",
    "  print('')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ranks_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my_slice in my_slices[0:2]:\n",
    "for my_slice in my_slices:\n",
    "  start_train = my_slice[0]\n",
    "  end_train = my_slice[1]\n",
    "  start_val = end_train\n",
    "  end_val = my_slice[2]\n",
    "  print(f'start_train: {start_train}')\n",
    "  print(f'end_train: {end_train}')\n",
    "  print(f'start_val: {start_val}')\n",
    "  print(f'end_val: {end_val}')\n",
    "\n",
    "  _df = df_train.iloc[start_train:end_train]\n",
    "  # print(_df) \n",
    "  perf_ranks_dict, ranked_perf_ranks_dict = _4_perf_ranks(_df, days_lookbacks=[60])\n",
    "  # print(perf_ranks_dict)\n",
    "  # print(ranked_perf_ranks_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(perf_ranks_dict)\n",
    "trash = perf_ranks_dict\n",
    "trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_perf_ranks_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d848e2535a99fe7c7346179acd9000b04da131f0f89ee41d962201c665cb28e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
