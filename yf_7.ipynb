{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_perf_ranks\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_df_c = 'df_close_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pickle_load(path_data_dump, filename_pickled_df_c)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_c)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _n_samples = 2  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "_n_samples = 2  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "_days_lookbacks = [120, 60, 30]\n",
    "_days_eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(104, 224, 234), (626, 746, 756)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create n_samples of iloc start_train:end_train:end_eval using max value in days_loobacks\n",
    "max_lookback_slices = _3_random_slices(len_df_train, n_samples=_n_samples, days_lookback=max(_days_lookbacks), days_eval=_days_eval)\n",
    "max_lookback_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days: 30, (194, 224, 234)\n",
      "days: 60, (164, 224, 234)\n",
      "days: 120, (104, 224, 234)\n",
      "\n",
      "days: 30, (716, 746, 756)\n",
      "days: 60, (686, 746, 756)\n",
      "days: 120, (626, 746, 756)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(194, 224, 234), (164, 224, 234), (104, 224, 234)],\n",
       " [(716, 746, 756), (686, 746, 756), (626, 746, 756)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yf_utils import _5_lookback_slices\n",
    "sets_lookback_slices = _5_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=_days_lookbacks, verbose=True)\n",
    "sets_lookback_slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [('grape', 100), ('apple', 15), ('grape', 3), ('apple', 10),\n",
    "    ('apple', 4), ('banana', 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grp_tuples_sort_sum(L, reverse=True):\n",
    "  # https://stackoverflow.com/questions/2249036/grouping-python-tuple-list\n",
    "  # https://stackoverflow.com/questions/10695139/sort-a-list-of-tuples-by-2nd-item-integer-value\n",
    "  \"\"\"\n",
    "  Given a list of tuples of (key:value) such as:\n",
    "  [('grape', 100), ('apple', 15), ('grape', 3), ('apple', 10),\n",
    "   ('apple', 4), ('banana', 3)]\n",
    "  Returns list of grouped-sorted-tuples based on summed-values such as:\n",
    "  [('grape', 103), ('apple', 29), ('banana', 3)] \n",
    "\n",
    "  Args:\n",
    "      L(list of tuples): list of tuples of key(str):value(int) pairs\n",
    "      reverse(bool): sort order of summed-values of the grouped tuples,\n",
    "       default is in descending order.  \n",
    "\n",
    "  Return:\n",
    "      grp_sorted_list(list of tuples): list of grouped-sorted-tuples\n",
    "       based on summed-values such as:\n",
    "       [('grape', 103), ('apple', 29), ('banana', 3)] \n",
    "  \"\"\" \n",
    "\n",
    "  import itertools\n",
    "  from operator import itemgetter\n",
    "\n",
    "  grp_list = []\n",
    "  l = sorted(L)\n",
    "  it = itertools.groupby(l, itemgetter(0))\n",
    "\n",
    "  for key, subiter in it:\n",
    "    # print(f'key: {key}')\n",
    "    key_sum = sum(item[1] for item in subiter)\n",
    "    # print(f'key_sum: {key_sum}')\n",
    "    grp_list.append((key, key_sum))\n",
    "\n",
    "  grp_sorted_list = sorted(grp_list, key=itemgetter(1), reverse=reverse)\n",
    "\n",
    "  return grp_sorted_list  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_tuples_sort_sum(L, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_perf_ranks = {}\n",
    "grp_most_common_syms = []\n",
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for lb_slices in sets_lookback_slices:  \n",
    "  for lb_slice in lb_slices:  # lb_slice, e.g. (246, 276, 286)\n",
    "    start_train = lb_slice[0]\n",
    "    end_train = lb_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = lb_slice[2]\n",
    "    lookback = end_train - start_train\n",
    "    eval = end_eval - start_eval\n",
    "    print(f'lb_slices:     {lb_slices}')\n",
    "    print(f'lb_slice:      {lb_slice}')\n",
    "    print(f'days lookback: {lookback}')\n",
    "    print(f'days eval:     {eval}')    \n",
    "    print(f'start_train:   {start_train}')\n",
    "    print(f'end_train:     {end_train}')\n",
    "    # print(f'start_eval:    {start_eval}')\n",
    "    # print(f'end_eval:      {end_eval}')\n",
    "\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, most_common_syms = _4_perf_ranks(_df, n_top_syms=10)\n",
    "    # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "    print(f'perf_ranks: {perf_ranks}')  \n",
    "    # most common symbols of perf_ranks \n",
    "    print(f'most_common_syms: {most_common_syms}')     \n",
    "    # grp_perf_ranks[lookback] = perf_ranks\n",
    "    print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "    grp_most_common_syms.append(most_common_syms)\n",
    "    \n",
    "  print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "  print(f'===== finish lookback slices {lb_slices} =====\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_perf_ranks\n",
    "grp_most_common_syms\n",
    "# flatten list of lists of (symbols:count)\n",
    "flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "\n",
    "sorted_grp_most_common_syms = grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "print(f'len(sorted_grp_most_common_syms): {len(sorted_grp_most_common_syms)}')\n",
    "sorted_grp_most_common_syms\n",
    "# top_common_syms = sorted_grp_most_common_syms[0:5]\n",
    "# top_common_syms = [i[0] for i in top_common_syms]  # get keys from key:value pairs\n",
    "# top_common_syms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_common_syms = sorted_grp_most_common_syms[0:5]\n",
    "top_common_syms = [i[0] for i in top_common_syms]  # get keys from key:value pairs\n",
    "top_common_syms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d848e2535a99fe7c7346179acd9000b04da131f0f89ee41d962201c665cb28e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
