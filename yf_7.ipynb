{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_perf_ranks\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_df_c = 'df_close_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pickle_load(path_data_dump, filename_pickled_df_c)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_c)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _n_samples = 2  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "_n_samples = 2  # number of tuples to create for iloc start_train:end_train:end_eval\n",
    "_days_lookbacks = [60, 120, 30]\n",
    "_days_eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(797, 917, 927), (393, 513, 523)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create n_samples of iloc start_train:end_train:end_eval using max value in days_loobacks\n",
    "max_train_eval_days = _3_random_slices(len_df_train, n_samples=_n_samples, days_lookback=max(_days_lookbacks), days_eval=_days_eval)\n",
    "max_train_eval_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookback_slices(max_slices, days_lookbacks, verbose=False):\n",
    "  \"\"\"Create \n",
    "  \n",
    "  \n",
    "  Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending\n",
    "    performance) and ranked_perf_ranks_dict(dic. of symbols ranked in\n",
    "    descending frequency in a combined pool of symbols in perf_ranks_dict).\n",
    "\n",
    "  Args:\n",
    "      df_close(dataframe): dataframe of symbols' close with\n",
    "        DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "        column names, and symbols' close as column values.\n",
    "      days_lookbacks(list of positive integers): list of number of days to\n",
    "      look-back, e.g. [15, 30], for performance calculation.\n",
    "      n_top_syms(int): number of top symbols to keep in perf_ranks_dict \n",
    "\n",
    "  Return:\n",
    "      perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending\n",
    "        performance.\n",
    "        First dic keys are:\n",
    "        'period' + str(days_lookbacks[0]), ... ,\n",
    "        'period' + str(days_lookbacks[-1])\n",
    "        Second dic keys are:\n",
    "        'r_CAGR/UI', 'r_CAGR/retnStd' and 'r_retnStd/UI'\n",
    "        e.g.:\n",
    "        {\n",
    "          period-15': {\n",
    "                        'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                        'r_CAGR/retnStd': ['BBW', ... , 'CPRX'],\n",
    "                        'r_retnStd/UI':   ['ENR', ... , 'HSY']\n",
    "                      },\n",
    "          ... ,\n",
    "          'period-60': {\n",
    "                        'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                        'r_CAGR/retnStd': ['VCYT', ... , 'BERY'],\n",
    "                        'r_retnStd/UI':   ['MYOV', ... , 'NSC']\n",
    "                        }\n",
    "        }\n",
    "      ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending\n",
    "        frequency in a combined pool of symbols in perf_ranks_dict.  Key is\n",
    "        'ranked_perf_ranks_period' + str(days_lookbacks), e.g.:\n",
    "        {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "  \"\"\"  \n",
    "  lb_slices = []\n",
    "  days_lookbacks.sort()  # sort list of integers in ascending order\n",
    "  for l_max_slice in max_slices:\n",
    "    for days in days_lookbacks:\n",
    "      new_slice = (l_max_slice[1]-days, l_max_slice[1], l_max_slice[2])\n",
    "      lb_slices.append(new_slice)\n",
    "      if verbose:\n",
    "        print(f'days: {days}, {new_slice}')      \n",
    "    if verbose:    \n",
    "     print('')\n",
    "  return lb_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookback_slices_2(max_slices, days_lookbacks, verbose=False):\n",
    "\n",
    "  lb_slices = []\n",
    "  days_lookbacks.sort()  # sort list of integers in ascending order\n",
    "  for max_slice in max_slices:\n",
    "    l_max_slice = []\n",
    "    for days in days_lookbacks:\n",
    "      new_slice = (max_slice[1]-days, max_slice[1], max_slice[2])\n",
    "      l_max_slice.append(new_slice)\n",
    "      if verbose:\n",
    "        print(f'days: {days}, {new_slice}')    \n",
    "    lb_slices.append(l_max_slice)  \n",
    "    if verbose:    \n",
    "     print('')\n",
    "  return lb_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
       " [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_slices = lookback_slices_2(max_slices=max_train_eval_days, days_lookbacks=_days_lookbacks, verbose=False)\n",
    "lb_slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_max_slices:  [(887, 917, 927), (857, 917, 927), (797, 917, 927)]\n",
      "l_max_slice:   (887, 917, 927)\n",
      "days_lookback: 30\n",
      "days_eval:     10\n",
      "start_train:   887\n",
      "end_train:     917\n",
      "\n",
      "l_max_slices:  [(887, 917, 927), (857, 917, 927), (797, 917, 927)]\n",
      "l_max_slice:   (857, 917, 927)\n",
      "days_lookback: 60\n",
      "days_eval:     10\n",
      "start_train:   857\n",
      "end_train:     917\n",
      "\n",
      "l_max_slices:  [(887, 917, 927), (857, 917, 927), (797, 917, 927)]\n",
      "l_max_slice:   (797, 917, 927)\n",
      "days_lookback: 120\n",
      "days_eval:     10\n",
      "start_train:   797\n",
      "end_train:     917\n",
      "\n",
      "l_max_slices:  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]\n",
      "l_max_slice:   (483, 513, 523)\n",
      "days_lookback: 30\n",
      "days_eval:     10\n",
      "start_train:   483\n",
      "end_train:     513\n",
      "\n",
      "l_max_slices:  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]\n",
      "l_max_slice:   (453, 513, 523)\n",
      "days_lookback: 60\n",
      "days_eval:     10\n",
      "start_train:   453\n",
      "end_train:     513\n",
      "\n",
      "l_max_slices:  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]\n",
      "l_max_slice:   (393, 513, 523)\n",
      "days_lookback: 120\n",
      "days_eval:     10\n",
      "start_train:   393\n",
      "end_train:     513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for l_max_slices in lb_slices:  \n",
    "  for l_max_slice in l_max_slices:\n",
    "    start_train = l_max_slice[0]\n",
    "    end_train = l_max_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = l_max_slice[2]\n",
    "    days_lookback = end_train - start_train\n",
    "    days_eval = end_eval - start_eval\n",
    "    print(f'l_max_slices:  {l_max_slices}')\n",
    "    print(f'l_max_slice:   {l_max_slice}')\n",
    "    print(f'days_lookback: {days_lookback}')\n",
    "    print(f'days_eval:     {days_eval}')    \n",
    "    print(f'start_train:   {start_train}')\n",
    "    print(f'end_train:     {end_train}')\n",
    "    # print(f'start_eval:    {start_eval}')\n",
    "    # print(f'end_eval:      {end_eval}')\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_perf_ranks = {}\n",
    "grp_most_common_syms = {}\n",
    "\n",
    "for lb_slice in lb_slices:\n",
    "  start_train = lb_slice[0]\n",
    "  end_train = lb_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = lb_slice[2]\n",
    "  days_lookback = end_train - start_train\n",
    "  days_eval = end_eval - start_eval\n",
    "  print(f'lb_slice:      {lb_slice}')\n",
    "  print(f'days_lookback: {days_lookback}')\n",
    "  print(f'days_eval:     {days_eval}')    \n",
    "  print(f'start_train:   {start_train}')\n",
    "  print(f'end_train:     {end_train}')\n",
    "  # print(f'start_eval:    {start_eval}')\n",
    "  # print(f'end_eval:      {end_eval}')\n",
    "  print('')\n",
    "  _df = df_train.iloc[start_train:end_train]\n",
    "  perf_ranks, most_common_syms = _4_perf_ranks(_df, n_top_syms=100)\n",
    "  grp_perf_ranks[days_lookback] = perf_ranks\n",
    "  grp_most_common_syms[days_lookback] = most_common_syms\n",
    "  print(f'perf_ranks: {perf_ranks}')\n",
    "  print(f'most_common_syms: {most_common_syms}')\n",
    "  print(f'grp_perf_ranks: {grp_perf_ranks}')\n",
    "  print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "  print('====', '\\n')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d848e2535a99fe7c7346179acd9000b04da131f0f89ee41d962201c665cb28e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
