{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 14)\n",
    "pd.set_option('display.max_colwidth', 12)\n",
    "pd.set_option('display.width', 800)\n",
    "\n",
    "# verbose = False  # True prints more output\n",
    "verbose = True  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "fp_df_eval_results = 'df_eval_results'\n",
    "\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_df_train: 1050, len_df_val: 300, len_df_test: 150 \n"
     ]
    }
   ],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "\n",
    "###################################\n",
    "# df_train, df_val, df_test = _2_split_train_val_test(df_close_clean, s_train=1, s_val=0, s_test=0)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)\n",
    "###################################\n",
    "\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if store_results:  # record results to df\n",
    "# my_cols = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std', 'SPY_CAGR/UI']\n",
    "df_eval_results = pickle_load(path_data_dump, fp_df_eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write run results to df_eval_results\n",
    "store_results = False\n",
    "# store_results = True\n",
    "\n",
    "# number of max lookback tuples to create for iloc start_train:end_train:end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "n_samples = 2\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback end_train\n",
    "# days_lookbacks = [15, 30, 60, 120]\n",
    "# days_lookbacks = [30, 60, 120]\n",
    "days_lookbacks = [60, 120]\n",
    "# days_lookbacks = [120]\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from end_train are used to evaluate effectiveness of the training\n",
    "days_eval = 10  \n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "# n_top_syms = 5\n",
    "n_top_syms = 10  \n",
    "\n",
    "syms_start = 0  #  start index of n_top_syms for evaluation\n",
    "syms_end = 5  #  end index of n_top_syms for evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a sets of iloc lookback slices (start_train:end_train:end_eval), where  \n",
    "end_train - start_train = days_lookback  \n",
    "end_eval - end_train = days_eval  \n",
    "for example,  \n",
    "if given:  \n",
    " n_samples = 2  \n",
    " days_lookbacks = [30, 60, 120]  \n",
    " days_eval = 10  \n",
    "a possible result is:  \n",
    " max_lookback_slices:  \n",
    " [(150, 270, 280), (5, 125, 135)]  \n",
    " where 270-150=125-5=max(days_lookbacks), 280-270=135-125=days_eval  \n",
    " sets_lookback_slices:  \n",
    " [[(240, 270, 280), (210, 270, 280), (150, 270, 280)], [(95, 125, 135), (65, 125, 135), (5, 125, 135)]]  \n",
    "  where in a set, 270-240=days_lookbacks[0], 270-210=days_lookbacks[1], 270-150=days_lookbacks[2]  \n",
    "  and 270, i.e. end_train, is constant for the set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_lookback_slices:\n",
      "[(330, 450, 460), (67, 187, 197)]\n",
      "sets_lookback_slices:\n",
      "[[(390, 450, 460), (330, 450, 460)], [(127, 187, 197), (67, 187, 197)]]\n"
     ]
    }
   ],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}')\n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate lists, n_samples long, of the highest performance ranked symbols. The performance metrics are: CAGR/UI, CAGR/retnStd, retnStd/UI. n_top_syms of the best performing symbols from each metric are combined. The symbols are sorted by their number of appearances in the combined pool, and are placed in a list. A slice of the best performing symbols is selected by syms_start:syms_end, i.e. top_set_syms_n_freq[syms_start:syms_end].     \n",
    "\n",
    "The performance metrics are calculated based on slices in sets_lookback_slices.  The first two numbers are ilocs for training. The last two numbers are ilocs for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days lookback: 60\n",
      "lb_slices:     [(390, 450, 460), (330, 450, 460)]\n",
      "lb_slice:      (390, 450, 460)\n",
      "days eval:     10\n",
      "start_train:   390\n",
      "end_train:     450\n",
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['FTSM', 'SBUX', 'LRN', 'LW', 'WBA', 'MKC', 'GOLD', 'PZZA', 'ULTA',\n",
      "       'AU'], dtype=object), 'r_CAGR/retnStd': array(['LRN', 'SBUX', 'FTSM', 'HRL', 'MKC', 'CCEP', 'ULTA', 'AU', 'LW',\n",
      "       'GOLD'], dtype=object), 'r_retnStd/UI': array(['FTSM', 'SBUX', 'WBA', 'LW', 'LRN', 'PZZA', 'MCD', 'MKC', 'TDS',\n",
      "       'AAP'], dtype=object)}}\n",
      "most_common_syms: [('FTSM', 3), ('SBUX', 3), ('LRN', 3), ('LW', 3), ('MKC', 3), ('WBA', 2), ('GOLD', 2), ('PZZA', 2), ('ULTA', 2), ('AU', 2), ('HRL', 1), ('CCEP', 1), ('MCD', 1), ('TDS', 1), ('AAP', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "days lookback: 120\n",
      "lb_slices:     [(390, 450, 460), (330, 450, 460)]\n",
      "lb_slice:      (330, 450, 460)\n",
      "days eval:     10\n",
      "start_train:   330\n",
      "end_train:     450\n",
      "perf_ranks: {'period-120': {'r_CAGR/UI': array(['FTSM', 'MKC', 'CLX', 'VZ', 'RCII', 'MRK', 'HELE', 'AAP', 'MPW',\n",
      "       'CCEP'], dtype=object), 'r_CAGR/retnStd': array(['FTSM', 'MKC', 'TNDM', 'HELE', 'CCEP', 'BALL', 'HASI', 'LLY',\n",
      "       'ABR', 'CLX'], dtype=object), 'r_retnStd/UI': array(['FTSM', 'RCII', 'MKC', 'AAP', 'CLX', 'VZ', 'MPW', 'MRK', 'SRE',\n",
      "       'NVS'], dtype=object)}}\n",
      "most_common_syms: [('FTSM', 3), ('MKC', 3), ('CLX', 3), ('VZ', 2), ('RCII', 2), ('MRK', 2), ('HELE', 2), ('AAP', 2), ('MPW', 2), ('CCEP', 2), ('TNDM', 1), ('BALL', 1), ('HASI', 1), ('LLY', 1), ('ABR', 1), ('SRE', 1), ('NVS', 1)]\n",
      "+++ finish lookback slice 120 +++\n",
      "\n",
      "grp_most_common_syms: [[('FTSM', 3), ('SBUX', 3), ('LRN', 3), ('LW', 3), ('MKC', 3), ('WBA', 2), ('GOLD', 2), ('PZZA', 2), ('ULTA', 2), ('AU', 2), ('HRL', 1), ('CCEP', 1), ('MCD', 1), ('TDS', 1), ('AAP', 1)], [('FTSM', 3), ('MKC', 3), ('CLX', 3), ('VZ', 2), ('RCII', 2), ('MRK', 2), ('HELE', 2), ('AAP', 2), ('MPW', 2), ('CCEP', 2), ('TNDM', 1), ('BALL', 1), ('HASI', 1), ('LLY', 1), ('ABR', 1), ('SRE', 1), ('NVS', 1)]]\n",
      "**** finish lookback slices [(390, 450, 460), (330, 450, 460)] ****\n",
      "\n",
      "top 10 ranked symbols and frequency from set [(390, 450, 460), (330, 450, 460)]:\n",
      "[('FTSM', 6), ('MKC', 6), ('AAP', 3), ('CCEP', 3), ('CLX', 3), ('LRN', 3), ('LW', 3), ('SBUX', 3), ('AU', 2), ('GOLD', 2)]\n",
      "top 10 ranked symbols from set [(390, 450, 460), (330, 450, 460)]:\n",
      "['FTSM', 'MKC', 'AAP', 'CCEP', 'CLX']\n",
      "===== finish top 10 ranked symbols from days_lookback set [(390, 450, 460), (330, 450, 460)] =====\n",
      "\n",
      "\n",
      "days lookback: 60\n",
      "lb_slices:     [(127, 187, 197), (67, 187, 197)]\n",
      "lb_slice:      (127, 187, 197)\n",
      "days eval:     10\n",
      "start_train:   127\n",
      "end_train:     187\n",
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['OSTK', 'QNST', 'RCKT', 'GDS', 'PRGS', 'HMC', 'HEES', 'AXGN', 'SQ',\n",
      "       'ACLS'], dtype=object), 'r_CAGR/retnStd': array(['RCKT', 'QNST', 'OSTK', 'GDS', 'HEES', 'RFP', 'SQ', 'ACLS', 'AXGN',\n",
      "       'ENPH'], dtype=object), 'r_retnStd/UI': array(['HMC', 'PRGS', 'FCN', 'VRNS', 'CAT', 'KMT', 'PSTG', 'DLTR', 'TBI',\n",
      "       'OSTK'], dtype=object)}}\n",
      "most_common_syms: [('OSTK', 3), ('QNST', 2), ('RCKT', 2), ('GDS', 2), ('PRGS', 2), ('HMC', 2), ('HEES', 2), ('AXGN', 2), ('SQ', 2), ('ACLS', 2), ('RFP', 1), ('ENPH', 1), ('FCN', 1), ('VRNS', 1), ('CAT', 1), ('KMT', 1), ('PSTG', 1), ('DLTR', 1), ('TBI', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "days lookback: 120\n",
      "lb_slices:     [(127, 187, 197), (67, 187, 197)]\n",
      "lb_slice:      (67, 187, 197)\n",
      "days eval:     10\n",
      "start_train:   67\n",
      "end_train:     187\n",
      "perf_ranks: {'period-120': {'r_CAGR/UI': array(['OSTK', 'PRGS', 'SPR', 'ALGN', 'IPGP', 'BA', 'CAT', 'QURE', 'ALLY',\n",
      "       'CTRA'], dtype=object), 'r_CAGR/retnStd': array(['OSTK', 'LGIH', 'CLMT', 'BLFS', 'SQ', 'QNST', 'QURE', 'TRUP',\n",
      "       'GDS', 'PRGS'], dtype=object), 'r_retnStd/UI': array(['CTRA', 'SPR', 'OSTK', 'ALGN', 'PRGS', 'FTSM', 'YELP', 'CAT', 'BA',\n",
      "       'IRTC'], dtype=object)}}\n",
      "most_common_syms: [('OSTK', 3), ('PRGS', 3), ('SPR', 2), ('ALGN', 2), ('BA', 2), ('CAT', 2), ('QURE', 2), ('CTRA', 2), ('IPGP', 1), ('ALLY', 1), ('LGIH', 1), ('CLMT', 1), ('BLFS', 1), ('SQ', 1), ('QNST', 1), ('TRUP', 1), ('GDS', 1), ('FTSM', 1), ('YELP', 1), ('IRTC', 1)]\n",
      "+++ finish lookback slice 120 +++\n",
      "\n",
      "grp_most_common_syms: [[('OSTK', 3), ('QNST', 2), ('RCKT', 2), ('GDS', 2), ('PRGS', 2), ('HMC', 2), ('HEES', 2), ('AXGN', 2), ('SQ', 2), ('ACLS', 2), ('RFP', 1), ('ENPH', 1), ('FCN', 1), ('VRNS', 1), ('CAT', 1), ('KMT', 1), ('PSTG', 1), ('DLTR', 1), ('TBI', 1)], [('OSTK', 3), ('PRGS', 3), ('SPR', 2), ('ALGN', 2), ('BA', 2), ('CAT', 2), ('QURE', 2), ('CTRA', 2), ('IPGP', 1), ('ALLY', 1), ('LGIH', 1), ('CLMT', 1), ('BLFS', 1), ('SQ', 1), ('QNST', 1), ('TRUP', 1), ('GDS', 1), ('FTSM', 1), ('YELP', 1), ('IRTC', 1)]]\n",
      "**** finish lookback slices [(127, 187, 197), (67, 187, 197)] ****\n",
      "\n",
      "top 10 ranked symbols and frequency from set [(127, 187, 197), (67, 187, 197)]:\n",
      "[('OSTK', 6), ('PRGS', 5), ('CAT', 3), ('GDS', 3), ('QNST', 3), ('SQ', 3), ('ACLS', 2), ('ALGN', 2), ('AXGN', 2), ('BA', 2)]\n",
      "top 10 ranked symbols from set [(127, 187, 197), (67, 187, 197)]:\n",
      "['OSTK', 'PRGS', 'CAT', 'GDS', 'QNST']\n",
      "===== finish top 10 ranked symbols from days_lookback set [(127, 187, 197), (67, 187, 197)] =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # list of lists of top_set_symbols, there are n_samples lists in list\n",
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for lb_slices in sets_lookback_slices:\n",
    "  grp_most_common_syms = []  \n",
    "  for lb_slice in lb_slices:  # lb_slice, e.g. (246, 276, 286)\n",
    "    start_train = lb_slice[0]\n",
    "    end_train = lb_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = lb_slice[2]\n",
    "    lookback = end_train - start_train\n",
    "    d_eval = end_eval - start_eval\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback: {lookback}')\n",
    "      print(f'lb_slices:     {lb_slices}')\n",
    "      print(f'lb_slice:      {lb_slice}')\n",
    "      print(f'days eval:     {d_eval}')    \n",
    "      print(f'start_train:   {start_train}')\n",
    "      print(f'end_train:     {end_train}')\n",
    "      # print(f'start_eval:    {start_eval}')\n",
    "      # print(f'end_eval:      {end_eval}')`\n",
    "\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, most_common_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "    grp_most_common_syms.append(most_common_syms)\n",
    "    \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_common_syms: {most_common_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "    # grp_most_common_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "  # group symbols from set of days_lookbacks (i.e. lb_slices) and sum frequency of the symbols\n",
    "  set_most_common_syms = _6_grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "  # get the top few most-frequent symbol:frequency pairs\n",
    "  top_set_syms_n_freq = set_most_common_syms[0:n_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq\n",
    "\n",
    "###################################  \n",
    "  # top_set_syms = [i[0] for i in top_set_syms_n_freq]\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "###################################  \n",
    "  \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms:\n",
      "((330, 450, 460), ['FTSM', 'MKC', 'AAP', 'CCEP', 'CLX'])\n",
      "((67, 187, 197), ['OSTK', 'PRGS', 'CAT', 'GDS', 'QNST'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "for item in z_grp_top_set_syms:\n",
    "  print(item)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms:\n",
      "1 of 2 max_lookback_slice\n",
      "max_lookback_slice: (330, 450, 460)\n",
      "max lookback dates: 2018-06-05, 2018-11-23, 2018-12-10\n",
      "df_eval dates (inclusive): 2018-11-23 - 2018-12-07\n",
      "top_set_syms: ['FTSM', 'MKC', 'AAP', 'CCEP', 'CLX']\n",
      "\n",
      "start_eval: 450,  date: 2018-11-23\n",
      "end_eval:   460,  date: 2018-12-10,  df_eval last date: 2018-12-07\n",
      "\n",
      "df_eval:\n",
      "                 FTSM        MKC         AAP       CCEP         CLX\n",
      "Date                                                               \n",
      "2018-11-23  57.552986  69.143875  166.839661  45.267357  145.605545\n",
      "2018-11-26  57.533775  68.934311  167.291489  45.063618  146.052719\n",
      "2018-11-27  57.543388  70.067825  168.750519  44.859875  148.762131\n",
      "2018-11-28  57.533775  70.467888  168.449310  45.461838  147.921585\n",
      "2018-11-29  57.533775  70.987015  167.244431  45.128445  148.484940\n",
      "2018-11-30  57.533775  71.439476  167.282089  44.952488  148.100433\n",
      "2018-12-03  57.533775  72.153854  167.451508  44.100479  147.805328\n",
      "2018-12-04  57.543388  72.182419  167.733871  44.267178  146.320969\n",
      "2018-12-06  57.524181  72.215767  165.446487  44.378304  146.437180\n",
      "2018-12-07  57.485771  71.625198  157.755920  43.563351  145.283676\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         1.057,         0.909,         1.162\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        -4.841,       116.896,        -0.041\n",
      "grp(CAGR/UI):      mean, std, mean/std:        77.593,       247.579,         0.313\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:         0.779,         1.721,         1.341\n",
      "================================================== \n",
      "\n",
      "2 of 2 max_lookback_slice\n",
      "max_lookback_slice: (67, 187, 197)\n",
      "max lookback dates: 2017-05-18, 2017-11-07, 2017-11-21\n",
      "df_eval dates (inclusive): 2017-11-07 - 2017-11-20\n",
      "top_set_syms: ['OSTK', 'PRGS', 'CAT', 'GDS', 'QNST']\n",
      "\n",
      "start_eval: 187,  date: 2017-11-07\n",
      "end_eval:   197,  date: 2017-11-21,  df_eval last date: 2017-11-20\n",
      "\n",
      "df_eval:\n",
      "                 OSTK       PRGS         CAT        GDS   QNST\n",
      "Date                                                          \n",
      "2017-11-07  40.450001  39.516750  122.081627  17.860001   9.26\n",
      "2017-11-08  40.099998  39.601604  120.744789  17.990000   8.99\n",
      "2017-11-09  52.400002  39.545033  119.029816  18.030001   9.00\n",
      "2017-11-10  53.150002  39.743046  120.032425  18.850000   8.85\n",
      "2017-11-13  56.299999  39.799610  120.076363  19.129999   8.91\n",
      "2017-11-14  50.250000  39.375301  120.964645  19.549999   8.79\n",
      "2017-11-15  50.029999  38.470131  117.939255  19.520000   8.51\n",
      "2017-11-16  54.250000  39.045296  119.926880  19.510000   8.96\n",
      "2017-11-17  52.400002  39.507320  119.724609  19.840000   9.19\n",
      "2017-11-20  56.650002  39.856186  120.410591  20.040001  10.04\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         4.568,         7.557,         0.605\n",
      "grp(CAGR/retnStd): mean, std, mean/std:     8,652.462,    18,605.196,         0.465\n",
      "grp(CAGR/UI):      mean, std, mean/std:    21,976.157,    38,264.781,         0.574\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:         0.886,        -8.754,        -7.753\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from yf_utils import _7_perf_eval\n",
    "\n",
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "# z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms[26:29])\n",
    "\n",
    "for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms):\n",
    "# for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms[26:29]):\n",
    "\n",
    "  start_train = _lookback_slice[0]\n",
    "  end_train = _lookback_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  d_start_train = df_train.index[start_train].strftime('%Y-%m-%d')\n",
    "  d_end_train = df_train.index[end_train].strftime('%Y-%m-%d')\n",
    "  d_start_eval = d_end_train\n",
    "  d_end_eval = df_train.index[end_eval].strftime('%Y-%m-%d')\n",
    "  d_df_eval_start = d_end_train\n",
    "  d_df_eval_end = df_train.index[end_eval - 1].strftime('%Y-%m-%d')  \n",
    "  print(f'max lookback dates: {d_start_train}, {d_end_train}, {d_end_eval}')\n",
    "  print(f'df_eval dates (inclusive): {d_df_eval_start} - {d_df_eval_end}')    \n",
    "  print(f'top_set_syms: {_top_set_syms}\\n')\n",
    "\n",
    "  df_eval = df_train[start_eval:end_eval][_top_set_syms]\n",
    "\n",
    "  if verbose:\n",
    "    # print(f'start_eval: {start_eval}')\n",
    "    # print(f'end_eval:   {end_eval}')  \n",
    "    print(f'start_eval: {start_eval},  date: {d_end_train}')\n",
    "    print(f'end_eval:   {end_eval},  date: {d_end_eval},  df_eval last date: {d_df_eval_end}')      \n",
    "    print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "\n",
    "  _, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = _7_perf_eval(df_eval)\n",
    "  print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]:>13,.3f}, {grp_retnStd_d_UI[1]:>13,.3f}, {grp_retnStd_d_UI[2]:>13,.3f}')\n",
    "  print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>13,.3f}, {grp_CAGR_d_retnStd[1]:>13,.3f}, {grp_CAGR_d_retnStd[2]:>13,.3f}')\n",
    "  print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]:>13,.3f}, {grp_CAGR_d_UI[1]:>13,.3f}, {grp_CAGR_d_UI[2]:>13,.3f}')\n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df_train[start_eval:end_eval][_sym_idx]\n",
    "  _, SPY_retnStd_d_UI, SPY_CAGR_d_retnStd, SPY_CAGR_d_UI = _7_perf_eval(df_SPY)\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI: {SPY_retnStd_d_UI[0]:>13,.3f}, {SPY_CAGR_d_retnStd[0]:>13,.3f}, {SPY_CAGR_d_UI[0]:>13,.3f}')\n",
    "\n",
    "  if store_results:  # record results to df\n",
    "    row_add = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, grp_CAGR_d_UI[0], grp_CAGR_d_UI[1], grp_CAGR_d_UI[2], SPY_CAGR_d_UI[0]]\n",
    "    df_eval_results.loc[len(df_eval_results)] = row_add\n",
    "    print(f'appended row_add to df_eval_results:\\n{row_add}\\n')\n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pandas-groupby-a-simple-but-detailed-tutorial-314b8f37005d\n",
    "# https://towardsdatascience.com/accessing-data-in-a-multiindex-dataframe-in-pandas-569e8767201d\n",
    "# https://towardsdatascience.com/summarizing-data-with-pandas-crosstab-efc8b9abecf\n",
    "# https://towardsdatascience.com/how-to-flatten-multiindex-columns-and-rows-in-pandas-f5406c50e569\n",
    "# https://datascientyst.com/list-aggregation-functions-aggfunc-groupby-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pickle_load(path_data_dump, 'df_eval_results')\n",
    "df = df_eval_results.copy()\n",
    "# display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row iloc with inf:\n",
      "Int64Index([25, 26, 38, 52, 65, 73, 76, 84, 100, 110, 131, 139, 149, 223, 225, 244, 266, 346, 349, 358, 384, 393, 405, 411, 412, 418, 419, 440, 473, 478, 496, 511, 525, 533, 535, 540, 554, 581, 586, 587, 590, 619, 623, 627, 629, 633, 681, 683, 684, 706, 727, 750, 763, 784], dtype='int64')\n",
      "len(row iloc with inf):\n",
      "54\n",
      "len(_df): 800\n"
     ]
    }
   ],
   "source": [
    "my_cols = ['grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'SPY_CAGR/UI']\n",
    "# my_cols = ['grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std']\n",
    "# my_cols = ['SPY_CAGR/UI']\n",
    "_df = df[my_cols]\n",
    "row_inf = _df.index[np.isinf(_df).any(axis=1)]\n",
    "print(f'row iloc with inf:\\n{row_inf}')\n",
    "print(f'len(row iloc with inf):\\n{len(row_inf)}')\n",
    "print(f'len(_df): {len(_df)}')\n",
    "# df_inf = df.iloc[row_inf].copy()  # df with inf in my_cols\n",
    "# # display(HTML(df_inf.to_html()))\n",
    "# df.drop(axis=0, index=row_inf, inplace=True)\n",
    "# # display(HTML(df.to_html()))\n",
    "# df.dropna(how='any', inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max grp(CAGR/UI)_mean:  444907257358.61584\n",
      "max grp(CAGR/UI)_std]:  994841359375.5496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp(CAGR/UI)_mean</th>\n",
       "      <th>grp(CAGR/UI)_std</th>\n",
       "      <th>SPY_CAGR/UI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248.489978</td>\n",
       "      <td>584.843540</td>\n",
       "      <td>-30.375669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.927844</td>\n",
       "      <td>60.229337</td>\n",
       "      <td>-10.581483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4008.399882</td>\n",
       "      <td>5423.419446</td>\n",
       "      <td>190.881313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3735.447231</td>\n",
       "      <td>8000.658763</td>\n",
       "      <td>289.043187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.004549</td>\n",
       "      <td>16.475508</td>\n",
       "      <td>-12.457626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>33229.34...</td>\n",
       "      <td>71736.37...</td>\n",
       "      <td>53.836188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>22.390279</td>\n",
       "      <td>82.528456</td>\n",
       "      <td>-18.271479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>569.693718</td>\n",
       "      <td>1270.879342</td>\n",
       "      <td>657.333386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>2093.482297</td>\n",
       "      <td>4283.497196</td>\n",
       "      <td>-7.457301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>197.694861</td>\n",
       "      <td>261.116903</td>\n",
       "      <td>8.162681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     grp(CAGR/UI)_mean  grp(CAGR/UI)_std  SPY_CAGR/UI\n",
       "0     248.489978         584.843540        -30.375669\n",
       "1      31.927844          60.229337        -10.581483\n",
       "2    4008.399882        5423.419446        190.881313\n",
       "3    3735.447231        8000.658763        289.043187\n",
       "4      -6.004549          16.475508        -12.457626\n",
       "..           ...                ...               ...\n",
       "795  33229.34...        71736.37...         53.836188\n",
       "796    22.390279          82.528456        -18.271479\n",
       "797   569.693718        1270.879342        657.333386\n",
       "798  2093.482297        4283.497196         -7.457301\n",
       "799   197.694861         261.116903          8.162681\n",
       "\n",
       "[800 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # https://stackoverflow.com/questions/50773107/how-to-replace-infinite-value-with-maximum-value-of-a-pandas-column\n",
    "# m = df.loc[df['Crime_Rate'] != np.inf, 'Crime_Rate'].max()\n",
    "# df['Crime_Rate'].replace(np.inf,m,inplace=True)\n",
    "\n",
    "# filter out inf value from column grp(CAGR/UI)_mean,\n",
    "#  than find max values in columns grp(CAGR/UI)_mean and grp(CAGR/UI)_std\n",
    "m = _df.loc[_df['grp(CAGR/UI)_mean'] != np.inf, ['grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std']].max()\n",
    "print(f'max grp(CAGR/UI)_mean:  {m[\"grp(CAGR/UI)_mean\"]}')\n",
    "print(f'max grp(CAGR/UI)_std]:  {m[\"grp(CAGR/UI)_std\"]}')\n",
    "\n",
    "# replace inf in column grp(CAGR/UI)_mean with max value excluding inf\n",
    "_df['grp(CAGR/UI)_mean'].replace(np.inf, m['grp(CAGR/UI)_mean']).copy()\n",
    "# replace inf in column grp(CAGR/UI)_stdn with max value excluding NaN\n",
    "_df['grp(CAGR/UI)_std'].replace(np.nan, m['grp(CAGR/UI)_std']).copy()\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = ['grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'SPY_CAGR/UI']\n",
    "_df = df[my_cols]\n",
    "row_inf = _df.index[np.isinf(_df).any(axis=1)]\n",
    "print(f'row iloc with inf:\\n{row_inf}\\n')\n",
    "df_inf = df.iloc[row_inf].copy()  # df with inf in my_cols\n",
    "# display(HTML(df_inf.to_html()))\n",
    "df.drop(axis=0, index=row_inf, inplace=True)\n",
    "# display(HTML(df.to_html()))\n",
    "df.dropna(how='any', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'days_lookbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15188\\2793973852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# pd.crosstab(df['days_lookbacks'], df['grp(CAGR/UI)_mean'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtbl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'days_lookbacks'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         .agg({'grp(CAGR/UI)_mean': ['mean', 'std'],\n\u001b[0;32m      4\u001b[0m               \u001b[1;34m'grp(CAGR/UI)_mean/std'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               'SPY_CAGR/UI': ['mean', 'std']})\n",
      "\u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py379\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7639\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7640\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7641\u001b[1;33m             \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7642\u001b[0m         )\n\u001b[0;32m   7643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py379\\.venv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    895\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                 \u001b[0mmutated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m                 \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m             )\n\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py379\\.venv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    860\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'days_lookbacks'"
     ]
    }
   ],
   "source": [
    "# pd.crosstab(df['days_lookbacks'], df['grp(CAGR/UI)_mean'])\n",
    "tbl = df.groupby(['days_lookbacks'])\\\n",
    "        .agg({'grp(CAGR/UI)_mean': ['mean', 'std'],\n",
    "              'grp(CAGR/UI)_mean/std': ['mean', 'std'],\n",
    "              'SPY_CAGR/UI': ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "x = np.linspace(-10,20,1000)\n",
    "y = norm.pdf(x, loc=3.579270, scale=3.953039)    # for example\n",
    "z = norm.pdf(x, loc=2.215328, scale=2.629466)    # for example\n",
    "z1 = norm.pdf(x, loc=1.021825, scale=1.505096)    # for example\n",
    "pylab.plot(x,y, 'b')\n",
    "pylab.plot(x,z, 'r')\n",
    "pylab.plot(x,z1, 'g')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'n_samples:             {n_samples:>13}')\n",
    "print(f'days_lookbacks:        {days_lookbacks}')\n",
    "print(f'days_eval:             {days_eval:>13}')\n",
    "print(f'n_top_syms:            {n_top_syms:>13}')\n",
    "print(f'syms_start:            {syms_start:>13}')\n",
    "print(f'syms_end:              {syms_end:>13}')\n",
    "print(f'grp(CAGR/UI)_mean:     {grp_CAGR_d_UI[0]:>13,.3f}')\n",
    "print(f'grp(CAGR/UI)_std:      {grp_CAGR_d_UI[1]:>13,.3f}')\n",
    "print(f'grp(CAGR/UI)_mean/std: {grp_CAGR_d_UI[2]:>13,.3f}')\n",
    "print(f'SPY_CAGR/UI:           {SPY_CAGR_d_UI[0]:>13,.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 20)\n",
    "_df\n",
    "# _df1 = _df.sort_values(by=['grp(CAGR/UI)_mean']).head(100).copy()\n",
    "_df1 = _df.sort_values(by=['grp(CAGR/UI)_mean']).tail(100).copy()\n",
    "# display(HTML(_df1.to_html()))\n",
    "_df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
