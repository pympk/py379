{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _4_perf_ranks(df_close, days_lookbacks, n_symbols=500, verbose=False):\n",
    "    \"\"\"Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending performance)\n",
    "     and ranked_perf_ranks_dict(dic. of symbols ranked in descending frequency in a combined\n",
    "     pool of symbols in perf_ranks_dict).\n",
    "\n",
    "    Args:\n",
    "        df_close(dataframe): dataframe of symbols' close with\n",
    "         DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "         column names, and symbols' close as column values.\n",
    "        days_lookbacks(list of negative integers): list of number of days to look-back,\n",
    "         e.g. [-15, -30]\n",
    "        n_sysmbols(int): number of symbols to be returned, default=500\n",
    "\n",
    "    Return:\n",
    "        perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending performance.\n",
    "         First dic keys are: 'period' + str(days_lookbacks[0]), ... ,  'period' + str(days_lookbacks[-1])\n",
    "         Second dic keys are: 'r_CAGR/UI', 'r_CAGR/Std' and 'r_Std/UI'\n",
    "         e.g.:\n",
    "          {\n",
    "            period-15': {\n",
    "                         'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                         'r_CAGR/Std': ['BBW', ... , 'CPRX'],\n",
    "                         'r_Std/UI':   ['ENR', ... , 'HSY']\n",
    "                        },\n",
    "            ... ,\n",
    "            'period-60': {\n",
    "                          'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                          'r_CAGR/Std': ['VCYT', ... , 'BERY'],\n",
    "                          'r_Std/UI':   ['MYOV', ... , 'NSC']\n",
    "                         }\n",
    "          }\n",
    "        ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending frequency in a combined\n",
    "         pool of symbols in perf_ranks_dict.  Key is 'ranked_perf_ranks_period' + str(days_lookbacks)\n",
    "         e.g.:\n",
    "          {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "    \"\"\"\n",
    "\n",
    "    # from myUtils import pickle_load, pickle_dump, symb_perf_stats_vectorized\n",
    "    import pandas as pd\n",
    "    from myUtils import symb_perf_stats_vectorized\n",
    "\n",
    "    perf_ranks_dict = {}  # dic of performance ranks\n",
    "    syms_perf_rank = []  # list of lists to store top 100 ranked symbols\n",
    "\n",
    "    # days_lookbacks = [-15, -30, -60, -120, -240]\n",
    "    # days_lookbacks = [-15, -30]\n",
    "\n",
    "    for days_lookback in days_lookbacks:\n",
    "        f_name = \"period\" + str(days_lookback)\n",
    "        _df_c = df_close[days_lookback::]\n",
    "        (\n",
    "            symbols,\n",
    "            period_yr,\n",
    "            drawdown,\n",
    "            UI,\n",
    "            max_drawdown,\n",
    "            returns_std,\n",
    "            Std_UI,\n",
    "            CAGR,\n",
    "            CAGR_Std,\n",
    "            CAGR_UI,\n",
    "        ) = symb_perf_stats_vectorized(_df_c)\n",
    "        caches_perf_stats_vect = []\n",
    "        for symbol in symbols:\n",
    "            date_first = drawdown.index[0].strftime(\"%Y-%m-%d\")\n",
    "            date_last = drawdown.index[-1].strftime(\"%Y-%m-%d\")\n",
    "            cache = (\n",
    "                symbol,\n",
    "                date_first,\n",
    "                date_last,\n",
    "                period_yr,\n",
    "                CAGR[symbol],\n",
    "                UI[symbol],\n",
    "                Std_UI[symbol],\n",
    "                CAGR_Std[symbol],\n",
    "                CAGR_UI[symbol],\n",
    "            )\n",
    "            # append performance data (tuple) to caches_perf_stats (list)\n",
    "            caches_perf_stats_vect.append(cache)\n",
    "        column_names = [\n",
    "            \"symbol\",\n",
    "            \"first date\",\n",
    "            \"last date\",\n",
    "            \"Year\",\n",
    "            \"CAGR\",\n",
    "            \"UI\",\n",
    "            \"Std/UI\",\n",
    "            \"CAGR/Std\",\n",
    "            \"CAGR/UI\",\n",
    "        ]\n",
    "\n",
    "        # write symbols' performance stats to dataframe\n",
    "        df_ps = pd.DataFrame(caches_perf_stats_vect, columns=column_names)\n",
    "        df_ps[\"r_CAGR/UI\"] = df_ps[\"CAGR/UI\"].rank(ascending=False)\n",
    "        df_ps[\"r_CAGR/Std\"] = df_ps[\"CAGR/Std\"].rank(ascending=False)\n",
    "        df_ps[\"r_Std/UI\"] = df_ps[\"Std/UI\"].rank(ascending=False)\n",
    "\n",
    "        _dict = {}\n",
    "        cols_sort = [\"r_CAGR/UI\", \"r_CAGR/Std\", \"r_Std/UI\"]\n",
    "\n",
    "        # print(f'{f_name} top 100 symbols')\n",
    "        for col in cols_sort:\n",
    "            symbols_top_n = (\n",
    "                df_ps.sort_values(by=[col]).head(n_symbols).symbol.values\n",
    "            )\n",
    "            syms_perf_rank.append(list(symbols_top_n))\n",
    "            # print(f'{col}: {symbols_top_n}')\n",
    "            _dict[col] = symbols_top_n\n",
    "            perf_ranks_dict[f\"{f_name}\"] = _dict\n",
    "        # print(' ')\n",
    "\n",
    "    # pickle_dump(perf_ranks_dict, path_data_dump, f_pickled_perf_ranks_dict)\n",
    "    # print(f'perf_ranks_dict:\\n{perf_ranks_dict}\\n')\n",
    "\n",
    "    syms_perf_rank  # list of lists of top 100 rank\n",
    "    l_syms_perf_rank = [\n",
    "        val for sublist in syms_perf_rank for val in sublist\n",
    "    ]  # flatten list of lists\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    cnt_symbol_freq = Counter(l_syms_perf_rank)  # count symbols and frequency\n",
    "    # print(cnt_symbol_freq)\n",
    "    l_tuples = (\n",
    "        cnt_symbol_freq.most_common()\n",
    "    )  # convert to e.g [('AKRO', 6), ('IMVT', 4), ... ('ADEA', 3)]\n",
    "    symbols_ranked_perf_ranks = [\n",
    "        symbol for symbol, count in l_tuples\n",
    "    ]  # select just the symbols without the frequency counts\n",
    "    symbols_ranked_perf_ranks = symbols_ranked_perf_ranks[:n_symbols]\n",
    "\n",
    "    ranked_perf_ranks_dict = {}\n",
    "    # f_name = f'ranked_perf_ranks_period' + str(_periods)  # key name, ranked_perf_ranks_dict\n",
    "    f_name = f\"ranked_perf_ranks_period\" + str(\n",
    "        days_lookbacks\n",
    "    )  # key name, ranked_perf_ranks_dict\n",
    "    ranked_perf_ranks_dict[\n",
    "        f\"{f_name}\"\n",
    "    ] = symbols_ranked_perf_ranks  # values: list of most common symbols in all performance ranks in descending order\n",
    "    # pickle_dump(ranked_perf_ranks_dict, path_data_dump, f_pickled_ranked_perf_ranks_dict)\n",
    "    # print(f'ranked_perf_ranks_dict:\\n{ranked_perf_ranks_dict}\\n')\n",
    "\n",
    "    return perf_ranks_dict, ranked_perf_ranks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _4_perf_ranks1(df_close, days_lookbacks, verbose=False):\n",
    "    \"\"\"Returns perf_ranks_dict(dic. of dic. of symbols ranked in descending performance)\n",
    "     and ranked_perf_ranks_dict(dic. of symbols ranked in descending frequency in a combined\n",
    "     pool of symbols in perf_ranks_dict).\n",
    "\n",
    "    Args:\n",
    "        df_close(dataframe): dataframe of symbols' close with\n",
    "         DatetimeIndex e.g. (['2016-12-19', ... '2016-12-22']), symbols as\n",
    "         column names, and symbols' close as column values.\n",
    "        days_lookbacks(list of negative integers): list of number of days to look-back,\n",
    "         e.g. [-15, -30]\n",
    "\n",
    "\n",
    "        # n_sysmbols(int): number of symbols to be returned, default=500\n",
    "\n",
    "\n",
    "\n",
    "    Return:\n",
    "        perf_ranks_dict({dic): dic. of dic. of symbols ranked in descending performance.\n",
    "         First dic keys are: 'period' + str(days_lookbacks[0]), ... ,  'period' + str(days_lookbacks[-1])\n",
    "         Second dic keys are: 'r_CAGR/UI', 'r_CAGR/Std' and 'r_Std/UI'\n",
    "         e.g.:\n",
    "          {\n",
    "            period-15': {\n",
    "                         'r_CAGR/UI':  ['HZNP', ... , 'CB'],\n",
    "                         'r_CAGR/Std': ['BBW', ... , 'CPRX'],\n",
    "                         'r_Std/UI':   ['ENR', ... , 'HSY']\n",
    "                        },\n",
    "            ... ,\n",
    "            'period-60': {\n",
    "                          'r_CAGR/UI':  ['WNC', ... , 'FSLR'],\n",
    "                          'r_CAGR/Std': ['VCYT', ... , 'BERY'],\n",
    "                          'r_Std/UI':   ['MYOV', ... , 'NSC']\n",
    "                         }\n",
    "          }\n",
    "        ranked_perf_ranks_dict(dic): dic. of symbols ranked in descending frequency in a combined\n",
    "         pool of symbols in perf_ranks_dict.  Key is 'ranked_perf_ranks_period' + str(days_lookbacks)\n",
    "         e.g.:\n",
    "          {'ranked_perf_ranks_period[-15, -30]': ['HZNP', ... , 'NSC']}\n",
    "    \"\"\"\n",
    "\n",
    "    # from myUtils import pickle_load, pickle_dump, symb_perf_stats_vectorized\n",
    "    import pandas as pd\n",
    "    from myUtils import symb_perf_stats_vectorized\n",
    "\n",
    "    perf_ranks_dict = {}  # dic of performance ranks\n",
    "    syms_perf_rank = []  # list of lists to store top 100 ranked symbols\n",
    "\n",
    "    # days_lookbacks = [-15, -30, -60, -120, -240]\n",
    "    # days_lookbacks = [-15, -30]\n",
    "\n",
    "    for days_lookback in days_lookbacks:\n",
    "        f_name = \"period\" + str(days_lookback)\n",
    "        _df_c = df_close[days_lookback::]\n",
    "        (\n",
    "            symbols,\n",
    "            period_yr,\n",
    "            drawdown,\n",
    "            UI,\n",
    "            max_drawdown,\n",
    "            returns_std,\n",
    "            Std_UI,\n",
    "            CAGR,\n",
    "            CAGR_Std,\n",
    "            CAGR_UI,\n",
    "        ) = symb_perf_stats_vectorized(_df_c)\n",
    "        caches_perf_stats_vect = []\n",
    "        for symbol in symbols:\n",
    "            date_first = drawdown.index[0].strftime(\"%Y-%m-%d\")\n",
    "            date_last = drawdown.index[-1].strftime(\"%Y-%m-%d\")\n",
    "            cache = (\n",
    "                symbol,\n",
    "                date_first,\n",
    "                date_last,\n",
    "                period_yr,\n",
    "                CAGR[symbol],\n",
    "                UI[symbol],\n",
    "                Std_UI[symbol],\n",
    "                CAGR_Std[symbol],\n",
    "                CAGR_UI[symbol],\n",
    "            )\n",
    "            # append performance data (tuple) to caches_perf_stats (list)\n",
    "            caches_perf_stats_vect.append(cache)\n",
    "        column_names = [\n",
    "            \"symbol\",\n",
    "            \"first date\",\n",
    "            \"last date\",\n",
    "            \"Year\",\n",
    "            \"CAGR\",\n",
    "            \"UI\",\n",
    "            \"Std/UI\",\n",
    "            \"CAGR/Std\",\n",
    "            \"CAGR/UI\",\n",
    "        ]\n",
    "\n",
    "        # write symbols' performance stats to dataframe\n",
    "        df_ps = pd.DataFrame(caches_perf_stats_vect, columns=column_names)\n",
    "        df_ps[\"r_CAGR/UI\"] = df_ps[\"CAGR/UI\"].rank(ascending=False)\n",
    "        df_ps[\"r_CAGR/Std\"] = df_ps[\"CAGR/Std\"].rank(ascending=False)\n",
    "        df_ps[\"r_Std/UI\"] = df_ps[\"Std/UI\"].rank(ascending=False)\n",
    "\n",
    "        _dict = {}\n",
    "        cols_sort = [\"r_CAGR/UI\", \"r_CAGR/Std\", \"r_Std/UI\"]\n",
    "\n",
    "        # print(f'{f_name} top 100 symbols')\n",
    "        for col in cols_sort:\n",
    "            symbols_top_n = (\n",
    "\n",
    "                # df_ps.sort_values(by=[col]).head(n_symbols).symbol.values\n",
    "                df_ps.sort_values(by=[col]).symbol.values\n",
    "\n",
    "            )\n",
    "            syms_perf_rank.append(list(symbols_top_n))\n",
    "            # print(f'{col}: {symbols_top_n}')\n",
    "            _dict[col] = symbols_top_n\n",
    "            perf_ranks_dict[f\"{f_name}\"] = _dict\n",
    "        # print(' ')\n",
    "\n",
    "    # pickle_dump(perf_ranks_dict, path_data_dump, f_pickled_perf_ranks_dict)\n",
    "    # print(f'perf_ranks_dict:\\n{perf_ranks_dict}\\n')\n",
    "\n",
    "    syms_perf_rank  # list of lists of top 100 rank\n",
    "    l_syms_perf_rank = [\n",
    "        val for sublist in syms_perf_rank for val in sublist\n",
    "    ]  # flatten list of lists\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    cnt_symbol_freq = Counter(l_syms_perf_rank)  # count symbols and frequency\n",
    "    # print(cnt_symbol_freq)\n",
    "    l_tuples = (\n",
    "        cnt_symbol_freq.most_common()\n",
    "    )  # convert to e.g [('AKRO', 6), ('IMVT', 4), ... ('ADEA', 3)]\n",
    "    symbols_ranked_perf_ranks = [\n",
    "        symbol for symbol, count in l_tuples\n",
    "    ]  # select just the symbols without the frequency counts\n",
    "\n",
    "\n",
    "    # symbols_ranked_perf_ranks = symbols_ranked_perf_ranks[:n_symbols]\n",
    "\n",
    "\n",
    "    ranked_perf_ranks_dict = {}\n",
    "    # f_name = f'ranked_perf_ranks_period' + str(_periods)  # key name, ranked_perf_ranks_dict\n",
    "    f_name = f\"ranked_perf_ranks_period\" + str(\n",
    "        days_lookbacks\n",
    "    )  # key name, ranked_perf_ranks_dict\n",
    "    ranked_perf_ranks_dict[\n",
    "        f\"{f_name}\"\n",
    "    ] = symbols_ranked_perf_ranks  # values: list of most common symbols in all performance ranks in descending order\n",
    "    # pickle_dump(ranked_perf_ranks_dict, path_data_dump, f_pickled_ranked_perf_ranks_dict)\n",
    "    # print(f'ranked_perf_ranks_dict:\\n{ranked_perf_ranks_dict}\\n')\n",
    "\n",
    "    return perf_ranks_dict, ranked_perf_ranks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import yfinance.shared as shared\n",
    "import time\n",
    "import pandas as pd\n",
    "# from datetime import date, timedelta, datetime\n",
    "from myUtils import pickle_dump, pickle_load, read_symbols_file # NOQA\n",
    "from myUtils import drop_symbols_all_NaN, chunked_list # NOQA\n",
    "from myUtils import yf_download_AdjOHLCV_noAutoAdj\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_df_c = 'df_close_clean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pickle_load(path_data_dump, filename_pickled_df_c)\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_lookbacks = [-15, -30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_ranks_dict, ranked_perf_ranks_dict = _4_perf_ranks(df_c, days_lookbacks, n_symbols=500, verbose=False)\n",
    "perf_ranks_dict, ranked_perf_ranks_dict = _4_perf_ranks1(df_c, days_lookbacks, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_slice = 0\n",
    "end_slice = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key0: period-15\n",
      "key1: r_CAGR/UI\n",
      "perf_ranks_dict[period-15][r_CAGR/UI][0:100]:\n",
      "['BBW' 'AXSM' 'BURL' 'CTRN' 'OFIX' 'POWL' 'AEO' 'TIPT' 'PEN' 'CVCO' 'AZN'\n",
      " 'PVH' 'ANF' 'RDNT' 'COUP' 'FE' 'NVS' 'GES' 'ROST' 'DMB' 'ATKR' 'HZNP'\n",
      " 'IIM' 'WLFC' 'BKE' 'BMRN' 'WEN' 'NVO' 'SJM' 'TBNK' 'MUJ' 'OFLX' 'NUVA'\n",
      " 'ZTO' 'GIS' 'UHAL' 'ODC' 'ZBH' 'CPB' 'MRK' 'CALM' 'ABBV' 'FL' 'BERY'\n",
      " 'AVA' 'FIVE' 'CAG' 'BVH' 'CIEN' 'BBY' 'UNVR' 'ULTA' 'BIDU' 'RIO' 'WEYS'\n",
      " 'NUO' 'DKS' 'EXC' 'MOH' 'RARE' 'VBF' 'HROW' 'NTGR' 'PCN' 'ISEE' 'TFX'\n",
      " 'PNW' 'KHC' 'CVS' 'GDS' 'ETR' 'ETSY' 'PG' 'RELL' 'ELV' 'NEWT' 'IPAR'\n",
      " 'SYK' 'ROG' 'CELH' 'VRDN' 'GSK' 'BDX' 'AMBC' 'MTX' 'HSY' 'MATW' 'MMS'\n",
      " 'HHC' 'MGI' 'STE' 'ENR' 'NI' 'PDI' 'KN' 'NWE' 'AEP' 'EDU' 'IFF' 'SPB']\n",
      "len(perf_ranks_dict[period-15][r_CAGR/UI][0:100]): 100\n",
      "key1: r_CAGR/Std\n",
      "perf_ranks_dict[period-15][r_CAGR/Std][0:100]:\n",
      "['AXSM' 'BBW' 'POWL' 'CTRN' 'OFIX' 'RDNT' 'BURL' 'PVH' 'AEO' 'ANF' 'COUP'\n",
      " 'PEN' 'HZNP' 'UHAL' 'ATKR' 'CVCO' 'GDS' 'WLFC' 'BMRN' 'ROST' 'BKE' 'GES'\n",
      " 'NVO' 'TIPT' 'BIDU' 'WEN' 'NUVA' 'OFLX' 'UNVR' 'ZTO' 'DMB' 'EDU' 'RELL'\n",
      " 'FL' 'DKS' 'RARE' 'ZBH' 'BBY' 'NEWT' 'MUJ' 'AVA' 'ETSY' 'ISEE' 'IIM' 'FE'\n",
      " 'TFX' 'SYK' 'BDX' 'ABBV' 'CPB' 'MRK' 'NVS' 'FIVE' 'MTX' 'NTGR' 'GIS'\n",
      " 'CHN' 'HROW' 'VRDN' 'SJM' 'EXC' 'STE' 'WEYS' 'MNRO' 'AMBA' 'BERY' 'CELH'\n",
      " 'ELV' 'CAG' 'ROG' 'AZN' 'NUO' 'HHC' 'PCN' 'GPS' 'ULTA' 'AEP' 'BSX' 'TBNK'\n",
      " 'KHC' 'RIO' 'CIEN' 'PMF' 'SPB' 'FIS' 'CALM' 'FIVN' 'WMC' 'CVS' 'FLEX'\n",
      " 'NSTG' 'BUD' 'OTTR' 'PAAS' 'IRM' 'PG' 'NI' 'IPAR' 'IFF' 'ENV']\n",
      "len(perf_ranks_dict[period-15][r_CAGR/Std][0:100]): 100\n",
      "key1: r_Std/UI\n",
      "perf_ranks_dict[period-15][r_Std/UI][0:100]:\n",
      "['AZN' 'TIPT' 'BURL' 'BBW' 'CVCO' 'NVS' 'FE' 'PEN' 'TBNK' 'AEO' 'ODC'\n",
      " 'IIM' 'AXSM' 'MGI' 'SJM' 'OFIX' 'CTRN' 'CALM' 'DMB' 'BVH' 'GES' 'GIS'\n",
      " 'MOH' 'ETR' 'ROST' 'AMBC' 'MUJ' 'CIEN' 'ANF' 'VBF' 'CPB' 'BERY' 'PNW'\n",
      " 'MRK' 'BKE' 'RIO' 'EOT' 'ULTA' 'CAF' 'CAG' 'ABBV' 'COUP' 'WEN' 'INSI'\n",
      " 'NVO' 'PVH' 'PDI' 'MMS' 'FIVE' 'NUO' 'MATW' 'WLFC' 'POWL' 'ATKR' 'HNW'\n",
      " 'WEYS' 'INCY' 'SJW' 'PG' 'ZBH' 'HSY' 'ABMD' 'CVS' 'AGR' 'OFLX' 'BMRN'\n",
      " 'ZTO' 'IPAR' 'SNY' 'NUVA' 'GSK' 'NWE' 'DE' 'CHT' 'RGR' 'HZNP' 'PCN' 'AVA'\n",
      " 'KHC' 'URBN' 'ENR' 'EXC' 'GRMN' 'YORW' 'WDAY' 'HUM' 'NID' 'NSS' 'JLS' 'K'\n",
      " 'MTH' 'KN' 'ACGL' 'GHY' 'SKX' 'GENC' 'NI' 'FL' 'HROW' 'IFF']\n",
      "len(perf_ranks_dict[period-15][r_Std/UI][0:100]): 100\n",
      " \n",
      "key0: period-30\n",
      "key1: r_CAGR/UI\n",
      "perf_ranks_dict[period-30][r_CAGR/UI][0:100]:\n",
      "['AXSM' 'WYNN' 'BBW' 'WLFC' 'ABMD' 'POWL' 'ZTO' 'HZNP' 'GDS' 'PVH' 'GILD'\n",
      " 'ACLS' 'LVS' 'BVH' 'TGLS' 'BIDU' 'AEO' 'SKX' 'UFPT' 'TIPT' 'APD' 'BERY'\n",
      " 'LSCC' 'JD' 'AU' 'RIO' 'YUMC' 'UNVR' 'HEES' 'CHN' 'BURL' 'PUK' 'AMBA'\n",
      " 'TCOM' 'NUO' 'VRDN' 'HHC' 'TSM' 'SEDG' 'HTHT' 'TSBK' 'NQP' 'KN' 'NOMD'\n",
      " 'BABA' 'CMPR' 'ELF' 'ODC' 'WB' 'KLAC' 'TRS' 'PDFS' 'AZN' 'CNHI' 'PNM'\n",
      " 'TBNK' 'NRIM' 'CIR' 'APAM' 'BA' 'MDRX' 'GES' 'OPY' 'YUM' 'RNR' 'ULTA'\n",
      " 'MUJ' 'RMBS' 'BHP' 'SBUX' 'AAON' 'CPRI' 'PG' 'MYE' 'ATKR' 'INCY' 'THRM'\n",
      " 'DMRC' 'AMG' 'GPS' 'IPAR' 'UTHR' 'MUI' 'BUD' 'KOP' 'PEN' 'PKX' 'AVNS'\n",
      " 'ENR' 'NGG' 'PNW' 'AMKR' 'NVO' 'NVS' 'WTW' 'EQIX' 'DD' 'PFGC' 'ROST'\n",
      " 'COLL']\n",
      "len(perf_ranks_dict[period-30][r_CAGR/UI][0:100]): 100\n",
      "key1: r_CAGR/Std\n",
      "perf_ranks_dict[period-30][r_CAGR/Std][0:100]:\n",
      "['AXSM' 'GDS' 'WYNN' 'POWL' 'JD' 'BBW' 'ZTO' 'BIDU' 'HZNP' 'TGLS' 'PVH'\n",
      " 'LVS' 'ACLS' 'YUMC' 'WLFC' 'CHN' 'HTHT' 'TCOM' 'WB' 'LSCC' 'AEO' 'AMBA'\n",
      " 'UNVR' 'BABA' 'TIPT' 'SKX' 'CMPR' 'BERY' 'AU' 'VRDN' 'CIR' 'PUK' 'BURL'\n",
      " 'AMKR' 'OPY' 'KN' 'APD' 'NRIM' 'VCYT' 'UFPT' 'HEES' 'PKX' 'RIO' 'RMBS'\n",
      " 'PEN' 'TSM' 'HHC' 'DMRC' 'BA' 'CNHI' 'THRM' 'SEDG' 'HOFT' 'EXAS' 'KLAC'\n",
      " 'GILD' 'GES' 'ATKR' 'OFIX' 'GPS' 'NOMD' 'NQP' 'ENV' 'PDFS' 'TSBK' 'AZN'\n",
      " 'DD' 'MDRX' 'NVS' 'BHP' 'BVH' 'WNC' 'CPRI' 'MUJ' 'BUD' 'RNR' 'AVNS' 'MYE'\n",
      " 'ODC' 'TRS' 'CARA' 'VRTV' 'MLAB' 'IPAR' 'ULTA' 'SLAB' 'NUO' 'ROST' 'ELF'\n",
      " 'UTHR' 'AAON' 'COLL' 'ABMD' 'KE' 'SIMO' 'NVDA' 'NVO' 'SCCO' 'PFGC' 'PG']\n",
      "len(perf_ranks_dict[period-30][r_CAGR/Std][0:100]): 100\n",
      "key1: r_Std/UI\n",
      "perf_ranks_dict[period-30][r_Std/UI][0:100]:\n",
      "['ABMD' 'BVH' 'GILD' 'ATCO' 'TBNK' 'WLFC' 'NUO' 'UFPT' 'BBW' 'ELF' 'PNM'\n",
      " 'NGG' 'MUI' 'APD' 'ODC' 'RIO' 'BFZ' 'YUM' 'TSBK' 'APAM' 'NAC' 'SKX' 'TRS'\n",
      " 'HEES' 'INCY' 'AEO' 'HZNP' 'PVH' 'WTW' 'MYI' 'AMG' 'NQP' 'NID' 'SBUX'\n",
      " 'NOMD' 'NMZ' 'PG' 'ENR' 'PNW' 'MQY' 'ULTA' 'ACLS' 'AAON' 'KOP' 'FIVE'\n",
      " 'PDFS' 'QNST' 'AZN' 'ZTO' 'HHC' 'BERY' 'AU' 'HSBC' 'TSM' 'IGI' 'MDLZ'\n",
      " 'RNR' 'MGI' 'ACM' 'THW' 'MDRX' 'ODP' 'BURL' 'CHGG' 'UTHR' 'TIPT' 'MUJ'\n",
      " 'AXS' 'GNL' 'CCK' 'SEDG' 'EQIX' 'WYNN' 'POWL' 'JHS' 'SNY' 'EOT' 'MYE'\n",
      " 'CPRI' 'ASIX' 'NXJ' 'KLAC' 'BHP' 'IGT' 'UTG' 'NVO' 'LVS' 'IPAR' 'TAK'\n",
      " 'ES' 'STRA' 'IRM' 'DE' 'PFGC' 'NEE' 'BBWI' 'UL' 'DEO' 'PWOD' 'PUK']\n",
      "len(perf_ranks_dict[period-30][r_Std/UI][0:100]): 100\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for key0 in perf_ranks_dict.keys():\n",
    "  print(f'key0: {key0}')\n",
    "  for key1 in perf_ranks_dict[key0].keys():\n",
    "    print(f'key1: {key1}')\n",
    "\n",
    "    print(f'perf_ranks_dict[{key0}][{key1}][{start_slice}:{end_slice}]:\\n{perf_ranks_dict[key0][key1][start_slice:end_slice]}')    \n",
    "    print(f'len(perf_ranks_dict[{key0}][{key1}][{start_slice}:{end_slice}]): {len(perf_ranks_dict[key0][key1][start_slice:end_slice])}')\n",
    "    \n",
    "    # print(f'perf_ranks_dict[{key0}][{key1}]:\\n{perf_ranks_dict[key0][key1]}')    \n",
    "    # print(f'len(perf_ranks_dict[{key0}][{key1}]): {len(perf_ranks_dict[key0][key1])}')\n",
    "  \n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key0: period-15\n",
      "key1: r_CAGR/UI\n",
      "perf_ranks_dict[period-15][r_CAGR/UI]:\n",
      "['BBW' 'AXSM' 'BURL' ... 'AROW' 'VVV' 'UNTY']\n",
      "len(perf_ranks_dict[period-15][r_CAGR/UI]): 2299\n",
      "key1: r_CAGR/Std\n",
      "perf_ranks_dict[period-15][r_CAGR/Std]:\n",
      "['AXSM' 'BBW' 'POWL' ... 'FFIC' 'DKL' 'FNWB']\n",
      "len(perf_ranks_dict[period-15][r_CAGR/Std]): 2299\n",
      "key1: r_Std/UI\n",
      "perf_ranks_dict[period-15][r_Std/UI]:\n",
      "['AZN' 'TIPT' 'BURL' ... 'PBF' 'DK' 'DKL']\n",
      "len(perf_ranks_dict[period-15][r_Std/UI]): 2299\n",
      " \n",
      "key0: period-30\n",
      "key1: r_CAGR/UI\n",
      "perf_ranks_dict[period-30][r_CAGR/UI]:\n",
      "['AXSM' 'WYNN' 'BBW' ... 'SAVE' 'MTB' 'EPD']\n",
      "len(perf_ranks_dict[period-30][r_CAGR/UI]): 2299\n",
      "key1: r_CAGR/Std\n",
      "perf_ranks_dict[period-30][r_CAGR/Std]:\n",
      "['AXSM' 'GDS' 'WYNN' ... 'FNWB' 'IEP' 'IRBT']\n",
      "len(perf_ranks_dict[period-30][r_CAGR/Std]): 2299\n",
      "key1: r_Std/UI\n",
      "perf_ranks_dict[period-30][r_Std/UI]:\n",
      "['ABMD' 'BVH' 'GILD' ... 'MARA' 'TTGT' 'MPAA']\n",
      "len(perf_ranks_dict[period-30][r_Std/UI]): 2299\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for key0 in perf_ranks_dict.keys():\n",
    "  print(f'key0: {key0}')\n",
    "  for key1 in perf_ranks_dict[key0].keys():\n",
    "    print(f'key1: {key1}')\n",
    "    # print(f'perf_ranks_dict[{key0}][{key1}][{start_slice}:{end_slice}]:\\n{perf_ranks_dict[key0][key1][start_slice:end_slice]}')    \n",
    "    # print(f'len(perf_ranks_dict[{key0}][{key1}][{start_slice}:{end_slice}]): {len(perf_ranks_dict[key0][key1][start_slice:end_slice])}')\n",
    "    \n",
    "    print(f'perf_ranks_dict[{key0}][{key1}]:\\n{perf_ranks_dict[key0][key1]}')    \n",
    "    print(f'len(perf_ranks_dict[{key0}][{key1}]): {len(perf_ranks_dict[key0][key1])}')\n",
    "  \n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perf_ranks_dict[key0][key1][start_slice:end_slice]    \n",
    "len(perf_ranks_dict[key0][key1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_slices (df, n_samples, days_lookback, days_eval):\n",
    "\n",
    "  import random\n",
    "  from random import randint\n",
    "\n",
    "  n_sample = 0\n",
    "  days_total = days_lookback + days_eval\n",
    "  print(f'days_lookback: {days_lookback}, days_eval: {days_eval}, days_total: {days_total}, len(df): {len(df)}')\n",
    "\n",
    "  if days_total > len(df):\n",
    "    msg_err = f'days_total: {days_total} must be less or equal to len(df): {len(df)}'\n",
    "    raise SystemExit(msg_err)\n",
    "\n",
    "  # random slices of iloc for train and eval that fits the days_lookback, days_eval and total len(df) constraints\n",
    "  l_slices = []  \n",
    "  while n_sample < n_samples:\n",
    "    random.seed(0)\n",
    "    n_rand = randint(0, 250-1)\n",
    "    start_train = n_rand - days_lookback\n",
    "    end_train = n_rand\n",
    "    start_eval = n_rand\n",
    "    end_eval = n_rand + days_eval\n",
    "    if 0 <= start_train and end_eval <= len(df):\n",
    "      l_slices.append((start_train, end_train, end_eval))\n",
    "      # print(f'n_rand: {n_rand:>3},    start_train: {start_train:>3},    end_train: {end_train:>3},    start_eval: {start_eval:>3},    end_eval: {end_eval:>3},    n_sample: {n_sample:>3}')\n",
    "      # ======== valid n_rand, do test and validation here ========\n",
    "      # ======== valid n_rand, do test and validation here ========\n",
    "      n_sample += 1\n",
    "\n",
    "  return l_slices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from myUtils import pickle_load, pickle_dump, symb_perf_stats_vectorized\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_load(path_data_dump, 'df_train')\n",
    "print(f\"Full path to pickled df_train: {path_data_dump}df_train\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_slices = random_slices(df, n_samples=100, days_lookback=120, days_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_slice in l_slices[0:1]:\n",
    "  start_train = l_slice[0]\n",
    "  end_train = l_slice[1]\n",
    "  df_train = df.iloc[start_train:end_train]\n",
    "\n",
    "  start_eval = end_train\n",
    "  end_eval = l_slice[2]\n",
    "  df_eval = df.iloc[start_eval:end_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
