{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 14)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 800)\n",
    "\n",
    "# verbose = False  # True prints more output\n",
    "verbose = True  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "\n",
    "# fp_df_eval_results = 'df_eval_results'\n",
    "fp_df_eval_sym_freq_results = 'df_eval_sym_freq_results'\n",
    "\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_df_train: 1050, len_df_val: 300, len_df_test: 150 \n"
     ]
    }
   ],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "\n",
    "###################################\n",
    "# df_train, df_val, df_test = _2_split_train_val_test(df_close_clean, s_train=1, s_val=0, s_test=0)\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)\n",
    "###################################\n",
    "\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if store_results:  # record results to df\n",
    "# my_cols = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std', 'SPY_CAGR/UI']\n",
    "# df_eval_results = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df_eval_sym_freq_results = pickle_load(path_data_dump, fp_df_eval_sym_freq_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write run results to df_eval_results\n",
    "# store_results = False\n",
    "store_results = True\n",
    "\n",
    "# number of max lookback tuples to create for iloc start_train:end_train:end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "n_samples = 2\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback end_train\n",
    "days_lookbacks = [15, 30, 60, 120]\n",
    "days_lookbacks = [30, 60, 120]\n",
    "days_lookbacks = [60, 120]\n",
    "days_lookbacks = [120]\n",
    "days_lookbacks = [60]\n",
    "days_lookbacks = [30]\n",
    "days_lookbacks = [15]\n",
    "days_lookbacks = [15, 30]\n",
    "# days_lookbacks = [15, 29]\n",
    "# days_lookbacks = [15, 31]\n",
    "# days_lookbacks = [14, 30]\n",
    "# days_lookbacks = [16, 32]\n",
    "# days_lookbacks = [14, 28]\n",
    "\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from end_train are used to evaluate effectiveness of the training\n",
    "# days_eval = 10\n",
    "days_eval = 5\n",
    "# days_eval = 4\n",
    "# days_eval = 3\n",
    "# days_eval = 2  \n",
    "\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "syms_start = 0  #  start index of n_top_syms for evaluation\n",
    "# syms_start = 1  #  start index of n_top_syms for evaluation\n",
    "\n",
    "# syms_end = n_top_syms  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 1  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 2  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 3  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 4  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 5  #  end index of n_top_syms for evaluation\n",
    "# syms_end = 6  #  end index of n_top_syms for evaluation\n",
    "syms_end = 10  #  end index of n_top_syms for evaluation\n",
    "\n",
    "freq_cnt = 6  # frequency of symbol in top_set_syms_n_freq "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a sets of iloc lookback slices (start_train:end_train:end_eval), where  \n",
    "end_train - start_train = days_lookback  \n",
    "end_eval - end_train = days_eval  \n",
    "for example,  \n",
    "if given:  \n",
    " n_samples = 2  \n",
    " days_lookbacks = [30, 60, 120]  \n",
    " days_eval = 10  \n",
    "a possible result is:  \n",
    " max_lookback_slices:  \n",
    " [(150, 270, 280), (5, 125, 135)]  \n",
    " where 270-150=125-5=max(days_lookbacks), 280-270=135-125=days_eval  \n",
    " sets_lookback_slices:  \n",
    " [[(240, 270, 280), (210, 270, 280), (150, 270, 280)], [(95, 125, 135), (65, 125, 135), (5, 125, 135)]]  \n",
    "  where in a set, 270-240=days_lookbacks[0], 270-210=days_lookbacks[1], 270-150=days_lookbacks[2]  \n",
    "  and 270, i.e. end_train, is constant for the set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_lookback_slices:\n",
      "[(87, 117, 122), (325, 355, 360)]\n",
      "sets_lookback_slices:\n",
      "[[(102, 117, 122), (87, 117, 122)], [(340, 355, 360), (325, 355, 360)]]\n"
     ]
    }
   ],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df_train, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}')\n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate lists, n_samples long, of the highest performance ranked symbols. The performance metrics are: CAGR/UI, CAGR/retnStd, retnStd/UI. n_top_syms of the best performing symbols from each metric are combined. The symbols are sorted by their number of appearances in the combined pool, and are placed in a list. A slice of the best performing symbols is selected by syms_start:syms_end, i.e. top_set_syms_n_freq[syms_start:syms_end].     \n",
    "\n",
    "The performance metrics are calculated based on slices in sets_lookback_slices.  The first two numbers are ilocs for training. The last two numbers are ilocs for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days lookback: 15\n",
      "lb_slices:     [(102, 117, 122), (87, 117, 122)]\n",
      "lb_slice:      (102, 117, 122)\n",
      "days eval:     5\n",
      "start_train:   102\n",
      "end_train:     117\n",
      "perf_ranks: {'period-15': {'r_CAGR/UI': array(['TNDM', 'NTRA', 'ATHM', 'MED', 'CUTR', 'QNST', 'CLMT', 'MYGN',\n",
      "       'BLFS', 'TVTX', 'PPC', 'YELP', 'AJRD', 'WING', 'CSTM', 'PAR',\n",
      "       'CMS', 'TTWO', 'WB', 'EXTR'], dtype=object), 'r_CAGR/retnStd': array(['TNDM', 'ATHM', 'NTRA', 'QNST', 'MED', 'BLFS', 'CLMT', 'CUTR',\n",
      "       'PPC', 'TVTX', 'MYGN', 'CSTM', 'YELP', 'WING', 'WB', 'PAR', 'OSTK',\n",
      "       'CYRX', 'EXTR', 'AJRD'], dtype=object), 'r_retnStd/UI': array(['NTRA', 'AJRD', 'CUTR', 'YELP', 'MED', 'MYGN', 'ATHM', 'CMS',\n",
      "       'WING', 'TTWO', 'FTSM', 'IRTC', 'TPVG', 'PZZA', 'TVTX', 'DXCM',\n",
      "       'ANET', 'PAR', 'NVO', 'NOMD'], dtype=object)}}\n",
      "most_common_syms: [('NTRA', 3), ('ATHM', 3), ('MED', 3), ('CUTR', 3), ('MYGN', 3), ('TVTX', 3), ('YELP', 3), ('AJRD', 3), ('WING', 3), ('PAR', 3), ('TNDM', 2), ('QNST', 2), ('CLMT', 2), ('BLFS', 2), ('PPC', 2), ('CSTM', 2), ('CMS', 2), ('TTWO', 2), ('WB', 2), ('EXTR', 2), ('OSTK', 1), ('CYRX', 1), ('FTSM', 1), ('IRTC', 1), ('TPVG', 1), ('PZZA', 1), ('DXCM', 1), ('ANET', 1), ('NVO', 1), ('NOMD', 1)]\n",
      "+++ finish lookback slice 15 +++\n",
      "\n",
      "days lookback: 30\n",
      "lb_slices:     [(102, 117, 122), (87, 117, 122)]\n",
      "lb_slice:      (87, 117, 122)\n",
      "days eval:     5\n",
      "start_train:   87\n",
      "end_train:     117\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['NRG', 'PPC', 'CLMT', 'CYRX', 'MED', 'ATHM', 'BLFS', 'AJRD',\n",
      "       'HTHT', 'WB', 'YELP', 'RACE', 'AVA', 'TECK', 'PAR', 'PG', 'TIMB',\n",
      "       'SQM', 'TVTX', 'SR'], dtype=object), 'r_CAGR/retnStd': array(['CLMT', 'CYRX', 'BLFS', 'PPC', 'NRG', 'ATHM', 'HTHT', 'MED', 'SQM',\n",
      "       'RACE', 'WB', 'TECK', 'YY', 'TVTX', 'PEG', 'OSTK', 'AJRD', 'SRC',\n",
      "       'AEE', 'FE'], dtype=object), 'r_retnStd/UI': array(['AVA', 'AJRD', 'MED', 'YELP', 'NRG', 'ATHM', 'PPC', 'PG', 'AGR',\n",
      "       'PAR', 'TIMB', 'TTWO', 'SPR', 'MAA', 'DELL', 'CUTR', 'SR', 'NEE',\n",
      "       'BWXT', 'VMW'], dtype=object)}}\n",
      "most_common_syms: [('NRG', 3), ('PPC', 3), ('MED', 3), ('ATHM', 3), ('AJRD', 3), ('CLMT', 2), ('CYRX', 2), ('BLFS', 2), ('HTHT', 2), ('WB', 2), ('YELP', 2), ('RACE', 2), ('AVA', 2), ('TECK', 2), ('PAR', 2), ('PG', 2), ('TIMB', 2), ('SQM', 2), ('TVTX', 2), ('SR', 2), ('YY', 1), ('PEG', 1), ('OSTK', 1), ('SRC', 1), ('AEE', 1), ('FE', 1), ('AGR', 1), ('TTWO', 1), ('SPR', 1), ('MAA', 1), ('DELL', 1), ('CUTR', 1), ('NEE', 1), ('BWXT', 1), ('VMW', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "grp_most_common_syms: [[('NTRA', 3), ('ATHM', 3), ('MED', 3), ('CUTR', 3), ('MYGN', 3), ('TVTX', 3), ('YELP', 3), ('AJRD', 3), ('WING', 3), ('PAR', 3), ('TNDM', 2), ('QNST', 2), ('CLMT', 2), ('BLFS', 2), ('PPC', 2), ('CSTM', 2), ('CMS', 2), ('TTWO', 2), ('WB', 2), ('EXTR', 2), ('OSTK', 1), ('CYRX', 1), ('FTSM', 1), ('IRTC', 1), ('TPVG', 1), ('PZZA', 1), ('DXCM', 1), ('ANET', 1), ('NVO', 1), ('NOMD', 1)], [('NRG', 3), ('PPC', 3), ('MED', 3), ('ATHM', 3), ('AJRD', 3), ('CLMT', 2), ('CYRX', 2), ('BLFS', 2), ('HTHT', 2), ('WB', 2), ('YELP', 2), ('RACE', 2), ('AVA', 2), ('TECK', 2), ('PAR', 2), ('PG', 2), ('TIMB', 2), ('SQM', 2), ('TVTX', 2), ('SR', 2), ('YY', 1), ('PEG', 1), ('OSTK', 1), ('SRC', 1), ('AEE', 1), ('FE', 1), ('AGR', 1), ('TTWO', 1), ('SPR', 1), ('MAA', 1), ('DELL', 1), ('CUTR', 1), ('NEE', 1), ('BWXT', 1), ('VMW', 1)]]\n",
      "**** finish lookback slices [(102, 117, 122), (87, 117, 122)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(102, 117, 122), (87, 117, 122)]:\n",
      "[('AJRD', 6), ('ATHM', 6), ('MED', 6), ('PAR', 5), ('PPC', 5), ('TVTX', 5), ('YELP', 5), ('BLFS', 4), ('CLMT', 4), ('CUTR', 4), ('WB', 4), ('CYRX', 3), ('MYGN', 3), ('NRG', 3), ('NTRA', 3), ('TTWO', 3), ('WING', 3), ('AVA', 2), ('CMS', 2), ('CSTM', 2)]\n",
      "top 20 ranked symbols from set [(102, 117, 122), (87, 117, 122)]:\n",
      "['AJRD', 'ATHM', 'MED', 'PAR', 'PPC', 'TVTX', 'YELP', 'BLFS', 'CLMT', 'CUTR']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(102, 117, 122), (87, 117, 122)] =====\n",
      "\n",
      "\n",
      "days lookback: 15\n",
      "lb_slices:     [(340, 355, 360), (325, 355, 360)]\n",
      "lb_slice:      (340, 355, 360)\n",
      "days eval:     5\n",
      "start_train:   340\n",
      "end_train:     355\n",
      "perf_ranks: {'period-15': {'r_CAGR/UI': array(['CLF', 'TSLX', 'HCA', 'RDN', 'CACC', 'MPC', 'UBS', 'RHI', 'HWM',\n",
      "       'AFL', 'TSM', 'NUVA', 'ALSN', 'LIVN', 'CCU', 'MCS', 'THR', 'CHRW',\n",
      "       'EIG', 'TA'], dtype=object), 'r_CAGR/retnStd': array(['CLF', 'HWM', 'RDN', 'TA', 'HCA', 'LIVN', 'NUVA', 'CSTM', 'GTLS',\n",
      "       'CACC', 'TSM', 'MPC', 'CHRW', 'MRCY', 'TSLX', 'CCU', 'THR', 'MCS',\n",
      "       'RHI', 'FCN'], dtype=object), 'r_retnStd/UI': array(['TSLX', 'UBS', 'CACC', 'RHI', 'HCA', 'ALSN', 'MPC', 'NVS', 'AFL',\n",
      "       'RDN', 'EIG', 'MAN', 'TSM', 'GLW', 'HCKT', 'CSX', 'CCU', 'MBI',\n",
      "       'AVY', 'MCS'], dtype=object)}}\n",
      "most_common_syms: [('TSLX', 3), ('HCA', 3), ('RDN', 3), ('CACC', 3), ('MPC', 3), ('RHI', 3), ('TSM', 3), ('CCU', 3), ('MCS', 3), ('CLF', 2), ('UBS', 2), ('HWM', 2), ('AFL', 2), ('NUVA', 2), ('ALSN', 2), ('LIVN', 2), ('THR', 2), ('CHRW', 2), ('EIG', 2), ('TA', 2), ('CSTM', 1), ('GTLS', 1), ('MRCY', 1), ('FCN', 1), ('NVS', 1), ('MAN', 1), ('GLW', 1), ('HCKT', 1), ('CSX', 1), ('MBI', 1), ('AVY', 1)]\n",
      "+++ finish lookback slice 15 +++\n",
      "\n",
      "days lookback: 30\n",
      "lb_slices:     [(340, 355, 360), (325, 355, 360)]\n",
      "lb_slice:      (325, 355, 360)\n",
      "days eval:     5\n",
      "start_train:   325\n",
      "end_train:     355\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['NTRA', 'DLR', 'MRCY', 'RPM', 'FMX', 'FCN', 'BLFS', 'RAMP', 'TNDM',\n",
      "       'MOH', 'CSL', 'PFE', 'FTSM', 'LLY', 'SCL', 'GTLS', 'HWM', 'KDP',\n",
      "       'COO', 'KO'], dtype=object), 'r_CAGR/retnStd': array(['NTRA', 'BLFS', 'TNDM', 'NOG', 'RPM', 'MRCY', 'RAMP', 'FCN', 'DLR',\n",
      "       'FMX', 'SRCL', 'COO', 'KDP', 'LLY', 'PBR', 'GTLS', 'PFE', 'MOH',\n",
      "       'HWM', 'CB'], dtype=object), 'r_retnStd/UI': array(['DLR', 'CSL', 'FTSM', 'AVY', 'FMX', 'MOH', 'PFE', 'MRCY', 'SCL',\n",
      "       'IFN', 'KO', 'HCKT', 'LLY', 'RPM', 'BDX', 'HII', 'DOV', 'HWM',\n",
      "       'NTRA', 'FCN'], dtype=object)}}\n",
      "most_common_syms: [('NTRA', 3), ('DLR', 3), ('MRCY', 3), ('RPM', 3), ('FMX', 3), ('FCN', 3), ('MOH', 3), ('PFE', 3), ('LLY', 3), ('HWM', 3), ('BLFS', 2), ('RAMP', 2), ('TNDM', 2), ('CSL', 2), ('FTSM', 2), ('SCL', 2), ('GTLS', 2), ('KDP', 2), ('COO', 2), ('KO', 2), ('NOG', 1), ('SRCL', 1), ('PBR', 1), ('CB', 1), ('AVY', 1), ('IFN', 1), ('HCKT', 1), ('BDX', 1), ('HII', 1), ('DOV', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "grp_most_common_syms: [[('TSLX', 3), ('HCA', 3), ('RDN', 3), ('CACC', 3), ('MPC', 3), ('RHI', 3), ('TSM', 3), ('CCU', 3), ('MCS', 3), ('CLF', 2), ('UBS', 2), ('HWM', 2), ('AFL', 2), ('NUVA', 2), ('ALSN', 2), ('LIVN', 2), ('THR', 2), ('CHRW', 2), ('EIG', 2), ('TA', 2), ('CSTM', 1), ('GTLS', 1), ('MRCY', 1), ('FCN', 1), ('NVS', 1), ('MAN', 1), ('GLW', 1), ('HCKT', 1), ('CSX', 1), ('MBI', 1), ('AVY', 1)], [('NTRA', 3), ('DLR', 3), ('MRCY', 3), ('RPM', 3), ('FMX', 3), ('FCN', 3), ('MOH', 3), ('PFE', 3), ('LLY', 3), ('HWM', 3), ('BLFS', 2), ('RAMP', 2), ('TNDM', 2), ('CSL', 2), ('FTSM', 2), ('SCL', 2), ('GTLS', 2), ('KDP', 2), ('COO', 2), ('KO', 2), ('NOG', 1), ('SRCL', 1), ('PBR', 1), ('CB', 1), ('AVY', 1), ('IFN', 1), ('HCKT', 1), ('BDX', 1), ('HII', 1), ('DOV', 1)]]\n",
      "**** finish lookback slices [(340, 355, 360), (325, 355, 360)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(340, 355, 360), (325, 355, 360)]:\n",
      "[('HWM', 5), ('FCN', 4), ('MRCY', 4), ('CACC', 3), ('CCU', 3), ('DLR', 3), ('FMX', 3), ('GTLS', 3), ('HCA', 3), ('LLY', 3), ('MCS', 3), ('MOH', 3), ('MPC', 3), ('NTRA', 3), ('PFE', 3), ('RDN', 3), ('RHI', 3), ('RPM', 3), ('TSLX', 3), ('TSM', 3)]\n",
      "top 20 ranked symbols from set [(340, 355, 360), (325, 355, 360)]:\n",
      "['HWM', 'FCN', 'MRCY', 'CACC', 'CCU', 'DLR', 'FMX', 'GTLS', 'HCA', 'LLY']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(340, 355, 360), (325, 355, 360)] =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # list of lists of top_set_symbols, there are n_samples lists in list\n",
    "# loop thru lists of tuples of start_train:end_train:end_eval, i.e.\n",
    "#  [[(887, 917, 927), (857, 917, 927), (797, 917, 927)],\n",
    "#  [(483, 513, 523), (453, 513, 523), (393, 513, 523)]]\n",
    "for lb_slices in sets_lookback_slices:\n",
    "  grp_most_common_syms = []  \n",
    "  for lb_slice in lb_slices:  # lb_slice, e.g. (246, 276, 286)\n",
    "    start_train = lb_slice[0]\n",
    "    end_train = lb_slice[1]\n",
    "    start_eval = end_train\n",
    "    end_eval = lb_slice[2]\n",
    "    lookback = end_train - start_train\n",
    "    d_eval = end_eval - start_eval\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback: {lookback}')\n",
    "      print(f'lb_slices:     {lb_slices}')\n",
    "      print(f'lb_slice:      {lb_slice}')\n",
    "      print(f'days eval:     {d_eval}')    \n",
    "      print(f'start_train:   {start_train}')\n",
    "      print(f'end_train:     {end_train}')\n",
    "      # print(f'start_eval:    {start_eval}')\n",
    "      # print(f'end_eval:      {end_eval}')`\n",
    "\n",
    "    _df = df_train.iloc[start_train:end_train]\n",
    "    perf_ranks, most_common_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "    grp_most_common_syms.append(most_common_syms)\n",
    "    \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_common_syms: {most_common_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_common_syms: {grp_most_common_syms}')\n",
    "    # grp_most_common_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "  # group symbols from set of days_lookbacks (i.e. lb_slices) and sum frequency of the symbols\n",
    "  set_most_common_syms = _6_grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "  # get the top few most-frequent symbol:frequency pairs\n",
    "  top_set_syms_n_freq = set_most_common_syms[0:n_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq\n",
    "\n",
    "###################################  \n",
    "  # top_set_syms = [i[0] for i in top_set_syms_n_freq]\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "###################################  \n",
    "  \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_set_sym_freq_cnt(top_set_syms_n_freq):\n",
    "    sym_freq_cnt_6 = []\n",
    "    sym_freq_cnt_5 = []\n",
    "    sym_freq_cnt_4 = []\n",
    "    sym_freq_cnt_3 = []\n",
    "    sym_freq_cnt_2 = []\n",
    "\n",
    "    for sym_n_freq in top_set_syms_n_freq:\n",
    "        _sym = sym_n_freq[0]\n",
    "        _freq = sym_n_freq[1]\n",
    "        # print(_sym, _freq)\n",
    "        if _freq == 6:\n",
    "            sym_freq_cnt_6.append(_sym)\n",
    "        elif _freq == 5:\n",
    "            sym_freq_cnt_5.append(_sym)\n",
    "        elif _freq == 4:\n",
    "            sym_freq_cnt_4.append(_sym)\n",
    "        elif _freq == 3:\n",
    "            sym_freq_cnt_3.append(_sym)          \n",
    "        else:\n",
    "            sym_freq_cnt_2.append(_sym)\n",
    "\n",
    "    l_sym_freq_cnt = []\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_6)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_5)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_4)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_3)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_2)    \n",
    "\n",
    "    # if verbose:\n",
    "    #     print(f'sym_freq_cnt_6: {sym_freq_cnt_6}')\n",
    "    #     print(f'sym_freq_cnt_5: {sym_freq_cnt_5}')\n",
    "    #     print(f'sym_freq_cnt_4: {sym_freq_cnt_4}')\n",
    "    #     print(f'sym_freq_cnt_3: {sym_freq_cnt_3}')\n",
    "    #     print(f'sym_freq_cnt_2: {sym_freq_cnt_2}')\n",
    "\n",
    "    # return sym_freq_cnt_6, sym_freq_cnt_5, sym_freq_cnt_4, sym_freq_cnt_3, sym_freq_cnt_2\n",
    "    return l_sym_freq_cnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sym_freq_6: ['AJRD', 'ATHM', 'MED']\n",
      "sym_freq_5: ['PAR', 'PPC', 'TVTX', 'YELP']\n",
      "sym_freq_4: ['BLFS', 'CLMT', 'CUTR', 'WB']\n",
      "sym_freq_3: ['CYRX', 'MYGN', 'NRG', 'NTRA', 'TTWO', 'WING']\n",
      "sym_freq_2: ['AVA', 'CMS', 'CSTM']\n",
      "\n",
      "sym_freq_6: []\n",
      "sym_freq_5: ['HWM']\n",
      "sym_freq_4: ['FCN', 'MRCY']\n",
      "sym_freq_3: ['CACC', 'CCU', 'DLR', 'FMX', 'GTLS', 'HCA', 'LLY', 'MCS', 'MOH', 'MPC', 'NTRA', 'PFE', 'RDN', 'RHI', 'RPM', 'TSLX', 'TSM']\n",
      "sym_freq_2: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for top_set_syms_n_freq in grp_top_set_syms_n_freq:\n",
    "  l_sym_freq_cnt = sym_freq_cnt(top_set_syms_n_freq)\n",
    "  print(f'sym_freq_6: {l_sym_freq_cnt[0]}')\n",
    "  print(f'sym_freq_5: {l_sym_freq_cnt[1]}')\n",
    "  print(f'sym_freq_4: {l_sym_freq_cnt[2]}')\n",
    "  print(f'sym_freq_3: {l_sym_freq_cnt[3]}')\n",
    "  print(f'sym_freq_2: {l_sym_freq_cnt[4]}\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "((87, 117, 122), [('AJRD', 6), ('ATHM', 6), ('MED', 6), ('PAR', 5), ('PPC', 5), ('TVTX', 5), ('YELP', 5), ('BLFS', 4), ('CLMT', 4), ('CUTR', 4), ('WB', 4), ('CYRX', 3), ('MYGN', 3), ('NRG', 3), ('NTRA', 3), ('TTWO', 3), ('WING', 3), ('AVA', 2), ('CMS', 2), ('CSTM', 2)])\n",
      "((325, 355, 360), [('HWM', 5), ('FCN', 4), ('MRCY', 4), ('CACC', 3), ('CCU', 3), ('DLR', 3), ('FMX', 3), ('GTLS', 3), ('HCA', 3), ('LLY', 3), ('MCS', 3), ('MOH', 3), ('MPC', 3), ('NTRA', 3), ('PFE', 3), ('RDN', 3), ('RHI', 3), ('RPM', 3), ('TSLX', 3), ('TSM', 3)])\n"
     ]
    }
   ],
   "source": [
    "print('z_grp_top_set_syms_n_freq:')\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "for items in z_grp_top_set_syms_n_freq:\n",
    "  print(items)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'sym_freq_cnt', 'grp(retnStd/UI)_mean', 'grp(retnStd/UI)_std', 'grp(retnStd/UI)_mean/std', 'grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std', 'grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std', 'SPY_retnStd/UI', 'SPY_CAGR/retnStd', 'SPY_CAGR/UI'], dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_sym_freq_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "1 of 2 max_lookback_slice\n",
      "max_lookback_slice: (87, 117, 122)\n",
      "max lookback dates: 2017-07-11, 2017-08-22, 2017-08-29\n",
      "df_eval dates (inclusive): 2017-08-22 - 2017-08-28\n",
      "top_set_syms_n_freq: [('AJRD', 6), ('ATHM', 6), ('MED', 6), ('PAR', 5), ('PPC', 5), ('TVTX', 5), ('YELP', 5), ('BLFS', 4), ('CLMT', 4), ('CUTR', 4), ('WB', 4), ('CYRX', 3), ('MYGN', 3), ('NRG', 3), ('NTRA', 3), ('TTWO', 3), ('WING', 3), ('AVA', 2), ('CMS', 2), ('CSTM', 2)]\n",
      "\n",
      "sym_freq_6: ['AJRD', 'ATHM', 'MED']\n",
      "sym_freq_5: ['PAR', 'PPC', 'TVTX', 'YELP']\n",
      "sym_freq_4: ['BLFS', 'CLMT', 'CUTR', 'WB']\n",
      "sym_freq_3: ['CYRX', 'MYGN', 'NRG', 'NTRA', 'TTWO', 'WING']\n",
      "\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:         0.685,       -62.513,       -42.835\n",
      "start_eval: 117,  date: 2017-08-22\n",
      "end_eval:   122,  date: 2017-08-29,  df_eval last date: 2017-08-28\n",
      "frequency count of symbol(s): 6\n",
      "\n",
      "df_eval:\n",
      "                 AJRD       ATHM        MED\n",
      "Date                                       \n",
      "2017-08-22  25.573433  63.195648  49.335510\n",
      "2017-08-23  25.348156  62.232353  48.901653\n",
      "2017-08-24  25.312113  62.470787  49.043324\n",
      "2017-08-25  24.870571  60.754036  49.406349\n",
      "2017-08-28  24.969690  60.258087  48.954788\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         0.778,         0.483,         1.610\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       -61.108,        19.644,        -3.111\n",
      "grp(CAGR/UI):      mean, std, mean/std:       -41.400,         9.812,        -4.219\n",
      "row_add_total: [2, '[15, 30]', 5, 20, 6, 0.778373246121212, 0.4833978028953631, 1.6102126270724892, -61.10816212388019, 19.643551738662456, -3.110850977300966, -41.39966448144524, 9.812035266880606, -4.219273917734992, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "appended row_add to df_eval_sym_freq_results:\n",
      "[2, '[15, 30]', 5, 20, 6, 0.778373246121212, 0.4833978028953631, 1.6102126270724892, -61.10816212388019, 19.643551738662456, -3.110850977300966, -41.39966448144524, 9.812035266880606, -4.219273917734992, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "\n",
      "================================================== \n",
      "\n",
      "start_eval: 117,  date: 2017-08-22\n",
      "end_eval:   122,  date: 2017-08-29,  df_eval last date: 2017-08-28\n",
      "frequency count of symbol(s): 5\n",
      "\n",
      "df_eval:\n",
      "              PAR        PPC       TVTX       YELP\n",
      "Date                                              \n",
      "2017-08-22  10.38  28.969999  23.910000  41.869999\n",
      "2017-08-23  10.50  29.110001  23.760000  42.119999\n",
      "2017-08-24  10.43  28.590000  23.680000  41.750000\n",
      "2017-08-25  11.00  28.400000  23.719999  42.139999\n",
      "2017-08-28  10.92  28.650000  23.990000  42.139999\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         2.660,         2.668,         0.997\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       111.268,       201.503,         0.552\n",
      "grp(CAGR/UI):      mean, std, mean/std:       698.065,     1,331.354,         0.524\n",
      "row_add_total: [2, '[15, 30]', 5, 20, 5, 2.660037308950124, 2.667601017022826, 0.9971646029430805, 111.26816623684576, 201.50266160787078, 0.5521920422737462, 698.0651498550478, 1331.3539417336378, 0.5243272491055642, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "appended row_add to df_eval_sym_freq_results:\n",
      "[2, '[15, 30]', 5, 20, 5, 2.660037308950124, 2.667601017022826, 0.9971646029430805, 111.26816623684576, 201.50266160787078, 0.5521920422737462, 698.0651498550478, 1331.3539417336378, 0.5243272491055642, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "\n",
      "================================================== \n",
      "\n",
      "start_eval: 117,  date: 2017-08-22\n",
      "end_eval:   122,  date: 2017-08-29,  df_eval last date: 2017-08-28\n",
      "frequency count of symbol(s): 4\n",
      "\n",
      "df_eval:\n",
      "            BLFS  CLMT       CUTR         WB\n",
      "Date                                        \n",
      "2017-08-22  4.68  6.70  34.950001  94.410004\n",
      "2017-08-23  4.87  6.55  34.900002  97.410004\n",
      "2017-08-24  4.40  6.60  35.150002  98.209999\n",
      "2017-08-25  4.43  6.55  35.700001  95.989998\n",
      "2017-08-28  4.51  6.60  35.849998  95.080002\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         3.556,         5.057,         0.703\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        83.147,       189.403,         0.439\n",
      "grp(CAGR/UI):      mean, std, mean/std:     1,011.861,     2,036.650,         0.497\n",
      "row_add_total: [2, '[15, 30]', 5, 20, 4, 3.556295095452503, 5.057291226661789, 0.7032015630628292, 83.14699450914138, 189.40328292762976, 0.4389944737172878, 1011.8606590439027, 2036.649774681782, 0.4968260481613741, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "appended row_add to df_eval_sym_freq_results:\n",
      "[2, '[15, 30]', 5, 20, 4, 3.556295095452503, 5.057291226661789, 0.7032015630628292, 83.14699450914138, 189.40328292762976, 0.4389944737172878, 1011.8606590439027, 2036.649774681782, 0.4968260481613741, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "\n",
      "================================================== \n",
      "\n",
      "start_eval: 117,  date: 2017-08-22\n",
      "end_eval:   122,  date: 2017-08-29,  df_eval last date: 2017-08-28\n",
      "frequency count of symbol(s): 3\n",
      "\n",
      "df_eval:\n",
      "            CYRX       MYGN        NRG   NTRA       TTWO       WING\n",
      "Date                                                               \n",
      "2017-08-22  7.50  28.959999  23.752718  11.64  94.949997  28.590012\n",
      "2017-08-23  6.67  29.250000  23.523088  11.35  94.400002  28.139902\n",
      "2017-08-24  6.90  29.520000  23.357756  11.64  95.250000  27.850550\n",
      "2017-08-25  6.61  29.320000  22.577019  11.60  94.639999  27.408472\n",
      "2017-08-28  6.63  29.570000  22.567839  12.23  95.809998  26.234970\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         1.615,         1.262,         1.280\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        77.329,       163.211,         0.474\n",
      "grp(CAGR/UI):      mean, std, mean/std:       281.120,       423.655,         0.664\n",
      "row_add_total: [2, '[15, 30]', 5, 20, 3, 1.6151172639582816, 1.261968153642059, 1.2798399541993424, 77.32889159326034, 163.2112530491752, 0.47379632316137726, 281.1201786120666, 423.65505147732165, 0.6635591329119677, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "appended row_add to df_eval_sym_freq_results:\n",
      "[2, '[15, 30]', 5, 20, 3, 1.6151172639582816, 1.261968153642059, 1.2798399541993424, 77.32889159326034, 163.2112530491752, 0.47379632316137726, 281.1201786120666, 423.65505147732165, 0.6635591329119677, 0.6852125108760572, -62.51283849947529, -42.83457903021492]\n",
      "\n",
      "================================================== \n",
      "\n",
      "2 of 2 max_lookback_slice\n",
      "max_lookback_slice: (325, 355, 360)\n",
      "max lookback dates: 2018-06-20, 2018-08-02, 2018-08-09\n",
      "df_eval dates (inclusive): 2018-08-02 - 2018-08-08\n",
      "top_set_syms_n_freq: [('HWM', 5), ('FCN', 4), ('MRCY', 4), ('CACC', 3), ('CCU', 3), ('DLR', 3), ('FMX', 3), ('GTLS', 3), ('HCA', 3), ('LLY', 3), ('MCS', 3), ('MOH', 3), ('MPC', 3), ('NTRA', 3), ('PFE', 3), ('RDN', 3), ('RHI', 3), ('RPM', 3), ('TSLX', 3), ('TSM', 3)]\n",
      "\n",
      "sym_freq_6: []\n",
      "sym_freq_5: ['HWM']\n",
      "sym_freq_4: ['FCN', 'MRCY']\n",
      "sym_freq_3: ['CACC', 'CCU', 'DLR', 'FMX', 'GTLS', 'HCA', 'LLY', 'MCS', 'MOH', 'MPC', 'NTRA', 'PFE', 'RDN', 'RHI', 'RPM', 'TSLX', 'TSM']\n",
      "\n",
      "\n",
      "SPY: retnStd/UI, CAGR/retnStd, CAGR/UI:        11.305,       340.972,     3,854.552\n",
      "start_eval: 355,  date: 2018-08-02\n",
      "end_eval:   360,  date: 2018-08-09,  df_eval last date: 2018-08-08\n",
      "frequency count of symbol(s): 5\n",
      "\n",
      "df_eval:\n",
      "                  HWM\n",
      "Date                 \n",
      "2018-08-02  20.768625\n",
      "2018-08-03  20.926336\n",
      "2018-08-06  20.877052\n",
      "2018-08-07  20.650341\n",
      "2018-08-08  20.610912\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         0.836,           nan,           nan\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       -42.301,           nan,           nan\n",
      "grp(CAGR/UI):      mean, std, mean/std:       -35.370,           nan,           nan\n",
      "row_add_total: [2, '[15, 30]', 5, 20, 5, 0.8361615407996722, nan, nan, -42.30085817015353, nan, nan, -35.37035074470398, nan, nan, 11.30459001143737, 340.9723094536495, 3854.5521636264575]\n",
      "appended row_add to df_eval_sym_freq_results:\n",
      "[2, '[15, 30]', 5, 20, 5, 0.8361615407996722, nan, nan, -42.30085817015353, nan, nan, -35.37035074470398, nan, nan, 11.30459001143737, 340.9723094536495, 3854.5521636264575]\n",
      "\n",
      "================================================== \n",
      "\n",
      "start_eval: 355,  date: 2018-08-02\n",
      "end_eval:   360,  date: 2018-08-09,  df_eval last date: 2018-08-08\n",
      "frequency count of symbol(s): 4\n",
      "\n",
      "df_eval:\n",
      "                  FCN       MRCY\n",
      "Date                            \n",
      "2018-08-02  80.379997  49.919998\n",
      "2018-08-03  79.230003  47.750000\n",
      "2018-08-06  79.849998  48.509998\n",
      "2018-08-07  81.180000  48.849998\n",
      "2018-08-08  81.500000  48.389999\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:         1.382,         0.660,         2.095\n",
      "grp(CAGR/retnStd): mean, std, mean/std:        23.591,        76.130,         0.310\n",
      "grp(CAGR/UI):      mean, std, mean/std:        57.732,       120.811,         0.478\n",
      "row_add_total: [2, '[15, 30]', 5, 20, 4, 1.3824248077806363, 0.6598813050152943, 2.09495980151854, 23.591407592524213, 76.1298331021624, 0.3098838737878978, 57.73167391539566, 120.81129872193135, 0.47786651187547746, 11.30459001143737, 340.9723094536495, 3854.5521636264575]\n",
      "appended row_add to df_eval_sym_freq_results:\n",
      "[2, '[15, 30]', 5, 20, 4, 1.3824248077806363, 0.6598813050152943, 2.09495980151854, 23.591407592524213, 76.1298331021624, 0.3098838737878978, 57.73167391539566, 120.81129872193135, 0.47786651187547746, 11.30459001143737, 340.9723094536495, 3854.5521636264575]\n",
      "\n",
      "================================================== \n",
      "\n",
      "start_eval: 355,  date: 2018-08-02\n",
      "end_eval:   360,  date: 2018-08-09,  df_eval last date: 2018-08-08\n",
      "frequency count of symbol(s): 3\n",
      "\n",
      "df_eval:\n",
      "                  CACC        CCU         DLR        FMX       GTLS         HCA        LLY  ...       NTRA        PFE        RDN        RHI        RPM       TSLX        TSM\n",
      "Date                                                                                        ...                                                                             \n",
      "2018-08-02  446.709991  20.753887  103.574234  89.142326  77.989998  121.375214  92.567322  ...  23.850000  31.939320  18.093782  72.183052  59.625183  13.194133  38.038536\n",
      "2018-08-03  446.000000  20.814526  104.891998  89.563667  76.430000  126.103111  93.600288  ...  23.639999  32.656254  18.084387  71.774155  59.737015  13.267658  38.166706\n",
      "2018-08-06  449.989990  20.511330  104.464157  89.728539  77.449997  124.795174  94.921753  ...  23.740000  33.059021  18.300457  73.270416  59.727688  13.421387  37.599091\n",
      "2018-08-07  428.720001  20.390049  104.506927  92.000153  77.879997  125.405540  94.865913  ...  24.219999  32.897903  18.638659  74.013893  59.625183  13.481544  37.754734\n",
      "2018-08-08  436.760010  20.344570  104.002075  92.476456  76.849998  124.310760  95.173019  ...  23.480000  33.357059  18.807762  73.753685  59.438793  13.327814  38.423042\n",
      "\n",
      "[5 rows x 17 columns]\n",
      "\n",
      "grp(retnStd/UI):   mean, std, mean/std:           inf,           nan,           nan\n",
      "grp(CAGR/retnStd): mean, std, mean/std:       170.223,       266.842,         0.638\n",
      "grp(CAGR/UI):      mean, std, mean/std:           inf,           nan,           nan\n",
      "row_add_total: [2, '[15, 30]', 5, 20, 3, inf, nan, nan, 170.22266391268192, 266.842346598468, 0.6379147316105157, inf, nan, nan, 11.30459001143737, 340.9723094536495, 3854.5521636264575]\n",
      "appended row_add to df_eval_sym_freq_results:\n",
      "[2, '[15, 30]', 5, 20, 3, inf, nan, nan, 170.22266391268192, 266.842346598468, 0.6379147316105157, inf, nan, nan, 11.30459001143737, 340.9723094536495, 3854.5521636264575]\n",
      "\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from yf_utils import _7_perf_eval\n",
    "\n",
    "print('z_grp_top_set_syms_n_freq:')\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "\n",
    "for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "\n",
    "  start_train = _lookback_slice[0]\n",
    "  end_train = _lookback_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  d_start_train = df_train.index[start_train].strftime('%Y-%m-%d')\n",
    "  d_end_train = df_train.index[end_train].strftime('%Y-%m-%d')\n",
    "  d_start_eval = d_end_train\n",
    "  d_end_eval = df_train.index[end_eval].strftime('%Y-%m-%d')\n",
    "  d_df_eval_start = d_end_train\n",
    "  d_df_eval_end = df_train.index[end_eval - 1].strftime('%Y-%m-%d')  \n",
    "  print(f'max lookback dates: {d_start_train}, {d_end_train}, {d_end_eval}')\n",
    "  print(f'df_eval dates (inclusive): {d_df_eval_start} - {d_df_eval_end}')    \n",
    "  print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}\\n')\n",
    "\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(_top_set_syms_n_freq)\n",
    "  print(f'sym_freq_6: {l_sym_freq_cnt[0]}')\n",
    "  print(f'sym_freq_5: {l_sym_freq_cnt[1]}')\n",
    "  print(f'sym_freq_4: {l_sym_freq_cnt[2]}')\n",
    "  print(f'sym_freq_3: {l_sym_freq_cnt[3]}\\n')\n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df_train[start_eval:end_eval][_sym_idx]\n",
    "  _, SPY_retnStd_d_UI, SPY_CAGR_d_retnStd, SPY_CAGR_d_UI = _7_perf_eval(df_SPY)\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI: {SPY_retnStd_d_UI[0]:>13,.3f}, {SPY_CAGR_d_retnStd[0]:>13,.3f}, {SPY_CAGR_d_UI[0]:>13,.3f}')\n",
    "\n",
    "  # drop last list in l_sym_freq_cnt from zip\n",
    "  zip_cnt_n_syms = zip([6,5,4,3], l_sym_freq_cnt[:-1])  \n",
    "  for item in zip_cnt_n_syms:\n",
    "    sym_freq_cnt = item[0]\n",
    "    syms = item[1]\n",
    "    if syms:  # iterate ONLY if there are symbols in syms\n",
    "      df_eval = df_train[start_eval:end_eval][syms]      \n",
    "\n",
    "      if verbose:\n",
    "        # print(f'start_eval: {start_eval}')\n",
    "        # print(f'end_eval:   {end_eval}')  \n",
    "        print(f'start_eval: {start_eval},  date: {d_end_train}')\n",
    "        print(f'end_eval:   {end_eval},  date: {d_end_eval},  df_eval last date: {d_df_eval_end}')\n",
    "        print(f'frequency count of symbol(s): {sym_freq_cnt}')      \n",
    "        print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "      _, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = _7_perf_eval(df_eval)\n",
    "      print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>13,.3f}, {grp_retnStd_d_UI[1]  :>13,.3f}, {grp_retnStd_d_UI[2]  :>13,.3f}')\n",
    "      print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>13,.3f}, {grp_CAGR_d_retnStd[1]:>13,.3f}, {grp_CAGR_d_retnStd[2]:>13,.3f}')\n",
    "      print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>13,.3f}, {grp_CAGR_d_UI[1]     :>13,.3f}, {grp_CAGR_d_UI[2]     :>13,.3f}')\n",
    "\n",
    "\n",
    "\n",
    "      if store_results:  # record results to df\n",
    "        # row_add = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, grp_CAGR_d_UI[0], grp_CAGR_d_UI[1], grp_CAGR_d_UI[2], SPY_CAGR_d_UI[0]]\n",
    "        # df_eval_results.loc[len(df_eval_results)] = row_add\n",
    "        # row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end]\n",
    "        row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, sym_freq_cnt]        \n",
    "        row_add1      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "        row_add2      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "        row_add3      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "        row_add4      = [SPY_retnStd_d_UI[0],   SPY_CAGR_d_retnStd[0], SPY_CAGR_d_UI[0]]\n",
    "        row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4\n",
    "        print(f'row_add_total: {row_add_total}')\n",
    "        df_eval_sym_freq_results.loc[len(df_eval_sym_freq_results)] = row_add_total\n",
    "        # print(f'appended row_add to df_eval_results:\\n{row_add}\\n')\n",
    "        print(f'appended row_add to df_eval_sym_freq_results:\\n{row_add_total}\\n')\n",
    "      print('='*50, '\\n')  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # # df_eval to show _top_set_syms_n_freq along with SPY \n",
    "  # symbols_eval = _top_set_syms_n_freq.copy()\n",
    "  # symbols_eval.append('SPY')\n",
    "  # print(f'symbols_eval: {symbols_eval}, _top_set_syms_n_freq: {_top_set_syms_n_freq}')\n",
    "  # df_eval = df_train[start_eval:end_eval][symbols_eval]\n",
    "\n",
    "  # if verbose:\n",
    "  #   # print(f'start_eval: {start_eval}')\n",
    "  #   # print(f'end_eval:   {end_eval}')  \n",
    "  #   print(f'start_eval: {start_eval},  date: {d_end_train}')\n",
    "  #   print(f'end_eval:   {end_eval},  date: {d_end_eval},  df_eval last date: {d_df_eval_end}')      \n",
    "  #   print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "\n",
    "  # _, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = _7_perf_eval(df_eval)\n",
    "  # print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>13,.3f}, {grp_retnStd_d_UI[1]  :>13,.3f}, {grp_retnStd_d_UI[2]  :>13,.3f}')\n",
    "  # print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>13,.3f}, {grp_CAGR_d_retnStd[1]:>13,.3f}, {grp_CAGR_d_retnStd[2]:>13,.3f}')\n",
    "  # print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>13,.3f}, {grp_CAGR_d_UI[1]     :>13,.3f}, {grp_CAGR_d_UI[2]     :>13,.3f}')\n",
    "\n",
    "  # _sym_idx = ['SPY']\n",
    "  # df_SPY = df_train[start_eval:end_eval][_sym_idx]\n",
    "  # _, SPY_retnStd_d_UI, SPY_CAGR_d_retnStd, SPY_CAGR_d_UI = _7_perf_eval(df_SPY)\n",
    "  # print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI: {SPY_retnStd_d_UI[0]:>13,.3f}, {SPY_CAGR_d_retnStd[0]:>13,.3f}, {SPY_CAGR_d_UI[0]:>13,.3f}')\n",
    "\n",
    "  # if store_results:  # record results to df\n",
    "  #   # row_add = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, grp_CAGR_d_UI[0], grp_CAGR_d_UI[1], grp_CAGR_d_UI[2], SPY_CAGR_d_UI[0]]\n",
    "  #   # df_eval_results.loc[len(df_eval_results)] = row_add\n",
    "  #   row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end]\n",
    "  #   row_add1      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "  #   row_add2      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "  #   row_add3      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "  #   row_add4      = [SPY_retnStd_d_UI[0],   SPY_CAGR_d_retnStd[0], SPY_CAGR_d_UI[0]]\n",
    "  #   row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4\n",
    "  #   print(f'row_add_total: {row_add_total}')\n",
    "  #   df_eval_results.loc[len(df_eval_results)] = row_add_total\n",
    "  #   # print(f'appended row_add to df_eval_results:\\n{row_add}\\n')\n",
    "  #   print(f'appended row_add to df_eval_results:\\n{row_add_total}\\n')\n",
    "  # print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>days_eval</th>\n",
       "      <th>n_top_syms</th>\n",
       "      <th>sym_freq_cnt</th>\n",
       "      <th>grp(retnStd/UI)_mean</th>\n",
       "      <th>grp(retnStd/UI)_std</th>\n",
       "      <th>...</th>\n",
       "      <th>grp(CAGR/retnStd)_mean/std</th>\n",
       "      <th>grp(CAGR/UI)_mean</th>\n",
       "      <th>grp(CAGR/UI)_std</th>\n",
       "      <th>grp(CAGR/UI)_mean/std</th>\n",
       "      <th>SPY_retnStd/UI</th>\n",
       "      <th>SPY_CAGR/retnStd</th>\n",
       "      <th>SPY_CAGR/UI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.778373</td>\n",
       "      <td>0.483398</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.110851</td>\n",
       "      <td>-41.399664</td>\n",
       "      <td>9.812035</td>\n",
       "      <td>-4.219274</td>\n",
       "      <td>0.685213</td>\n",
       "      <td>-62.512838</td>\n",
       "      <td>-42.834579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2.660037</td>\n",
       "      <td>2.667601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552192</td>\n",
       "      <td>698.065150</td>\n",
       "      <td>1331.353942</td>\n",
       "      <td>0.524327</td>\n",
       "      <td>0.685213</td>\n",
       "      <td>-62.512838</td>\n",
       "      <td>-42.834579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3.556295</td>\n",
       "      <td>5.057291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438994</td>\n",
       "      <td>1011.860659</td>\n",
       "      <td>2036.649775</td>\n",
       "      <td>0.496826</td>\n",
       "      <td>0.685213</td>\n",
       "      <td>-62.512838</td>\n",
       "      <td>-42.834579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.615117</td>\n",
       "      <td>1.261968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473796</td>\n",
       "      <td>281.120179</td>\n",
       "      <td>423.655051</td>\n",
       "      <td>0.663559</td>\n",
       "      <td>0.685213</td>\n",
       "      <td>-62.512838</td>\n",
       "      <td>-42.834579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.836162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35.370351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.304590</td>\n",
       "      <td>340.972309</td>\n",
       "      <td>3854.552164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.382425</td>\n",
       "      <td>0.659881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309884</td>\n",
       "      <td>57.731674</td>\n",
       "      <td>120.811299</td>\n",
       "      <td>0.477867</td>\n",
       "      <td>11.304590</td>\n",
       "      <td>340.972309</td>\n",
       "      <td>3854.552164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>[15, 30]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637915</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.304590</td>\n",
       "      <td>340.972309</td>\n",
       "      <td>3854.552164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_samples days_lookbacks days_eval n_top_syms sym_freq_cnt  grp(retnStd/UI)_mean  grp(retnStd/UI)_std  ...  grp(CAGR/retnStd)_mean/std  grp(CAGR/UI)_mean  grp(CAGR/UI)_std  grp(CAGR/UI)_mean/std  SPY_retnStd/UI  SPY_CAGR/retnStd  SPY_CAGR/UI\n",
       "0         2       [15, 30]         5         20            6         0.778373              0.483398      ...        -3.110851                  -41.399664           9.812035         -4.219274              0.685213       -62.512838    -42.834579\n",
       "1         2       [15, 30]         5         20            5         2.660037              2.667601      ...         0.552192                  698.065150        1331.353942          0.524327              0.685213       -62.512838    -42.834579\n",
       "2         2       [15, 30]         5         20            4         3.556295              5.057291      ...         0.438994                 1011.860659        2036.649775          0.496826              0.685213       -62.512838    -42.834579\n",
       "3         2       [15, 30]         5         20            3         1.615117              1.261968      ...         0.473796                  281.120179         423.655051          0.663559              0.685213       -62.512838    -42.834579\n",
       "4         2       [15, 30]         5         20            5         0.836162                   NaN      ...              NaN                  -35.370351                NaN               NaN             11.304590       340.972309   3854.552164\n",
       "5         2       [15, 30]         5         20            4         1.382425              0.659881      ...         0.309884                   57.731674         120.811299          0.477867             11.304590       340.972309   3854.552164\n",
       "6         2       [15, 30]         5         20            3              inf                   NaN      ...         0.637915                         inf                NaN               NaN             11.304590       340.972309   3854.552164\n",
       "\n",
       "[7 rows x 17 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_sym_freq_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "for item in z_grp_top_set_syms:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_add0 = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end']\n",
    "col_add0 = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'sym_freq_cnt']\n",
    "\n",
    "col_add1 = ['grp(retnStd/UI)_mean',   'grp(retnStd/UI)_std',   'grp(retnStd/UI)_mean/std']\n",
    "col_add2 = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "col_add3 = ['grp(CAGR/UI)_mean',      'grp(CAGR/UI)_std',      'grp(CAGR/UI)_mean/std']\n",
    "col_add4 = ['SPY_retnStd/UI', 'SPY_CAGR/retnStd', 'SPY_CAGR/UI']\n",
    "col_add_total = col_add0 + col_add1 + col_add2 + col_add3 + col_add4\n",
    "print(f'col_add_total: {col_add_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yf_utils import _7_perf_eval\n",
    "\n",
    "print('z_grp_top_set_syms:')\n",
    "z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms)\n",
    "# z_grp_top_set_syms = zip(max_lookback_slices, grp_top_set_syms[26:29])\n",
    "\n",
    "for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms):\n",
    "# for i, (_lookback_slice, _top_set_syms) in enumerate(z_grp_top_set_syms[26:29]):\n",
    "\n",
    "  start_train = _lookback_slice[0]\n",
    "  end_train = _lookback_slice[1]\n",
    "  start_eval = end_train\n",
    "  end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice')\n",
    "  print(f'max_lookback_slice: {_lookback_slice}')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  d_start_train = df_train.index[start_train].strftime('%Y-%m-%d')\n",
    "  d_end_train = df_train.index[end_train].strftime('%Y-%m-%d')\n",
    "  d_start_eval = d_end_train\n",
    "  d_end_eval = df_train.index[end_eval].strftime('%Y-%m-%d')\n",
    "  d_df_eval_start = d_end_train\n",
    "  d_df_eval_end = df_train.index[end_eval - 1].strftime('%Y-%m-%d')  \n",
    "  print(f'max lookback dates: {d_start_train}, {d_end_train}, {d_end_eval}')\n",
    "  print(f'df_eval dates (inclusive): {d_df_eval_start} - {d_df_eval_end}')    \n",
    "  print(f'top_set_syms: {_top_set_syms}\\n')\n",
    "\n",
    "  # df_eval to show _top_set_syms along with SPY \n",
    "  symbols_eval = _top_set_syms.copy()\n",
    "  symbols_eval.append('SPY')\n",
    "  print(f'symbols_eval: {symbols_eval}, _top_set_syms: {_top_set_syms}')\n",
    "  df_eval = df_train[start_eval:end_eval][symbols_eval]\n",
    "\n",
    "  if verbose:\n",
    "    # print(f'start_eval: {start_eval}')\n",
    "    # print(f'end_eval:   {end_eval}')  \n",
    "    print(f'start_eval: {start_eval},  date: {d_end_train}')\n",
    "    print(f'end_eval:   {end_eval},  date: {d_end_eval},  df_eval last date: {d_df_eval_end}')      \n",
    "    print(f'\\ndf_eval:\\n{df_eval}\\n')\n",
    "\n",
    "\n",
    "  _, grp_retnStd_d_UI, grp_CAGR_d_retnStd, grp_CAGR_d_UI = _7_perf_eval(df_eval)\n",
    "  print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>13,.3f}, {grp_retnStd_d_UI[1]  :>13,.3f}, {grp_retnStd_d_UI[2]  :>13,.3f}')\n",
    "  print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>13,.3f}, {grp_CAGR_d_retnStd[1]:>13,.3f}, {grp_CAGR_d_retnStd[2]:>13,.3f}')\n",
    "  print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>13,.3f}, {grp_CAGR_d_UI[1]     :>13,.3f}, {grp_CAGR_d_UI[2]     :>13,.3f}')\n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df_train[start_eval:end_eval][_sym_idx]\n",
    "  _, SPY_retnStd_d_UI, SPY_CAGR_d_retnStd, SPY_CAGR_d_UI = _7_perf_eval(df_SPY)\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI: {SPY_retnStd_d_UI[0]:>13,.3f}, {SPY_CAGR_d_retnStd[0]:>13,.3f}, {SPY_CAGR_d_UI[0]:>13,.3f}')\n",
    "\n",
    "  if store_results:  # record results to df\n",
    "    # row_add = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, grp_CAGR_d_UI[0], grp_CAGR_d_UI[1], grp_CAGR_d_UI[2], SPY_CAGR_d_UI[0]]\n",
    "    # df_eval_results.loc[len(df_eval_results)] = row_add\n",
    "    row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end]\n",
    "    row_add1      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "    row_add2      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "    row_add3      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "    row_add4      = [SPY_retnStd_d_UI[0],   SPY_CAGR_d_retnStd[0], SPY_CAGR_d_UI[0]]\n",
    "    row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4\n",
    "    print(f'row_add_total: {row_add_total}')\n",
    "    df_eval_results.loc[len(df_eval_results)] = row_add_total\n",
    "    # print(f'appended row_add to df_eval_results:\\n{row_add}\\n')\n",
    "    print(f'appended row_add to df_eval_results:\\n{row_add_total}\\n')\n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating Empty DataFrame and Storing it in variable df\n",
    "# df_eval_results = pd.DataFrame(columns=col_add_total)\n",
    "pickle_dump(df_eval_results, path_data_dump, fp_df_eval_results)\n",
    "df = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pandas-groupby-a-simple-but-detailed-tutorial-314b8f37005d\n",
    "# https://towardsdatascience.com/accessing-data-in-a-multiindex-dataframe-in-pandas-569e8767201d\n",
    "# https://towardsdatascience.com/summarizing-data-with-pandas-crosstab-efc8b9abecf\n",
    "# https://towardsdatascience.com/how-to-flatten-multiindex-columns-and-rows-in-pandas-f5406c50e569\n",
    "# https://datascientyst.com/list-aggregation-functions-aggfunc-groupby-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(df.columns): {len(df.columns)}')\n",
    "print(f'df.columns: {df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(df['days_lookbacks'], df['grp(CAGR/UI)_mean'])\n",
    "tbl = df.groupby(['days_lookbacks', 'days_eval', 'syms_start', 'syms_end'])\\\n",
    "        .agg({'grp(CAGR/retnStd)_mean':     ['mean', 'std'],\n",
    "              'grp(CAGR/retnStd)_mean/std': ['mean', 'std'],\n",
    "              'SPY_CAGR/retnStd':           ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl['SPY_m/s'] = tbl['SPY_CAGR/retnStd', 'mean'] / tbl['SPY_CAGR/retnStd', 'std'] \n",
    "tbl['grp-SPY_m/s'] = tbl['grp(CAGR/retnStd)_mean/std', 'mean'] - tbl['SPY_m/s'] \n",
    "tbl.sort_values(by='grp-SPY_m/s', ascending=False, inplace=True)\n",
    "# tbl.sort_values(by='days_lookbacks', ascending=False, inplace=True)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/31674195/plot-normal-distribution-given-mean-and-sigma-python\n",
    "# # loc is mean, scale is standard deviation\n",
    "# import pylab\n",
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "# # x = np.linspace(-10000,100000,1000)\n",
    "# x = np.linspace(-40e+10,50e+10,1000)\n",
    "# y = norm.pdf(x, loc=2.562777e+10, scale=1.036925e+11)    # loc = mean, scale = standard deviation\n",
    "# # z = norm.pdf(x, loc=3.540615e+10, scale=1.194430e+11)    # for example\n",
    "# # z1 = norm.pdf(x, loc=298.805901, scale=826.875749)    # for example\n",
    "# # z1 = norm.pdf(x, loc=1.021825, scale=1.505096)    # for example\n",
    "# pylab.plot(x,y, 'b')\n",
    "# # pylab.plot(x,z, 'g')\n",
    "# # pylab.plot(x,z1, 'r')\n",
    "# pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get values of _cols, where grp(CAGR/retnStd)_mean is max after filtering out inf\n",
    "# _cols = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "# # _df_no_inf = df.loc[df['grp(CAGR/retnStd)_mean'] != np.inf]  # df with filter out inf in column grp(CAGR/UI)_mean \n",
    "# # _idx = _df_no_inf['grp(CAGR/retnStd)_mean'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# _idx = df['grp(CAGR/retnStd)_mean'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# grp_inf_replacement = df.loc[[_idx], _cols].squeeze()  # convert df (only has 1 row) to series\n",
    "# print(f'_idx: {_idx}')\n",
    "# grp_inf_replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get values of _cols, where SPY_CAGR/retnStd is max after filtering out inf\n",
    "# _cols = ['SPY_CAGR/retnStd']\n",
    "# # _df_no_inf = df.loc[df['SPY_CAGR/retnStd'] != np.inf]  # df with filter out inf in column grp(CAGR/UI)_mean \n",
    "# _idx = df['SPY_CAGR/retnStd'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "# SPY_inf_replacement = df.loc[[_idx], _cols].squeeze()  # convert df (only has 1 row) to series\n",
    "# print(f'_idx: {_idx}')\n",
    "# SPY_inf_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # https://stackoverflow.com/questions/50773107/how-to-replace-infinite-value-with-maximum-value-of-a-pandas-column\n",
    "# # replace inf in column grp(CAGR/UI)_mean\n",
    "# df['grp(CAGR/UI)_mean'].replace(np.inf, grp_inf_replacement['grp(CAGR/UI)_mean'], inplace=True)\n",
    "# # replace NaN in column grp(CAGR/UI)_std\n",
    "# df['grp(CAGR/UI)_std'].replace(np.nan, grp_inf_replacement['grp(CAGR/UI)_std'], inplace=True)\n",
    "# # replace NaN in column grp(CAGR/UI)_mean/std\n",
    "# df['grp(CAGR/UI)_mean/std'].replace(np.nan, grp_inf_replacement['grp(CAGR/UI)_mean/std'], inplace=True)\n",
    "# # replace inf in column SPY_CAGR/UI\n",
    "# df['SPY_CAGR/UI'].replace(np.inf, SPY_inf_replacement, inplace=True)\n",
    "# df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'n_samples:             {n_samples:>13}')\n",
    "# print(f'days_lookbacks:        {days_lookbacks}')\n",
    "# print(f'days_eval:             {days_eval:>13}')\n",
    "# print(f'n_top_syms:            {n_top_syms:>13}')\n",
    "# print(f'syms_start:            {syms_start:>13}')\n",
    "# print(f'syms_end:              {syms_end:>13}')\n",
    "# print(f'grp(CAGR/UI)_mean:     {grp_CAGR_d_UI[0]:>13,.3f}')\n",
    "# print(f'grp(CAGR/UI)_std:      {grp_CAGR_d_UI[1]:>13,.3f}')\n",
    "# print(f'grp(CAGR/UI)_mean/std: {grp_CAGR_d_UI[2]:>13,.3f}')\n",
    "# print(f'SPY_CAGR/UI:           {SPY_CAGR_d_UI[0]:>13,.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
